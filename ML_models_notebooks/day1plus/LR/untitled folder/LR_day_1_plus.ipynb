{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/src')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "from dfwiz import dfwiz\n",
    "from dfwiz import dfwiz_compare\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from utils.vis import spy, look, plot_nunique, plot_dists\n",
    "from utils.processing import sort, impute, replace_inf, drop_empty, select, drop_by_nunique, scale, melt, unmelt, \\\n",
    "                             remove_outliers, get_categories, filter_categorical, onehot, filter_regex, match, cap,get_dates\n",
    "from utils.pipelines import scale_impute_via_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables representing experiment parameters\n",
    "EXPERIMENT = 'Processing Demo'\n",
    "IMPUTE_NUM = 'constant'\n",
    "IMPUTE_CAT = 'other'\n",
    "FIGSIZE    = [12,3]\n",
    "\n",
    "# parameter dict\n",
    "params = {\n",
    "    'experiment':EXPERIMENT,\n",
    "    'figsize'   :FIGSIZE,\n",
    "    'impute_num':IMPUTE_NUM,\n",
    "    'impute_cat':IMPUTE_CAT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy as sp\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn')\n",
    "sns.set_theme(style=\"ticks\")\n",
    "mpl.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "# Title\n",
    "mpl.rcParams['figure.titlesize'] = 22\n",
    "mpl.rcParams['figure.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlesize'] = 22\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlepad'] = 20\n",
    "\n",
    "# Axes labels\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "\n",
    "# Grid and thicks\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['axes.grid.axis'] = 'y'\n",
    "#mpl.rcParams['axes.xmargin'] = 0\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "\n",
    "# Legend\n",
    "mpl.rcParams['legend.facecolor'] = 'w'\n",
    "mpl.rcParams['legend.title_fontsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['legend.frameon'] = True\n",
    "mpl.rcParams['legend.framealpha'] = 1\n",
    "mpl.rcParams['legend.fancybox'] = True\n",
    "mpl.rcParams['legend.facecolor'] = 'white'\n",
    "mpl.rcParams['legend.edgecolor'] = 'blue'\n",
    "mpl.rcParams['legend.borderpad'] = 0.6\n",
    "\n",
    "# Other\n",
    "mpl.rcParams['lines.linewidth'] = 2.5\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['scatter.edgecolors'] = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### upsampler func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "class upsampler(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        return X\n",
    "\n",
    "    def sample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y[y == 0]], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y[y == 1]], y[y == 1]\n",
    "        else:\n",
    "            print(X[y[y == 0]].shape)\n",
    "            X1, y1 = resample(X[y[y == 1]], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y[y == 0]], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "\n",
    "        return X_out, y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### accuracy func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y, y_pred, y_pred_proba):\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "    score = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.plot(fpr,tpr,label=\"AUC=\"+str(round(score,2)))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    # print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "    cr = classification_report(y, y_pred)\n",
    "    print(\"\\r\\n\"+\"Classification report\"+\"\\r\\n\")\n",
    "    print(cr)\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    print(\"\\r\\n\"+\"Specificity\"+\"\\r\\n\")\n",
    "    print(round(specificity,2))\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def up_sample(X_train_raw, y_train_raw,col_name):\n",
    "\n",
    "    # upsampling X_train and y_train\n",
    "    df_upsampled = pd.merge(X_train_raw, y_train_raw, left_index=True, right_index=True)\n",
    "\n",
    "    X_minority = df_upsampled[df_upsampled[col_name]==1]\n",
    "    X_majority = df_upsampled[df_upsampled[col_name]!=1]\n",
    "\n",
    "    n_samples = X_majority.shape[0]\n",
    "    X_minority_upsampled = resample(X_minority,\n",
    "                                    replace=True,     # sample with replacement\n",
    "                                    n_samples=n_samples,    # to match majority class\n",
    "                                    random_state=42) # reproducible results\n",
    "\n",
    "    df_upsampled = pd.concat([X_majority, X_minority_upsampled]).sample(frac=1)\n",
    "\n",
    "    y_train_out = df_upsampled[[col_name]]\n",
    "    X_train_out = df_upsampled.drop([col_name], axis=1)\n",
    "\n",
    "    return X_train_out, y_train_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### define cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "def param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 5, sample_ratio = 0.2, refit=True, use_error=True, multi_class=False, average_metric='macro'):\n",
    "\n",
    "    print(\"This search selects lower indexes of search list if their score is within the error of maximum score.\")\n",
    "    print(\"Putting parameters for less complicated model on the left side of the grid lists leads to better generalisation. \")\n",
    "    print(\" \")\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    n_train = int(sample_ratio * len(y_train))\n",
    "    X_train_s, y_train_s  = resample(X_train, y_train, n_samples=n_train, stratify=y_train)\n",
    "\n",
    "    best_score = {}\n",
    "    best_params = {}\n",
    "    for k, v in param_grid.items():\n",
    "        # best_params[k] = v[int(len(v)/2)-1]\n",
    "        best_params[k] = v[0]\n",
    "    best_params_m1 = best_params.copy()\n",
    "    print(\"start_params:\", best_params)\n",
    "\n",
    "    score = {}\n",
    "    score_std = {}\n",
    "\n",
    "    for i_iter in range(max_iter):\n",
    "        print(\"_\"*100)\n",
    "        print(\"Iteration\", i_iter)\n",
    "\n",
    "        for k, v in param_grid.items():\n",
    "\n",
    "            best_params1 = best_params.copy()\n",
    "            del best_params1[k]  \n",
    "\n",
    "            score[k] = v.copy()\n",
    "            score_std[k] = v.copy()\n",
    "\n",
    "            for i_param, val_param in enumerate(v):\n",
    "                cv_sc = np.zeros(cv)\n",
    "\n",
    "                for i_cv in range(cv):\n",
    "\n",
    "                    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train_s, y_train_s, test_size=0.2, stratify=y_train_s, shuffle=True) # 80% training and 20% test\n",
    "\n",
    "                    p1 = copy.deepcopy(pipe)\n",
    "                    p1.set_params(**best_params1)\n",
    "                    params2 = {k:val_param}\n",
    "                    p1.set_params(**params2)\n",
    "\n",
    "                    p1.fit(X_train2, y_train2.ravel())\n",
    "                    # X,y = p1.named_steps['resample'].fit_resample(X_test2, y_test2)\n",
    "                    X,y = X_test2, y_test2\n",
    "                    # y_pred_proba = p1.predict_proba(X)\n",
    "                    # cv_sc[i_cv] = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "                    y_pred = p1.predict(X)\n",
    "                    if(multi_class):\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred, average=average_metric)\n",
    "                    else:\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred)\n",
    "\n",
    "                    i_cv = i_cv + 1\n",
    "\n",
    "                score[k][i_param] = cv_sc.mean()\n",
    "                score_std[k][i_param] = cv_sc.std()\n",
    "\n",
    "            print(\"\")\n",
    "            print(k)\n",
    "            print(v)\n",
    "            print(score[k])\n",
    "\n",
    "            best_params[k] = v[np.argmax(score[k])]\n",
    "            best_score[k] = score[k][np.argmax(score[k])]\n",
    "\n",
    "            if use_error:\n",
    "                for i_b in  range(np.argmax(score[k]),-1,-1):\n",
    "                    err1 = (score_std[k][i_b] + score_std[k][v.index(best_params[k])] ) / 4\n",
    "                    # print(\"err1\")\n",
    "                    max_del = max(score[k]) - err1\n",
    "                    # print( i_b, score[k][i_b], max(score[k]), err1, max_del )\n",
    "                    if score[k][i_b] >= max_del:\n",
    "                        best_params[k] = v[i_b]\n",
    "                        best_score[k] = score[k][i_b]\n",
    "\n",
    "            print(\"best_param:\",  v[np.argmax(score[k])], \"score:\", max(score[k]))\n",
    "            print(\"selected_param:\",  best_params[k], \"score:\", best_score[k])\n",
    "            \n",
    "\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"best_params =\", best_params)\n",
    "        print(\"\")\n",
    "        if best_params_m1 == best_params:\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "            print(\"Early stop. No improvement in the last iteration.\")\n",
    "            break\n",
    "        best_params_m1 = best_params.copy()\n",
    "\n",
    "    param_graph_plot(score)\n",
    "\n",
    "    if refit:\n",
    "        print(\"Refitting final model...\")\n",
    "        pipeline_final = copy.deepcopy(pipe)\n",
    "        pipeline_final.set_params(**best_params)\n",
    "        pipeline_final.fit(X_train, y_train.values.ravel())\n",
    "    else:\n",
    "        pipeline_final = None\n",
    "\n",
    "    return score, best_params, pipeline_final\n",
    "    \n",
    "\n",
    "def param_graph_plot(score):\n",
    "    ax = {}\n",
    "    fig = {}\n",
    "    for i, (k, v) in enumerate(score.items()):\n",
    "        fig[k], ax[k] = plt.subplots()\n",
    "\n",
    "    for k, v in score.items():\n",
    "        x = score[k]\n",
    "        y = v\n",
    "        ax[k].plot(x,y,\"-o\", label=\"Score\")\n",
    "        # ax[k].set_ylim([0.5, 1])\n",
    "        ax[k].set_title(k)\n",
    "        ax[k].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Define upsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "class upsampler(BaseEstimator): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def fit_resample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).ravel()\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y == 0], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y == 1], y[y == 1]\n",
    "        else:\n",
    "            X1, y1 = resample(X[y == 1], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y == 0], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "        return X_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Load data and select index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "sqluser = 'uqhkamel'\n",
    "dbname = 'mimiciv'\n",
    "schema_name = 'mimic_derived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to {}'.format(schema_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select * from all_scr_preadmission_75_JOIN\"\n",
    "# data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id','hadm_id'])\n",
    "query = \"select * from AKI_ICU_JOIN_day1plus_SD\"\n",
    "data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id'])\n",
    "data.drop('hadm_id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ethnicity'] = data['ethnicity'].replace(['OTHER'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNKNOWN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['AMERICAN INDIAN/ALASKA NATIVE'],np.nan)\n",
    "\n",
    "data = data.fillna(value=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aki_kdigo = ['aki_kdigo_grade_1','aki_kdigo_grade_2','aki_kdigo_grade_3']\n",
    "\n",
    "# outcome_var = ['day_detection_kdigo_grade_1','day_detection_kdigo_grade_2','day_detection_kdigo_grade_3']\n",
    "\n",
    "# outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "# first_24h = 1\n",
    "# data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['min_day_rrt_present']<=1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = []\n",
    "outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "first_24h = 1\n",
    "data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['ckd']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['ckd']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['kidney_transplant']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['kidney_transplant']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data['egfr_mdrd_scr']>60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.egfr_mdrd_scr<60].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dropna(axis=1, thresh = int(0.3*data.shape[0]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_window = 3\n",
    "\n",
    "# data.loc[(((data['aki_kdigo_grade_1']== 1)| (data['aki_kdigo_grade_2']== 1) | (data['aki_kdigo_grade_3']==1)) \\\n",
    "#     &( (data['day_detection_kdigo_grade_1']<=prediction_window)| (data['day_detection_kdigo_grade_2']<=prediction_window) | (data['day_detection_kdigo_grade_3']<=prediction_window)) \\\n",
    "#         |(data['min_day_rrt_present']<= prediction_window)), 'outcome'] = 1\n",
    "\n",
    "\n",
    "# data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_window = 3\n",
    "\n",
    "data.loc[(( (data['aki_kdigo_grade_1']== 1)) \\\n",
    "    &( (data['day_detection_kdigo_grade_1']<=prediction_window))), 'outcome'] = 1\n",
    "\n",
    "\n",
    "data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "'day_detection_kdigo_grade_1',\n",
    "'day_detection_kdigo_grade_2',\n",
    "'day_detection_kdigo_grade_3',\n",
    "'day_detection_mkdigo_grade_1',\n",
    "'day_detection_mkdigo_grade_2',\n",
    "'day_detection_mkdigo_grade_3',\n",
    "'min_day_rrt_active',\n",
    "'min_day_rrt_present',\n",
    "'ckd',\n",
    "'chronic_kidney_disease'\n",
    "]\n",
    "# CRP and vomit_nausea as they had mostly empty\n",
    "\n",
    "data.drop(drop_X, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missingness percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = 20 # remove rows with NaN is 80 or more in each row\n",
    "min_count =  int(((100-perc)/100)*data.shape[0])\n",
    "data.dropna(axis=1, thresh = min_count, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.reset_index().drop_duplicates(subset=['stay_id','subject_id','hadm_id']).set_index(['stay_id','subject_id','hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove unpopulated columns\n",
    "# data.pipe(sort)\\\n",
    "#               .pipe(replace_inf).pipe(drop_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by column type\n",
    "data_num = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'numerical')\n",
    "\n",
    "data_cat = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cat = data_cat.pipe(filter_categorical, cutoff=20, plot=False)\\\n",
    "#                                             .pipe(sort).pipe(spy, title='Before onehot', figsize=[12,4])\\\n",
    "#                                             .fillna('other').pipe(onehot)\n",
    "# data_cat = data_cat.fillna('other').pipe(onehot)\n",
    "data_cat = pd.get_dummies(data_cat,prefix=[''], prefix_sep='', columns = ['ethnicity'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed = pd.merge(data_num, data_cat, left_index=True, right_index=True)\n",
    "processed = pd.merge(data_num, data_cat, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2 = processed.copy()\n",
    "processed.drop(['egfr_epi_scr','egfr_mdrd_scr'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(processed[processed['aki_kdigo_grade_3']==1].shape[0])/processed.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(processed[processed['aki_kdigo_grade_3']==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(processed[processed['aki_kdigo_grade_1']==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# X_MI = np.array(processed.creatinine_max).reshape(-1,1)\n",
    "# y_MI = np.array(processed.outcome)\n",
    "\n",
    "# mi = mutual_info_classif(X_MI,y_MI)\n",
    "# mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKI_1_df = (processed[processed['outcome']==1])\n",
    "# AKI_0_df = (processed[processed['outcome']==0])\n",
    "\n",
    "# columns = ['egfr_epi_scr_max', 'egfr_mdrd_scr_max','creatinine_max','creatinine_min']\n",
    "\n",
    "\n",
    "\n",
    "# dfwiz_compare(AKI_1_df, AKI_0_df, columns=columns, label = ['AKi_1', 'AKI_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKI_1_df.hospital_expire_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKI_0_df.hospital_expire_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "    'aki_kdigo_grade_1',\n",
    "    'aki_mkdigo_grade_1',\n",
    "\n",
    "    'aki_kdigo_grade_2',\n",
    "    'aki_mkdigo_grade_2',\n",
    "\n",
    "    'aki_kdigo_grade_3',\n",
    "    'aki_mkdigo_grade_3',\n",
    "    'is_mdrd',\n",
    "    'hospital_expire_flag'\n",
    "\n",
    "]\n",
    " \n",
    "select_y = ['outcome']\n",
    "\n",
    "processed_X = processed.pipe(filter_regex, drop_X+select_y)\n",
    "processed_Y = processed.filter(regex='|'.join(select_y))\n",
    "raw_Y = data_num.pipe(replace_inf).pipe(drop_empty).filter(regex='|'.join(select_y)).pipe(remove_outliers)\n",
    "df_y = raw_Y[select_y]\n",
    "\n",
    "\n",
    "df_X, df_y = match(processed_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.female.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_X, df_y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_0, X_valid, y_train_0, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y) # \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_0, y_train_0, test_size=0.25, random_state=42, shuffle=True, stratify=y_train_0) #0.25 *0.8 = 0.2 for test and 0.75*0.8 = 0.60 for train\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train.copy()\n",
    "y_train_copy = y_train.copy()\n",
    "\n",
    "train_df = pd.merge(X_train_copy, y_train_copy, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "train_df.drop([col for col in train_df.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "processed_copy = processed2.copy()\n",
    "processed_copy = pd.merge(processed_copy, train_df, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "processed_copy.drop([col for col in processed_copy.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AKI_1_df = (processed_copy[processed_copy['outcome']==1])\n",
    "AKI_0_df = (processed_copy[processed_copy['outcome']==0])\n",
    "\n",
    "columns = ['egfr_epi_scr_max', 'egfr_mdrd_scr_max','creatinine_max','creatinine_min']\n",
    "\n",
    "\n",
    "\n",
    "dfwiz_compare(AKI_1_df, AKI_0_df, columns=columns, label = ['AKi_1', 'AKI_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_1_df.hospital_expire_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_1_df.query(\"hospital_expire_flag==1\").shape[0]/AKI_1_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_0_df.hospital_expire_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_0_df.query(\"hospital_expire_flag==1\").shape[0]/AKI_0_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = df_X, df_y\n",
    "# X_train, y_train = up_sample(X_train, y_train,'outcome')\n",
    "X_train,  y_train = [\n",
    "    df.reset_index(drop=True)\n",
    "    for df in up_sample(X_train, y_train,'outcome')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# rus = RandomUnderSampler(random_state=42, sampling_strategy='auto')\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfwiz_compare(X_train,X_test, label=['df_train','df_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.query(\"outcome==1\").sum()/df_y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm  # standard alias\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "('scaler', MinMaxScaler()),\n",
    "('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "('model', lgbm.LGBMClassifier(n_jobs=-1, n_estimators=300))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Cross validation search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### **************************************8\n",
    "# # Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "\n",
    "\n",
    "# param_grid ={'model__num_leaves': [6, 10, 20, 50], \n",
    "#              'model__min_child_samples': [100, 200, 300, 400, 500], \n",
    "#              'model__min_child_weight': [1e-5,  1e-2,  1,  1e2,  1e4],\n",
    "#              'model__subsample' : [0.2, 0.5, 0.8], \n",
    "#              'model__reg_alpha': [0, 1e-1, 1, 5,  10, 50, 100],\n",
    "#              'model__reg_lambda': [0, 1e-1, 1,  10,  50, 100]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# score, best_params, pipeline_final = param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True)\n",
    "\n",
    "# # dump(pipeline_final , open('pipeline_final_LGBM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgbm  # standard alias\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# # ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan, sample_posterior=True)),\n",
    "# ('model', lgbm.LGBMClassifier(n_jobs=-1))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt import BayesSearchCV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# bayes_cv_tuner = BayesSearchCV(\n",
    "#     estimator = pipe\n",
    "#     ,search_spaces = {\n",
    "#         'model__n_estimators': (100,200,300,400),\n",
    "#         'model__num_leaves': (6, 10, 20, 50), \n",
    "#         'model__min_child_samples': (100, 200, 300, 400, 500), \n",
    "#         'model__min_child_weight': (1e-5,  1e-2,  1,  1e2,  1e4),\n",
    "#         'model__subsample' : (0.2, 0.5, 0.8), \n",
    "#         'model__reg_alpha': (0, 1e-1, 1, 5,  10, 50, 100),\n",
    "#         'model__reg_lambda': (0, 1e-1, 1,  10,  50, 100)\n",
    "\n",
    "#     }, \n",
    "#     cv = StratifiedKFold(\n",
    "#         n_splits=5,\n",
    "#         shuffle=True,\n",
    "#     ),\n",
    "#     # cv=3,\n",
    "#     n_jobs = 3,\n",
    "#     n_iter = 10,   \n",
    "#     verbose = 0,\n",
    "#     scoring='f1'\n",
    "# )\n",
    "\n",
    "# sample_ratio = 0.1\n",
    "# n_samples = int(len(X_train)*sample_ratio)\n",
    "# X, y = resample(X_train.values, y_train.values, n_samples=n_samples, stratify=y_train.values, random_state=10)\n",
    "# result = bayes_cv_tuner.fit(X, y.ravel())\n",
    "# # print(result.score(X_test, y_test))\n",
    "# print(result.best_params_)\n",
    "# print(result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Fitting Pipeline one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params = {'model__num_leaves': 20, 'model__min_child_samples': 100, 'model__min_child_weight': 0.01, 'model__subsample': 0.8, 'model__reg_alpha': 0, 'model__reg_lambda': 0.1}\n",
    "# best_params = {'model__n_estimators': 400,'model__num_leaves': 20, 'model__min_child_samples': 300, 'model__min_child_weight': 0.01, 'model__subsample': 0.2, 'model__reg_alpha': 1, 'model__reg_lambda': 50}\n",
    "# best_params = {'model__min_child_samples': 300, 'model__min_child_weight': 1, 'model__n_estimators': 400, 'model__num_leaves': 20, 'model__reg_alpha': 1.0, 'model__reg_lambda': 50, 'model__subsample': 0.2}\n",
    "best_params = {'model__n_estimators': 400,'model__num_leaves': 50, 'model__min_child_samples': 100, 'model__min_child_weight': 1, 'model__subsample': 0.2, 'model__reg_alpha': 50, 'model__reg_lambda': 0}\n",
    "# Or get parameters from search above\n",
    "best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train)*sample_ratio)\n",
    "X, y = resample(X_train.values, y_train.outcome.values, n_samples=n_samples, stratify=y_train.values, random_state=10)\n",
    "pipeline_final = copy.deepcopy(pipe)\n",
    "pipeline_final.set_params(**best_params2)\n",
    "pipeline_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(pipeline_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = pipeline_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "clf_threshold = 0.46\n",
    "\n",
    "X,y = X_valid.values, y_valid.values\n",
    "\n",
    "y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= clf_threshold).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "def scale_impute(df, pipe):\n",
    "    data_scaled = pipe.named_steps['scaler'].transform(df)\n",
    "    df_scaled = pd.DataFrame(data_scaled, columns=df.columns)\n",
    "    data_imputed = pipe.named_steps['imputer'].transform(df_scaled)\n",
    "    df_result = pd.DataFrame(data_imputed, columns=df.columns)\n",
    "    return df_result\n",
    "\n",
    "X_train_copy = X_train.copy()\n",
    "y_train_copy = y_train.copy()\n",
    "\n",
    "X_train_copy = scale_impute(X_train_copy, pipeline_final)\n",
    "\n",
    "\n",
    "X_MI = np.array(X_train_copy[['creatinine_max','egfr_epi_scr_max']])\n",
    "y_MI = np.array(y_train_copy.outcome)\n",
    "\n",
    "mi = mutual_info_classif(X_MI,y_MI)\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_kappa_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_XGB_grade123, tpr_XGB_grade123, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "%store fpr_XGB_grade123\n",
    "%store tpr_XGB_grade123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r fpr_RF_grade123\n",
    "%store -r tpr_RF_grade123\n",
    "\n",
    "%store -r fpr_ANN_grade123\n",
    "%store -r tpr_ANN_grade123\n",
    "\n",
    "%store -r fpr_LR_grade123\n",
    "%store -r tpr_LR_grade123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (7.5,6)\n",
    "plt.rcParams[\"figure.figsize\"] = (9,8)\n",
    "mpl.rcParams['lines.linewidth'] = 1.5\n",
    "plt.plot(fpr_XGB_grade123,tpr_XGB_grade123,label=\"XGB (AUC=0.90)\")\n",
    "plt.plot(fpr_RF_grade123,tpr_RF_grade123,label=\"RF    (AUC=0.88)\")\n",
    "plt.plot(fpr_LR_grade123,tpr_LR_grade123,label=\"LR    (AUC=0.87)\")\n",
    "plt.plot(fpr_ANN_grade123,tpr_ANN_grade123,label=\"ANN (AUC=0.86)\")\n",
    "plt.plot([0, 1], [0, 1], marker=\".\", alpha=0.4)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator = pipeline_final._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = final_estimator.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,20)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_impute(df, pipe):\n",
    "    data_scaled = pipe.named_steps['scaler'].transform(df)\n",
    "    df_scaled = pd.DataFrame(data_scaled, columns=df.columns)\n",
    "    data_imputed = pipe.named_steps['imputer'].transform(df_scaled)\n",
    "    df_result = pd.DataFrame(data_imputed, columns=df.columns)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "exp = dx.Explainer(pipeline_final, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_parts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number = 1\n",
    "exp.predict_parts(X_test.iloc[[row_number]], N=100).plot(min_max=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_t = scale_impute_via_pipeline(df=X_test,pipe=pipeline_final)\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(final_estimator)\n",
    "shap_values = explainer.shap_values(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.temperature_min.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.temperature_min.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"age\",shap_values[1], X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_t = scale_impute_via_pipeline(X_train, pipeline_final)\n",
    "shap.initjs()\n",
    "# X_sampled = df_X_train_imp.sample(100, random_state=10)\n",
    "explainer = shap.TreeExplainer(final_estimator)\n",
    "shap_values = explainer.shap_values(X_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"age\",shap_values[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_train_t,max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_t = scale_impute(df=X_test,pipe=pipeline_final)\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(pipeline_final._final_estimator)\n",
    "shap_values = explainer.shap_values(X_test_t)\n",
    "shap.summary_plot(shap_values[1], X_test_t, max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X_train.columns:\n",
    "    shap.dependence_plot(name, shap_values[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHAP values\n",
    "\n",
    "# compute SHAP values\n",
    "X_test_t = scale_impute(df=X_test,pipe=pipeline_final)\n",
    "shap.initjs()\n",
    "explainer = shap.Explainer(pipeline_final._final_estimator, X_test_t)\n",
    "shap_values = explainer(X_test_t,check_additivity=False)\n",
    "shap.plots.beeswarm(shap_values,max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number=1\n",
    "single_observation = X_train.iloc[[row_number]].values[0]\n",
    "X_train_t = scale_impute(df=X_train,pipe=pipeline_final)\n",
    "\n",
    "# data = shap_values.data[row_number]\n",
    "# data = single_observation\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.Explainer(final_estimator,X_train_t, check_additivity=False)\n",
    "# shap_values = explainer(X_train_t)\n",
    "shap_values = explainer(single_observation)\n",
    "\n",
    "\n",
    "\n",
    "class ShapObject:\n",
    "    \n",
    "    def __init__(self, base_values, data, values, feature_names):\n",
    "        self.base_values = base_values # Single value\n",
    "        self.data = data # Raw feature values for 1 row of data\n",
    "        self.values = values # SHAP values for the same row of data\n",
    "        self.feature_names = feature_names # Column names\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "shap_object = ShapObject(base_values = shap_values.base_values[row_number],\n",
    "                         values = shap_values.values[row_number],\n",
    "                         feature_names = single_observation.columns,\n",
    "                         data = single_observation)\n",
    "\n",
    "                         \n",
    "\n",
    "shap.waterfall_plot(shap_object, max_display=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining X_test,y_test and y_pred in one dataset\n",
    "# del(df_test_all)\n",
    "df_test_all = X_test.copy()\n",
    "df_test_all['y_actual'] = y_test\n",
    "df_test_all['y_pred'] = y_pred\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3\n",
    "\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TN = df_test_all[df_test_all.error_category==0]\n",
    "df_FP = df_test_all[df_test_all.error_category==1]\n",
    "\n",
    "df_TP = df_test_all[df_test_all.error_category==2]\n",
    "df_FN = df_test_all[df_test_all.error_category==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "df_TN_shap = df_TN.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "df_TN_shap = scale_impute_via_pipeline(df_TN_shap)\n",
    "shap.initjs()\n",
    "# X_sampled = df_X_train_imp.sample(100, random_state=10)\n",
    "explainer = shap.TreeExplainer(final_estimator)\n",
    "shap_values = explainer.shap_values(df_TN_shap)\n",
    "shap.summary_plot(shap_values[1], df_TN_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "# error_df = {\"df_FP\":df_FP, \"df_FN\":df_FN}\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "    df_shap = scale_impute_via_pipeline(df_shap, final_estimator)\n",
    "\n",
    "    explainer = shap.TreeExplainer(final_estimator)\n",
    "    shap_values = explainer.shap_values(df_shap)\n",
    "    print(\"SHAP: \"+k)\n",
    "    shap.summary_plot(shap_values[1], df_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_processed = processed2.copy()\n",
    "common_FN = pd.merge(df_FN, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "common_FN.drop([col for col in common_FN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "common_FN.aki_kdigo_grade_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FN.aki_kdigo_grade_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FN.aki_kdigo_grade_3.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "exp = dx.Explainer(pipeline_final, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_performance(model_type='classification').plot(geom='roc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_parts().plot(max_vars=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number = 1\n",
    "exp.predict_parts(X_test.iloc[[row_number]], N=100).plot(min_max=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[[row_number]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[row_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "# error_df = {\"df_FP\":df_FP, \"df_FN\":df_FN}\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "\n",
    "    row_number = 1\n",
    "    print(\"SHAP: \"+k)\n",
    "    exp.predict_parts(df_shap.iloc[[row_number]], N=100).plot(min_max=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap.iloc[[281]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break-down plot using Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "rand_list = random.sample(range(0, df_FP.shape[0]), 10)\n",
    "\n",
    "clf_threshold = 0.38\n",
    "import dalex as dx\n",
    "\n",
    "# error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "error_df = {\"df_FP\":df_FP}\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "\n",
    "    for row_number in rand_list:\n",
    "        print(\"Using DALEX on false positive instance with row number: \"+str(row_number))\n",
    "        exp.predict_parts(df_shap.iloc[[row_number]], N=100).plot(min_max=[0,1], max_vars=30, baseline=clf_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP plot using Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "rand_list = random.sample(range(0, df_FP.shape[0]), 10)\n",
    "\n",
    "clf_threshold = 0.38\n",
    "import dalex as dx\n",
    "\n",
    "# error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "error_df = {\"df_FP\":df_FP}\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "\n",
    "    for row_number in rand_list:\n",
    "        print(\"Using DALEX SHAP on false positive instance with row number: \"+str(row_number))\n",
    "        exp.predict_parts(df_shap.iloc[[row_number]], N=100, type='shap').plot(min_max=[0,1], max_vars=30, baseline=clf_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP.creatinine_max.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TN.creatinine_min.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "rand_list = random.sample(range(0, df_TN.shape[0]), 10)\n",
    "\n",
    "\n",
    "import dalex as dx\n",
    "\n",
    "# error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "error_df = {\"df_TN\":df_TN}\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "\n",
    "    for row_number in rand_list:\n",
    "        print(\"Using DALEX on true negative instance with row number: \"+str(row_number))\n",
    "        exp.predict_parts(df_shap.iloc[[row_number]], N=100).plot(min_max=[0,1], max_vars=30, baseline=clf_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the DataFrames\n",
    "# common_processed = processed2.copy()\n",
    "common_processed = processed.copy()\n",
    "common_FP = pd.merge(df_FP, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FP.drop([col for col in common_FP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TN = pd.merge(df_TN, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TN.drop([col for col in common_TN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TP = pd.merge(df_TP, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TP.drop([col for col in common_TP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_FN = pd.merge(df_FN, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FN.drop([col for col in common_FN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_test_all = pd.merge(df_test_all, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_test_all.drop([col for col in common_test_all.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FP.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FP, kind=\"hex\", joint_kws={'color':'#66ffcc'})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<60].shape[0])/(common_FP.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<60].shape[0])/(processed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_TN[common_TN.egfr_epi_scr<60].shape[0])/(common_TN.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<60].shape[0])/(processed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TP, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr_max\", y=\"age\", data=common_FN, kind=\"hex\", joint_kws={'color':\"#ffe6ff\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FP, kind=\"hex\", joint_kws={'color':'#66ffcc'})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hist2d(common_FP.egfr_epi_scr, common_FP.age, bins=[x_bins, y_bins])\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hexbin(common_FP.egfr_epi_scr, common_FP.age, bins=50)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(common_FP.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=common_FP, x=col, bins=50, stat='percent', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for True negative and  False positive and compare their distribution.\n",
    "# It plots the distribution and prints Jensen-Shanon distance.\n",
    "# from functions_compare_distribution import compare_hist_df\n",
    "from dfwiz import dfwiz, dfwiz_compare\n",
    "# healthy patients\n",
    "TN = df_test_all.query(\"error_category == 0\")[X_test.columns] # True negative\n",
    "FP = df_test_all.query(\"error_category == 1\")[X_test.columns] # False positive\n",
    "\n",
    "if len(TN) == 0 or len(FP) == 0:\n",
    "    print(\"Error! one of the dataframes are empty\")\n",
    "else:\n",
    "    # compare_hist_df(TN, FP) # plot distributions and output Jensen-Shanon distance.\n",
    "    dfwiz_compare(FP, TN,label=['FP', 'TN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.kdeplot(data=df_test_all, x=col, hue='error_category', bins=50, stat='density', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', common_norm=False, bins=50, stat=\"percent\");\n",
    "    plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_FP, x=df_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"density\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', bins=len(df_test_all), stat='density', element=\"step\", fill=False, cumulative=True,common_norm=False);\n",
    "    plt.title(\"Cumulative distribution function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree on validation set to differentiate between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "del(df_test_all)\n",
    "\n",
    "\n",
    "# X_test_scaled_array = pipeline_final.named_steps['scaler'].transform(X_test)\n",
    "# X_test_scaled = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "# X_test_imp_array = pipeline_final.named_steps['imputer'].transform(X_test_scaled)\n",
    "# df_test_all = pd.DataFrame(X_test_imp_array, columns=X_test.columns)\n",
    "\n",
    "\n",
    "X_test_imp_array = pipeline_final.named_steps['imputer'].transform(X_test)\n",
    "df_test_all = pd.DataFrame(X_test_imp_array, columns=X_test.columns)\n",
    "\n",
    "\n",
    "# df_test_all['y_actual'] = y_valid.values.ravel()\n",
    "df_test_all['y_actual'] = y_test.values.ravel()\n",
    "df_test_all['y_pred'] = y_pred\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP_TN = df_test_all.loc[(df_test_all['error_category'] == 0) | (df_test_all['error_category'] == 1)]\n",
    "df_FP_FN = df_test_all.loc[(df_test_all['error_category'] == 1) | (df_test_all['error_category'] == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP_TN.error_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP_FN.error_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP']\n",
    "df1 = df_FP_TN.copy()\n",
    "X1 = df1[X_test.columns]\n",
    "X1\n",
    "y1 =  df1[['error_category']]\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 5 , class_weight='balanced', random_state=42, criterion=\"gini\", min_impurity_decrease = 0.01)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "plt.figure(figsize=(20,12))\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = list(X1.columns), \n",
    "               rounded=True, \n",
    "               filled = True,\n",
    "               proportion = True,\n",
    "               class_names = class_names);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['FP', 'FN']\n",
    "df1 = df_FP_FN.copy()\n",
    "X1 = df1[X_test.columns]\n",
    "X1\n",
    "y1 =  df1[['error_category']]\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 5 , class_weight='balanced', random_state=42, criterion=\"gini\", min_impurity_decrease = 0.01)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "plt.figure(figsize=(20,12))\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = list(X1.columns), \n",
    "               rounded=True, \n",
    "               filled = True,\n",
    "               proportion = True,\n",
    "               class_names = class_names);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.loc[~(y_error_t==1)]\n",
    "y_train_new = y_train.loc[~(y_error_t==1)]\n",
    "\n",
    "X_valid_new = X_valid.loc[~(y_error_v==1)]\n",
    "y_valid_new = y_valid.loc[~(y_error_v==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new, y_train_new = up_sample(X_train_new, y_train_new,'outcome')\n",
    "X_train_new, y_train_new = up_sample(X_train, y_train,'outcome')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7ea45291871ad6e398ab50f9f84dad559e0de667f49db4aea6ebf0e175149ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
