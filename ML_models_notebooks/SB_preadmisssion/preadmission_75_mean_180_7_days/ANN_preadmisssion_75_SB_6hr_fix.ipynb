{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/src')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "from dfwiz import dfwiz\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from utils.vis import spy, look, plot_nunique, plot_dists\n",
    "from utils.processing import sort, impute, replace_inf, drop_empty, select, drop_by_nunique, scale, melt, unmelt, \\\n",
    "                             remove_outliers, get_categories, filter_categorical, onehot, filter_regex, match, cap,get_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables representing experiment parameters\n",
    "EXPERIMENT = 'Processing Demo'\n",
    "IMPUTE_NUM = 'constant'\n",
    "IMPUTE_CAT = 'other'\n",
    "FIGSIZE    = [12,3]\n",
    "\n",
    "# parameter dict\n",
    "params = {\n",
    "    'experiment':EXPERIMENT,\n",
    "    'figsize'   :FIGSIZE,\n",
    "    'impute_num':IMPUTE_NUM,\n",
    "    'impute_cat':IMPUTE_CAT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy as sp\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn')\n",
    "sns.set_theme(style=\"ticks\")\n",
    "mpl.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "# Title\n",
    "mpl.rcParams['figure.titlesize'] = 22\n",
    "mpl.rcParams['figure.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlesize'] = 22\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlepad'] = 20\n",
    "\n",
    "# Axes labels\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "\n",
    "# Grid and thicks\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['axes.grid.axis'] = 'y'\n",
    "#mpl.rcParams['axes.xmargin'] = 0\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "\n",
    "# Legend\n",
    "mpl.rcParams['legend.facecolor'] = 'w'\n",
    "mpl.rcParams['legend.title_fontsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['legend.frameon'] = True\n",
    "mpl.rcParams['legend.framealpha'] = 1\n",
    "mpl.rcParams['legend.fancybox'] = True\n",
    "mpl.rcParams['legend.facecolor'] = 'white'\n",
    "mpl.rcParams['legend.edgecolor'] = 'blue'\n",
    "mpl.rcParams['legend.borderpad'] = 0.6\n",
    "\n",
    "# Other\n",
    "mpl.rcParams['lines.linewidth'] = 2.5\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['scatter.edgecolors'] = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### upsampler func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "class upsampler(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        return X\n",
    "\n",
    "    def sample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y[y == 0]], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y[y == 1]], y[y == 1]\n",
    "        else:\n",
    "            print(X[y[y == 0]].shape)\n",
    "            X1, y1 = resample(X[y[y == 1]], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y[y == 0]], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "\n",
    "        return X_out, y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### accuracy func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y, y_pred, y_pred_proba):\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "    score = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.plot(fpr,tpr,label=\"AUC=\"+str(round(score,2)))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    # print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "    cr = classification_report(y, y_pred)\n",
    "    print(\"\\r\\n\"+\"Classification report\"+\"\\r\\n\")\n",
    "    print(cr)\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    print(\"\\r\\n\"+\"Specificity\"+\"\\r\\n\")\n",
    "    print(round(specificity,2))\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def up_sample(X_train_raw, y_train_raw,col_name):\n",
    "\n",
    "    # upsampling X_train and y_train\n",
    "    df_upsampled = pd.merge(X_train_raw, y_train_raw, left_index=True, right_index=True)\n",
    "\n",
    "    X_minority = df_upsampled[df_upsampled[col_name]==1]\n",
    "    X_majority = df_upsampled[df_upsampled[col_name]!=1]\n",
    "\n",
    "    n_samples = X_majority.shape[0]\n",
    "    X_minority_upsampled = resample(X_minority,\n",
    "                                    replace=True,     # sample with replacement\n",
    "                                    n_samples=n_samples,    # to match majority class\n",
    "                                    random_state=42) # reproducible results\n",
    "\n",
    "    df_upsampled = pd.concat([X_majority, X_minority_upsampled]).sample(frac=1)\n",
    "\n",
    "    y_train_out = df_upsampled[[col_name]]\n",
    "    X_train_out = df_upsampled.drop([col_name], axis=1)\n",
    "\n",
    "    return X_train_out, y_train_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### define cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "def param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 5, sample_ratio = 0.2, refit=True, use_error=True, multi_class=False, average_metric='macro'):\n",
    "\n",
    "    print(\"This search selects lower indexes of search list if their score is within the error of maximum score.\")\n",
    "    print(\"Putting parameters for less complicated model on the left side of the grid lists leads to better generalisation. \")\n",
    "    print(\" \")\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    n_train = int(sample_ratio * len(y_train))\n",
    "    X_train_s, y_train_s  = resample(X_train, y_train, n_samples=n_train, stratify=y_train)\n",
    "\n",
    "    best_score = {}\n",
    "    best_params = {}\n",
    "    for k, v in param_grid.items():\n",
    "        # best_params[k] = v[int(len(v)/2)-1]\n",
    "        best_params[k] = v[0]\n",
    "    best_params_m1 = best_params.copy()\n",
    "    print(\"start_params:\", best_params)\n",
    "\n",
    "    score = {}\n",
    "    score_std = {}\n",
    "\n",
    "    for i_iter in range(max_iter):\n",
    "        print(\"_\"*100)\n",
    "        print(\"Iteration\", i_iter)\n",
    "\n",
    "        for k, v in param_grid.items():\n",
    "\n",
    "            best_params1 = best_params.copy()\n",
    "            del best_params1[k]  \n",
    "\n",
    "            score[k] = v.copy()\n",
    "            score_std[k] = v.copy()\n",
    "\n",
    "            for i_param, val_param in enumerate(v):\n",
    "                cv_sc = np.zeros(cv)\n",
    "\n",
    "                for i_cv in range(cv):\n",
    "\n",
    "                    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train_s, y_train_s, test_size=0.2, stratify=y_train_s, shuffle=True) # 80% training and 20% test\n",
    "\n",
    "                    p1 = copy.deepcopy(pipe)\n",
    "                    p1.set_params(**best_params1)\n",
    "                    params2 = {k:val_param}\n",
    "                    p1.set_params(**params2)\n",
    "\n",
    "                    p1.fit(X_train2, y_train2.ravel())\n",
    "                    # X,y = p1.named_steps['resample'].fit_resample(X_test2, y_test2)\n",
    "                    X,y = X_test2, y_test2\n",
    "                    # y_pred_proba = p1.predict_proba(X)\n",
    "                    # cv_sc[i_cv] = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "                    y_pred = p1.predict(X)\n",
    "                    if(multi_class):\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred, average=average_metric)\n",
    "                    else:\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred)\n",
    "\n",
    "                    i_cv = i_cv + 1\n",
    "\n",
    "                score[k][i_param] = cv_sc.mean()\n",
    "                score_std[k][i_param] = cv_sc.std()\n",
    "\n",
    "            print(\"\")\n",
    "            print(k)\n",
    "            print(v)\n",
    "            print(score[k])\n",
    "\n",
    "            best_params[k] = v[np.argmax(score[k])]\n",
    "            best_score[k] = score[k][np.argmax(score[k])]\n",
    "\n",
    "            if use_error:\n",
    "                for i_b in  range(np.argmax(score[k]),-1,-1):\n",
    "                    err1 = (score_std[k][i_b] + score_std[k][v.index(best_params[k])] ) / 4\n",
    "                    # print(\"err1\")\n",
    "                    max_del = max(score[k]) - err1\n",
    "                    # print( i_b, score[k][i_b], max(score[k]), err1, max_del )\n",
    "                    if score[k][i_b] >= max_del:\n",
    "                        best_params[k] = v[i_b]\n",
    "                        best_score[k] = score[k][i_b]\n",
    "\n",
    "            print(\"best_param:\",  v[np.argmax(score[k])], \"score:\", max(score[k]))\n",
    "            print(\"selected_param:\",  best_params[k], \"score:\", best_score[k])\n",
    "            \n",
    "\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"best_params =\", best_params)\n",
    "        print(\"\")\n",
    "        if best_params_m1 == best_params:\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "            print(\"Early stop. No improvement in the last iteration.\")\n",
    "            break\n",
    "        best_params_m1 = best_params.copy()\n",
    "\n",
    "    param_graph_plot(score)\n",
    "\n",
    "    if refit:\n",
    "        print(\"Refitting final model...\")\n",
    "        model_final = copy.deepcopy(pipe)\n",
    "        model_final.set_params(**best_params)\n",
    "        model_final.fit(X_train, y_train.values.ravel())\n",
    "    else:\n",
    "        model_final = None\n",
    "\n",
    "    return score, best_params, model_final\n",
    "    \n",
    "\n",
    "def param_graph_plot(score):\n",
    "    ax = {}\n",
    "    fig = {}\n",
    "    for i, (k, v) in enumerate(score.items()):\n",
    "        fig[k], ax[k] = plt.subplots()\n",
    "\n",
    "    for k, v in score.items():\n",
    "        x = score[k]\n",
    "        y = v\n",
    "        ax[k].plot(x,y,\"-o\", label=\"Score\")\n",
    "        # ax[k].set_ylim([0.5, 1])\n",
    "        ax[k].set_title(k)\n",
    "        ax[k].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Define upsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "class upsampler(BaseEstimator): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def fit_resample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).ravel()\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y == 0], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y == 1], y[y == 1]\n",
    "        else:\n",
    "            X1, y1 = resample(X[y == 1], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y == 0], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "        return X_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Load data and select index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table from database\n",
    "# database = \"data.sqlite\"\n",
    "# con = sqlite3.connect(database)\n",
    "\n",
    "# X_train = pd.read_sql_query(\"SELECT * from X_train\", con)\n",
    "# y_train = pd.read_sql_query(\"SELECT * from y_train\", con)\n",
    "# # select index\n",
    "# index_c = ['USUBJID'] # empty list for no index\n",
    "# X_train = X_train.set_index(index_c)\n",
    "# y_train = y_train.set_index(index_c)\n",
    "\n",
    "# X_train1 = X_train[~X_train.scr_umol_l.isna()]\n",
    "# y_train1 = y_train[~X_train.scr_umol_l.isna()]\n",
    "\n",
    "# X_test = pd.read_sql_query(\"SELECT * from X_test\", con)\n",
    "# y_test = pd.read_sql_query(\"SELECT * from y_test\", con)\n",
    "# # select index\n",
    "# index_c = ['USUBJID'] # empty list for no index\n",
    "# X_test = X_test.set_index(index_c)\n",
    "# y_test = y_test.set_index(index_c)\n",
    "\n",
    "# y_test = y_test[~X_test.scr_umol_l.isna()]\n",
    "# X_test = X_test[~X_test.scr_umol_l.isna()]\n",
    "\n",
    "\n",
    "# X_train, y_train  = resample(X_train, y_train, n_samples=5000, stratify=y_train)\n",
    "# X_test, y_test  = resample(X_test, y_test, n_samples=1000, stratify=y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "sqluser = 'uqhkamel'\n",
    "dbname = 'mimiciv'\n",
    "schema_name = 'mimic_derived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to {}'.format(schema_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select * from all_scr_preadmission_75_JOIN\"\n",
    "# data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id','hadm_id'])\n",
    "\n",
    "query = \"select * from all_scr_preadmission_75_JOIN_6hr_fix\"\n",
    "data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id'])\n",
    "data.drop('hadm_id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ethnicity'] = data['ethnicity'].replace(['OTHER'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNKNOWN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['AMERICAN INDIAN/ALASKA NATIVE'],np.nan)\n",
    "\n",
    "data = data.fillna(value=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data[\"min_day_rrt_present\"]<=1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aki_kdigo = ['aki_kdigo_grade_1','aki_kdigo_grade_2','aki_kdigo_grade_3']\n",
    "\n",
    "# outcome_var = ['day_detection_kdigo_grade_1','day_detection_kdigo_grade_2','day_detection_kdigo_grade_3']\n",
    "\n",
    "# outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "outcome_var = ['day_detection_kdigo_grade_1']\n",
    "\n",
    "first_24h = 1\n",
    "data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = []\n",
    "outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "first_24h = 1\n",
    "data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2276, 111)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"ckd\"]==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['ckd']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 111)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"kidney_transplant\"]==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['kidney_transplant']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data['egfr_mdrd_scr']>60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28030, 111)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aki_kdigo_grade_1</th>\n",
       "      <th>aki_kdigo_grade_2</th>\n",
       "      <th>aki_kdigo_grade_3</th>\n",
       "      <th>day_detection_kdigo_grade_1</th>\n",
       "      <th>day_detection_kdigo_grade_2</th>\n",
       "      <th>day_detection_kdigo_grade_3</th>\n",
       "      <th>aki_mkdigo_grade_1</th>\n",
       "      <th>aki_mkdigo_grade_2</th>\n",
       "      <th>aki_mkdigo_grade_3</th>\n",
       "      <th>day_detection_mkdigo_grade_1</th>\n",
       "      <th>day_detection_mkdigo_grade_2</th>\n",
       "      <th>day_detection_mkdigo_grade_3</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>ckd</th>\n",
       "      <th>is_mdrd</th>\n",
       "      <th>egfr_epi_scr</th>\n",
       "      <th>egfr_mdrd_scr</th>\n",
       "      <th>kidney_transplant</th>\n",
       "      <th>congestive_heart_failure</th>\n",
       "      <th>diabetes_type2</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>obesity_icd</th>\n",
       "      <th>peripheral_vascular_disease</th>\n",
       "      <th>chronic_liver_disease</th>\n",
       "      <th>mild_liver_disease</th>\n",
       "      <th>severe_liver_disease</th>\n",
       "      <th>myocardial_infarct</th>\n",
       "      <th>chronic_pulmonary_disease</th>\n",
       "      <th>chronic_heart_failure</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>hemoglobin_min</th>\n",
       "      <th>hemoglobin_max</th>\n",
       "      <th>platelets_min</th>\n",
       "      <th>platelets_max</th>\n",
       "      <th>wbc_min</th>\n",
       "      <th>wbc_max</th>\n",
       "      <th>wbc_bd_min</th>\n",
       "      <th>wbc_bd_max</th>\n",
       "      <th>albumin_min</th>\n",
       "      <th>albumin_max</th>\n",
       "      <th>globulin_min</th>\n",
       "      <th>globulin_max</th>\n",
       "      <th>total_protein_min</th>\n",
       "      <th>total_protein_max</th>\n",
       "      <th>aniongap_min</th>\n",
       "      <th>aniongap_max</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>bun_min</th>\n",
       "      <th>bun_max</th>\n",
       "      <th>calcium_min</th>\n",
       "      <th>calcium_max</th>\n",
       "      <th>chloride_min</th>\n",
       "      <th>chloride_max</th>\n",
       "      <th>creatinine_min</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>glucose_min</th>\n",
       "      <th>glucose_max</th>\n",
       "      <th>sodium_min</th>\n",
       "      <th>sodium_max</th>\n",
       "      <th>potassium_min</th>\n",
       "      <th>potassium_max</th>\n",
       "      <th>pt_min</th>\n",
       "      <th>pt_max</th>\n",
       "      <th>thrombin_min</th>\n",
       "      <th>thrombin_max</th>\n",
       "      <th>ptt_min</th>\n",
       "      <th>ptt_max</th>\n",
       "      <th>inr_min</th>\n",
       "      <th>inr_max</th>\n",
       "      <th>bilirubin_total_min</th>\n",
       "      <th>bilirubin_total_max</th>\n",
       "      <th>egfr_epi_scr_max</th>\n",
       "      <th>egfr_mdrd_scr_max</th>\n",
       "      <th>heart_rate_min</th>\n",
       "      <th>heart_rate_max</th>\n",
       "      <th>heart_rate_mean</th>\n",
       "      <th>sbp_min</th>\n",
       "      <th>sbp_max</th>\n",
       "      <th>sbp_mean</th>\n",
       "      <th>dbp_min</th>\n",
       "      <th>dbp_max</th>\n",
       "      <th>dbp_mean</th>\n",
       "      <th>resp_rate_min</th>\n",
       "      <th>resp_rate_max</th>\n",
       "      <th>resp_rate_mean</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>arbs_acei</th>\n",
       "      <th>cyclosporine</th>\n",
       "      <th>bmi</th>\n",
       "      <th>urineoutput_24hr</th>\n",
       "      <th>supplemental_oxygen</th>\n",
       "      <th>invasive_vent</th>\n",
       "      <th>hfnc</th>\n",
       "      <th>non_invasive_vent</th>\n",
       "      <th>tracheostomy</th>\n",
       "      <th>min_day_rrt_present</th>\n",
       "      <th>min_day_rrt_active</th>\n",
       "      <th>weight_admit</th>\n",
       "      <th>weight_min</th>\n",
       "      <th>weight_max</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30283046</th>\n",
       "      <th>10777271</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>179.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>15.3</td>\n",
       "      <td>13.6</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.7</td>\n",
       "      <td>32.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>90.150000</td>\n",
       "      <td>111.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>118.550000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.904762</td>\n",
       "      <td>37.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>37.568750</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>83.5</td>\n",
       "      <td>83.5</td>\n",
       "      <td>83.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36223916</th>\n",
       "      <th>10135398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>39.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.3</td>\n",
       "      <td>135.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>135.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.3</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>103.640000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>133.037037</td>\n",
       "      <td>47.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>75.444444</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.944444</td>\n",
       "      <td>37.28</td>\n",
       "      <td>38.39</td>\n",
       "      <td>37.843333</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.04</td>\n",
       "      <td>675.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>87.3</td>\n",
       "      <td>87.3</td>\n",
       "      <td>87.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39625809</th>\n",
       "      <th>19016548</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>194.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>89.387097</td>\n",
       "      <td>88.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>126.965517</td>\n",
       "      <td>31.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>41.724138</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>36.50</td>\n",
       "      <td>39.00</td>\n",
       "      <td>37.701000</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.20</td>\n",
       "      <td>550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>90.3</td>\n",
       "      <td>90.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37944322</th>\n",
       "      <th>12187566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>95.166667</td>\n",
       "      <td>87.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>98.880000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.800000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.680000</td>\n",
       "      <td>35.44</td>\n",
       "      <td>37.22</td>\n",
       "      <td>36.402500</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.73</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>86.5</td>\n",
       "      <td>96.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33754541</th>\n",
       "      <th>19510789</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.2</td>\n",
       "      <td>29.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>68.615385</td>\n",
       "      <td>94.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>120.884615</td>\n",
       "      <td>40.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>52.192308</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.769231</td>\n",
       "      <td>36.78</td>\n",
       "      <td>37.22</td>\n",
       "      <td>36.935000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aki_kdigo_grade_1  aki_kdigo_grade_2  aki_kdigo_grade_3  \\\n",
       "stay_id  subject_id                                                            \n",
       "30283046 10777271                    0                  0                  0   \n",
       "36223916 10135398                    0                  0                  0   \n",
       "39625809 19016548                    1                  0                  0   \n",
       "37944322 12187566                    0                  0                  0   \n",
       "33754541 19510789                    0                  0                  0   \n",
       "\n",
       "                     day_detection_kdigo_grade_1  day_detection_kdigo_grade_2  \\\n",
       "stay_id  subject_id                                                             \n",
       "30283046 10777271                      9999999.0                    9999999.0   \n",
       "36223916 10135398                      9999999.0                    9999999.0   \n",
       "39625809 19016548                            2.0                    9999999.0   \n",
       "37944322 12187566                      9999999.0                    9999999.0   \n",
       "33754541 19510789                      9999999.0                    9999999.0   \n",
       "\n",
       "                     day_detection_kdigo_grade_3  aki_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                                    \n",
       "30283046 10777271                      9999999.0                   1   \n",
       "36223916 10135398                      9999999.0                   1   \n",
       "39625809 19016548                      9999999.0                   1   \n",
       "37944322 12187566                      9999999.0                   0   \n",
       "33754541 19510789                      9999999.0                   0   \n",
       "\n",
       "                     aki_mkdigo_grade_2  aki_mkdigo_grade_3  \\\n",
       "stay_id  subject_id                                           \n",
       "30283046 10777271                     0                   0   \n",
       "36223916 10135398                     0                   0   \n",
       "39625809 19016548                     0                   0   \n",
       "37944322 12187566                     0                   0   \n",
       "33754541 19510789                     0                   0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                 \n",
       "30283046 10777271                             2.0   \n",
       "36223916 10135398                             1.0   \n",
       "39625809 19016548                             2.0   \n",
       "37944322 12187566                       9999999.0   \n",
       "33754541 19510789                       9999999.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_2  \\\n",
       "stay_id  subject_id                                 \n",
       "30283046 10777271                       9999999.0   \n",
       "36223916 10135398                       9999999.0   \n",
       "39625809 19016548                       9999999.0   \n",
       "37944322 12187566                       9999999.0   \n",
       "33754541 19510789                       9999999.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_3   age  female ethnicity  \\\n",
       "stay_id  subject_id                                                         \n",
       "30283046 10777271                       9999999.0  54.0       0       NaN   \n",
       "36223916 10135398                       9999999.0  59.0       0     WHITE   \n",
       "39625809 19016548                       9999999.0  42.0       0       NaN   \n",
       "37944322 12187566                       9999999.0  68.0       1       NaN   \n",
       "33754541 19510789                       9999999.0  85.0       1       NaN   \n",
       "\n",
       "                     ckd  is_mdrd  egfr_epi_scr  egfr_mdrd_scr  \\\n",
       "stay_id  subject_id                                              \n",
       "30283046 10777271      0        1          62.0           58.0   \n",
       "36223916 10135398      0        1          75.0           71.0   \n",
       "39625809 19016548      0        1          67.0           61.0   \n",
       "37944322 12187566      0        1          66.0           62.0   \n",
       "33754541 19510789      0        1          51.0           53.0   \n",
       "\n",
       "                     kidney_transplant  congestive_heart_failure  \\\n",
       "stay_id  subject_id                                                \n",
       "30283046 10777271                    0                         0   \n",
       "36223916 10135398                    0                         0   \n",
       "39625809 19016548                    0                         1   \n",
       "37944322 12187566                    0                         0   \n",
       "33754541 19510789                    0                         0   \n",
       "\n",
       "                     diabetes_type2  chronic_kidney_disease  hypertension  \\\n",
       "stay_id  subject_id                                                         \n",
       "30283046 10777271                 0                       0             1   \n",
       "36223916 10135398                 0                       0             0   \n",
       "39625809 19016548                 1                       0             0   \n",
       "37944322 12187566                 0                       0             1   \n",
       "33754541 19510789                 0                       0             1   \n",
       "\n",
       "                     obesity_icd  peripheral_vascular_disease  \\\n",
       "stay_id  subject_id                                             \n",
       "30283046 10777271              0                            0   \n",
       "36223916 10135398              0                            0   \n",
       "39625809 19016548              0                            0   \n",
       "37944322 12187566              0                            0   \n",
       "33754541 19510789              0                            1   \n",
       "\n",
       "                     chronic_liver_disease  mild_liver_disease  \\\n",
       "stay_id  subject_id                                              \n",
       "30283046 10777271                        0                   0   \n",
       "36223916 10135398                        0                   0   \n",
       "39625809 19016548                        0                   1   \n",
       "37944322 12187566                        0                   0   \n",
       "33754541 19510789                        0                   0   \n",
       "\n",
       "                     severe_liver_disease  myocardial_infarct  \\\n",
       "stay_id  subject_id                                             \n",
       "30283046 10777271                       0                   0   \n",
       "36223916 10135398                       0                   0   \n",
       "39625809 19016548                       0                   1   \n",
       "37944322 12187566                       0                   0   \n",
       "33754541 19510789                       0                   0   \n",
       "\n",
       "                     chronic_pulmonary_disease  chronic_heart_failure  sepsis  \\\n",
       "stay_id  subject_id                                                             \n",
       "30283046 10777271                            0                      0       0   \n",
       "36223916 10135398                            0                      0       0   \n",
       "39625809 19016548                            0                      1       1   \n",
       "37944322 12187566                            0                      0       0   \n",
       "33754541 19510789                            1                      0       0   \n",
       "\n",
       "                     hematocrit_min  hematocrit_max  hemoglobin_min  \\\n",
       "stay_id  subject_id                                                   \n",
       "30283046 10777271              41.0            42.4            13.7   \n",
       "36223916 10135398              30.8            39.2            10.8   \n",
       "39625809 19016548              25.0            25.0             7.9   \n",
       "37944322 12187566              26.0            31.5             8.7   \n",
       "33754541 19510789              37.8            37.8            12.3   \n",
       "\n",
       "                     hemoglobin_max  platelets_min  platelets_max  wbc_min  \\\n",
       "stay_id  subject_id                                                          \n",
       "30283046 10777271              14.7          179.0          204.0     13.6   \n",
       "36223916 10135398              13.3          135.0          185.0      6.8   \n",
       "39625809 19016548               7.9          194.0          194.0      NaN   \n",
       "37944322 12187566              10.6           96.0          143.0     11.0   \n",
       "33754541 19510789              12.3          158.0          158.0      6.7   \n",
       "\n",
       "                     wbc_max  wbc_bd_min  wbc_bd_max  albumin_min  \\\n",
       "stay_id  subject_id                                                 \n",
       "30283046 10777271       15.3        13.6        15.3          3.5   \n",
       "36223916 10135398        9.2         6.8         9.2          4.0   \n",
       "39625809 19016548        NaN         NaN         NaN          NaN   \n",
       "37944322 12187566       17.9        11.0        17.9          NaN   \n",
       "33754541 19510789        6.7         6.7         6.7          NaN   \n",
       "\n",
       "                     albumin_max  globulin_min  globulin_max  \\\n",
       "stay_id  subject_id                                            \n",
       "30283046 10777271            3.5           NaN           NaN   \n",
       "36223916 10135398            4.0           NaN           NaN   \n",
       "39625809 19016548            NaN           NaN           NaN   \n",
       "37944322 12187566            NaN           NaN           NaN   \n",
       "33754541 19510789            NaN           NaN           NaN   \n",
       "\n",
       "                     total_protein_min  total_protein_max  aniongap_min  \\\n",
       "stay_id  subject_id                                                       \n",
       "30283046 10777271                  NaN                NaN          12.0   \n",
       "36223916 10135398                  NaN                NaN          16.0   \n",
       "39625809 19016548                  NaN                NaN          13.0   \n",
       "37944322 12187566                  NaN                NaN           7.0   \n",
       "33754541 19510789                  NaN                NaN          12.0   \n",
       "\n",
       "                     aniongap_max  bicarbonate_min  bicarbonate_max  bun_min  \\\n",
       "stay_id  subject_id                                                            \n",
       "30283046 10777271            14.0             20.0             22.0     10.0   \n",
       "36223916 10135398            23.0             20.0             26.0      7.0   \n",
       "39625809 19016548            13.0             23.0             23.0     55.0   \n",
       "37944322 12187566            12.0             19.0             26.0      8.0   \n",
       "33754541 19510789            12.0             24.0             24.0     22.0   \n",
       "\n",
       "                     bun_max  calcium_min  calcium_max  chloride_min  \\\n",
       "stay_id  subject_id                                                    \n",
       "30283046 10777271       15.0          7.0          8.0         113.0   \n",
       "36223916 10135398        9.0          7.6          8.3         100.0   \n",
       "39625809 19016548       55.0          8.0          8.0          95.0   \n",
       "37944322 12187566       10.0          NaN          NaN         106.0   \n",
       "33754541 19510789       22.0          9.5          9.5         108.0   \n",
       "\n",
       "                     chloride_max  creatinine_min  creatinine_max  \\\n",
       "stay_id  subject_id                                                 \n",
       "30283046 10777271           116.0             1.2             1.3   \n",
       "36223916 10135398           104.0             0.6             0.8   \n",
       "39625809 19016548            95.0             1.0             1.0   \n",
       "37944322 12187566           109.0             0.7             0.9   \n",
       "33754541 19510789           108.0             0.9             0.9   \n",
       "\n",
       "                     glucose_min  glucose_max  sodium_min  sodium_max  \\\n",
       "stay_id  subject_id                                                     \n",
       "30283046 10777271           94.0        151.0       144.0       146.0   \n",
       "36223916 10135398          135.0        185.0       139.0       144.0   \n",
       "39625809 19016548          193.0        193.0       131.0       131.0   \n",
       "37944322 12187566           90.0         90.0       139.0       139.0   \n",
       "33754541 19510789           95.0         95.0       144.0       144.0   \n",
       "\n",
       "                     potassium_min  potassium_max  pt_min  pt_max  \\\n",
       "stay_id  subject_id                                                 \n",
       "30283046 10777271              3.2            3.4    11.3    11.3   \n",
       "36223916 10135398              2.9            3.8    11.0    12.6   \n",
       "39625809 19016548              4.7            4.7    17.7    17.7   \n",
       "37944322 12187566              NaN            NaN    14.1    16.9   \n",
       "33754541 19510789              4.2            4.2    11.0    11.0   \n",
       "\n",
       "                     thrombin_min  thrombin_max  ptt_min  ptt_max  inr_min  \\\n",
       "stay_id  subject_id                                                          \n",
       "30283046 10777271             NaN           NaN     32.7     32.7      1.0   \n",
       "36223916 10135398             NaN           NaN     26.3     27.7      1.0   \n",
       "39625809 19016548             NaN           NaN     30.1     30.1      1.6   \n",
       "37944322 12187566             NaN           NaN     26.0     33.2      1.3   \n",
       "33754541 19510789             NaN           NaN     29.2     29.2      1.0   \n",
       "\n",
       "                     inr_max  bilirubin_total_min  bilirubin_total_max  \\\n",
       "stay_id  subject_id                                                      \n",
       "30283046 10777271        1.0                  0.2                  0.2   \n",
       "36223916 10135398        1.2                  1.3                  1.3   \n",
       "39625809 19016548        1.6                  1.1                  1.1   \n",
       "37944322 12187566        1.6                  NaN                  NaN   \n",
       "33754541 19510789        1.0                  NaN                  NaN   \n",
       "\n",
       "                     egfr_epi_scr_max  egfr_mdrd_scr_max  heart_rate_min  \\\n",
       "stay_id  subject_id                                                        \n",
       "30283046 10777271                62.0               58.0            83.0   \n",
       "36223916 10135398                98.0               99.0            86.0   \n",
       "39625809 19016548                92.0               82.0            71.0   \n",
       "37944322 12187566                66.0               62.0            83.0   \n",
       "33754541 19510789                58.0               60.0            56.0   \n",
       "\n",
       "                     heart_rate_max  heart_rate_mean  sbp_min  sbp_max  \\\n",
       "stay_id  subject_id                                                      \n",
       "30283046 10777271             101.0        90.150000    111.0    143.0   \n",
       "36223916 10135398             127.0       103.640000     85.0    166.0   \n",
       "39625809 19016548             131.0        89.387097     88.0    147.0   \n",
       "37944322 12187566             104.0        95.166667     87.0    127.0   \n",
       "33754541 19510789              79.0        68.615385     94.0    160.0   \n",
       "\n",
       "                       sbp_mean  dbp_min  dbp_max   dbp_mean  resp_rate_min  \\\n",
       "stay_id  subject_id                                                           \n",
       "30283046 10777271    118.550000     62.0    100.0  78.000000           13.0   \n",
       "36223916 10135398    133.037037     47.0    106.0  75.444444           10.0   \n",
       "39625809 19016548    126.965517     31.0     59.0  41.724138           10.0   \n",
       "37944322 12187566     98.880000     57.0     80.0  66.800000           11.0   \n",
       "33754541 19510789    120.884615     40.0    104.0  52.192308           14.0   \n",
       "\n",
       "                     resp_rate_max  resp_rate_mean  temperature_min  \\\n",
       "stay_id  subject_id                                                   \n",
       "30283046 10777271             23.0       16.904762            37.00   \n",
       "36223916 10135398             28.0       15.944444            37.28   \n",
       "39625809 19016548             25.0       23.200000            36.50   \n",
       "37944322 12187566             24.0       17.680000            35.44   \n",
       "33754541 19510789             26.0       17.769231            36.78   \n",
       "\n",
       "                     temperature_max  temperature_mean  spo2_min  spo2_max  \\\n",
       "stay_id  subject_id                                                          \n",
       "30283046 10777271              39.00         37.568750      95.0     100.0   \n",
       "36223916 10135398              38.39         37.843333      91.0     100.0   \n",
       "39625809 19016548              39.00         37.701000      95.0     100.0   \n",
       "37944322 12187566              37.22         36.402500      94.0     100.0   \n",
       "33754541 19510789              37.22         36.935000      93.0      98.0   \n",
       "\n",
       "                     arbs_acei  cyclosporine    bmi  urineoutput_24hr  \\\n",
       "stay_id  subject_id                                                     \n",
       "30283046 10777271            0             0    NaN            1500.0   \n",
       "36223916 10135398            0             0  49.04             675.0   \n",
       "39625809 19016548            1             0  52.20             550.0   \n",
       "37944322 12187566            0             0  53.73             275.0   \n",
       "33754541 19510789            1             0    NaN             400.0   \n",
       "\n",
       "                     supplemental_oxygen  invasive_vent  hfnc  \\\n",
       "stay_id  subject_id                                             \n",
       "30283046 10777271                      0              0     0   \n",
       "36223916 10135398                      0              0     0   \n",
       "39625809 19016548                      0              1     0   \n",
       "37944322 12187566                      1              1     0   \n",
       "33754541 19510789                      0              0     0   \n",
       "\n",
       "                     non_invasive_vent  tracheostomy  min_day_rrt_present  \\\n",
       "stay_id  subject_id                                                         \n",
       "30283046 10777271                    0             0           99999999.0   \n",
       "36223916 10135398                    0             0           99999999.0   \n",
       "39625809 19016548                    0             0           99999999.0   \n",
       "37944322 12187566                    0             0           99999999.0   \n",
       "33754541 19510789                    0             0           99999999.0   \n",
       "\n",
       "                     min_day_rrt_active  weight_admit  weight_min  weight_max  \\\n",
       "stay_id  subject_id                                                             \n",
       "30283046 10777271            99999999.0          83.5        83.5        83.5   \n",
       "36223916 10135398            99999999.0          87.3        87.3        87.3   \n",
       "39625809 19016548            99999999.0          90.3        90.3        90.3   \n",
       "37944322 12187566            99999999.0          86.5        86.5        96.1   \n",
       "33754541 19510789            99999999.0          45.6        45.6        45.6   \n",
       "\n",
       "                     hospital_expire_flag  \n",
       "stay_id  subject_id                        \n",
       "30283046 10777271                       0  \n",
       "36223916 10135398                       0  \n",
       "39625809 19016548                       1  \n",
       "37944322 12187566                       0  \n",
       "33754541 19510789                       0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dropna(axis=1, thresh = int(0.8*data.shape[0]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_window = 3\n",
    "\n",
    "# data.loc[(((data['aki_kdigo_grade_1']== 1)| (data['aki_kdigo_grade_2']== 1) | (data['aki_kdigo_grade_3']==1)) \\\n",
    "#     &( (data['day_detection_kdigo_grade_1']<=prediction_window)| (data['day_detection_kdigo_grade_2']<=prediction_window) | (data['day_detection_kdigo_grade_3']<=prediction_window)) \\\n",
    "#         |(data['min_day_rrt_present']<= prediction_window)), 'outcome'] = 1\n",
    "\n",
    "\n",
    "# data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_window = 3\n",
    "\n",
    "data.loc[(( (data['aki_kdigo_grade_1']== 1)) \\\n",
    "    &( (data['day_detection_kdigo_grade_1']<=prediction_window))), 'outcome'] = 1\n",
    "\n",
    "\n",
    "data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "'day_detection_kdigo_grade_1',\n",
    "'day_detection_kdigo_grade_2',\n",
    "'day_detection_kdigo_grade_3',\n",
    "'day_detection_mkdigo_grade_1',\n",
    "'day_detection_mkdigo_grade_2',\n",
    "'day_detection_mkdigo_grade_3',\n",
    "'min_day_rrt_active',\n",
    "'min_day_rrt_present',\n",
    "'ckd',\n",
    "'chronic_kidney_disease'\n",
    "]\n",
    "# CRP and vomit_nausea as they had mostly empty\n",
    "\n",
    "data.drop(drop_X, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missingness percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.reset_index().drop_duplicates(subset=['stay_id','subject_id','hadm_id']).set_index(['stay_id','subject_id','hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove unpopulated columns\n",
    "# data.pipe(sort)\\\n",
    "#               .pipe(replace_inf).pipe(drop_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by column type\n",
    "data_num = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'numerical')\n",
    "\n",
    "data_cat = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cat = data_cat.pipe(filter_categorical, cutoff=20, plot=False)\\\n",
    "#                                             .pipe(sort).pipe(spy, title='Before onehot', figsize=[12,4])\\\n",
    "#                                             .fillna('other').pipe(onehot)\n",
    "\n",
    "data_cat = data_cat.fillna('other').pipe(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ethnicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>ASIAN</th>\n",
       "      <th>BLACK/AFRICAN AMERICAN</th>\n",
       "      <th>HISPANIC/LATINO</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30000153</th>\n",
       "      <th>12466550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001148</th>\n",
       "      <th>12980335</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001656</th>\n",
       "      <th>19609454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001947</th>\n",
       "      <th>15904173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30002415</th>\n",
       "      <th>17921898</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          len                                               \\\n",
       "variable            ethnicity                                                \n",
       "value                   ASIAN BLACK/AFRICAN AMERICAN HISPANIC/LATINO WHITE   \n",
       "stay_id  subject_id                                                          \n",
       "30000153 12466550           0                      0               0     1   \n",
       "30001148 12980335           0                      0               0     0   \n",
       "30001656 19609454           0                      0               0     1   \n",
       "30001947 15904173           0                      0               0     1   \n",
       "30002415 17921898           0                      0               0     1   \n",
       "\n",
       "                           \n",
       "variable                   \n",
       "value               other  \n",
       "stay_id  subject_id        \n",
       "30000153 12466550       0  \n",
       "30001148 12980335       1  \n",
       "30001656 19609454       0  \n",
       "30001947 15904173       0  \n",
       "30002415 17921898       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pd.merge(data_num, data_cat, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28030, 100)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4259"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.aki_kdigo_grade_1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[processed['is_mdrd']==0].aki_kdigo_grade_1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17995\n",
       "0    10035\n",
       "Name: is_mdrd, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.is_mdrd.value_counts()\n",
    "# processed['is_mdrd'].sum()/len(processed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2 = processed.copy()\n",
    "processed.drop(['egfr_epi_scr','egfr_mdrd_scr'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "    'aki_kdigo_grade_1',\n",
    "    'aki_mkdigo_grade_1',\n",
    "\n",
    "    'aki_kdigo_grade_2',\n",
    "    'aki_mkdigo_grade_2',\n",
    "\n",
    "    'aki_kdigo_grade_3',\n",
    "    'aki_mkdigo_grade_3',\n",
    "\n",
    "    'is_mdrd'\n",
    "\n",
    "]\n",
    " \n",
    "select_y = ['outcome']\n",
    "\n",
    "processed_X = processed.pipe(filter_regex, drop_X+select_y)\n",
    "processed_Y = processed.filter(regex='|'.join(select_y))\n",
    "raw_Y = data_num.pipe(replace_inf).pipe(drop_empty).filter(regex='|'.join(select_y)).pipe(remove_outliers)\n",
    "df_y = raw_Y[select_y]\n",
    "\n",
    "\n",
    "df_X, df_y = match(processed_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28030, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_X, df_y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = df_X, df_y\n",
    "X_train, y_train = up_sample(X_train, y_train,'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# rus = RandomUnderSampler(random_state=42, sampling_strategy='auto')\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0.0        23771\n",
       "1.0         4259\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class tabular_nn_model(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d_in=10, n_epochs=15, batch_size=10, lr = 0.001, drop_out=0, weight_decay=0, early_stop=True, verbose=2):\n",
    "        self.d_in = d_in\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.drop_out = drop_out\n",
    "        self.weight_decay = weight_decay  \n",
    "        self.early_stop = early_stop\n",
    "        self.verbose = verbose  \n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.net(d_in, self.drop_out)\n",
    "        self.model.to(self.device) \n",
    "\n",
    "    class net(nn.Module):\n",
    "        def __init__(self, d_in, drop_out):\n",
    "            super(tabular_nn_model.net, self).__init__()\n",
    "            # Number of input features is D_in.\n",
    "            self.layer_1 = nn.Linear(d_in, 128) \n",
    "            self.layer_2 = nn.Linear(128, 128)\n",
    "            self.layer_3 = nn.Linear(128, 128)\n",
    "            self.layer_4 = nn.Linear(128, 128)\n",
    "            self.layer_out = nn.Linear(128, 2) \n",
    "            \n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(p=drop_out)\n",
    "            self.batchnorm1 = nn.BatchNorm1d(128)\n",
    "            self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "            self.batchnorm3 = nn.BatchNorm1d(128)\n",
    "            self.batchnorm4 = nn.BatchNorm1d(128)\n",
    "\n",
    "            self.sf = nn.Softmax(dim=1)\n",
    "            \n",
    "        def forward(self, inputs):\n",
    "            x = self.relu(self.layer_1(inputs))\n",
    "            x = self.batchnorm1(x)\n",
    "\n",
    "            x = self.relu(self.layer_2(x))\n",
    "            x = self.batchnorm2(x)\n",
    "\n",
    "            x = self.relu(self.layer_3(x))\n",
    "            x = self.batchnorm3(x)\n",
    "\n",
    "            x = self.relu(self.layer_4(x))\n",
    "            x = self.batchnorm4(x)\n",
    "\n",
    "            x = self.dropout(x)\n",
    "            x = self.layer_out(x)\n",
    "            x = self.sf(x)\n",
    "            \n",
    "            return x\n",
    "\n",
    "    def fit(self, X_train, y_train, n_epochs=None):\n",
    "\n",
    "        if n_epochs != None:\n",
    "            self.n_epochs = n_epochs\n",
    "\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "        class TrainData(Dataset):\n",
    "            def __init__(self, X_data, y_data):\n",
    "                self.X_data = X_data\n",
    "                self.y_data = y_data\n",
    "                \n",
    "            def __getitem__(self, index):\n",
    "                return self.X_data[index], self.y_data[index]\n",
    "                \n",
    "            def __len__ (self):\n",
    "                return len(self.X_data)\n",
    "\n",
    "        train_data = TrainData(torch.FloatTensor(X_train), \n",
    "                            torch.FloatTensor(y_train))\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "        self.loss_array = []\n",
    "        for e in range(1, self.n_epochs+1):\n",
    "            epoch_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_pred = self.model(X_batch)\n",
    "                loss = criterion(y_pred,y_batch.long())\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "            if self.verbose == 2:\n",
    "                print(\"epoch:\", e, \", loss:\", epoch_loss/len(train_loader))\n",
    "            self.loss_array.append(epoch_loss/len(train_loader))\n",
    "\n",
    "            if self.early_stop:\n",
    "                n_av = 10\n",
    "                if e > n_av:\n",
    "                    s1 = 0 \n",
    "                    s2 = 0\n",
    "                    for i_l in range(n_av):\n",
    "                        s1 = s1 + self.loss_array[-i_l-1]-self.loss_array[-i_l-2]\n",
    "                        s2 = s2 - abs(self.loss_array[-i_l-1]-self.loss_array[-i_l-2])\n",
    "                    cond1 = s1 > (s2/10.0)\n",
    "                    # print(\"early stop\", s1, s2/10.0)\n",
    "                    if cond1:\n",
    "                        print(\"Early stopping triggered. No. of epochs:\", e)\n",
    "                        break\n",
    "        if self.verbose == 2:\n",
    "            plt.plot(self.loss_array)\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "\n",
    "        if self.verbose == 1:\n",
    "            sample = 5\n",
    "            epoch_s = [0]*sample\n",
    "            loss_s = [0]*sample\n",
    "            l_loss = len(self.loss_array)\n",
    "            for i_s in range(sample-1):\n",
    "                ii = int(i_s/(sample-1)* l_loss)\n",
    "                epoch_s[i_s] = ii+1\n",
    "                loss_s[i_s] = self.loss_array[ii]\n",
    "\n",
    "            epoch_s[i_s+1] = l_loss\n",
    "            loss_s[i_s+1] = self.loss_array[-1]            \n",
    "\n",
    "            print(\"epoch:\", epoch_s)\n",
    "            print(\"loss:\", loss_s)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        y_proba = self.model(torch.from_numpy(X).float()).detach().numpy()\n",
    "        return y_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        y_proba = self.model(torch.from_numpy(X).float()).detach().numpy()\n",
    "        y_pred = (y_proba[:,1] >= 0.5).astype(int)\n",
    "        return y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = len(X_train.iloc[0])\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "('scaler', MinMaxScaler()),\n",
    "('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "('model', tabular_nn_model(d_in=d_in, n_epochs=100, lr=0.01, weight_decay=0, early_stop=True, verbose=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Cross validation search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### **************************************8\n",
    "# # Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "\n",
    "\n",
    "# param_grid ={\n",
    "#             'model__lr' : [0.1, 0.01, 0.001],\n",
    "#             'model__drop_out' : [0.4, 0.25, 0.1, 0.05, 0]\n",
    "#              }\n",
    "\n",
    "\n",
    "\n",
    "# score, best_params, model_final = param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True)\n",
    "\n",
    "# # dump(model_final , open('model_final_rf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Fitting Pipeline one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No. of epochs: 26\n",
      "epoch: [1, 7, 14, 20, 26]\n",
      "loss: [0.6321084951643061, 0.6003976505010787, 0.5939230858010448, 0.5907388547852588, 0.5937211155640716]\n",
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "Train Accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAH0CAYAAACAfgxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABHE0lEQVR4nO3dd3RUdf7G8fekh1QIBKRJkWqClEDoLSACUqUKARRRQFxkxRVRirpUlSIoCtKNigIr4I8A0ssGkCpFmhAgQCDUFJJMMjO/P7KMxARM4EJIeF7neM7MnVs+cw3zzLfcOyabzWZDREREDOGQ0wWIiIjkJQpWERERAylYRUREDKRgFRERMZCCVURExEAKVhGRbEhNTc3pEuQRp2CVx8aNGzeYMWMGXbt2JTg4mICAAOrXr89rr73GypUrsVqtOV0iu3btok+fPgQFBREYGEjTpk2ZMWPGQzv+sGHDqFChAhUqVGDmzJkP7bhZMW3aNHttt/775ptvMqx35MiRDOuFhobe9/FPnjxJ3759OXjwYLa3bdq0qb2Wffv23Xct8mhTsMpjYdOmTTRv3pwpU6awb98+rl+/TkpKCjExMWzcuJEhQ4bQu3dvbty4kWM1Xrp0ib59+xIREUFcXBxms5lz585x5cqVHKvpURcREZFh2fbt2w0/ztSpU2nbti1bt241fN+S9zjldAEiD1pERAQDBgzAYrEA4O/vT8OGDXFxcWHPnj0cOXIEgJ07dzJ06FBmzZqVI3Xu37+fpKQkAJydnenYsSPOzs6EhIQ8tBoaNWpEwYIFAahatepDO+692rlzJxaLBUdHR/uyBxGsy5YtIyUl5Z6379atG7GxsQAULlzYqLLkEaVglTwtOTmZt99+2x6qzz//PGPGjMHNzQ0Am83GV199xeTJkwHYvHkzERER1KlT56HXGh8fb38cFBTEhx9++NBraNmyJS1btnzox80ud3d3EhMTiY2N5dChQ1SpUgUAi8XCrl27AMiXLx83b97MyTLtXn311ZwuQR4idQVLnrZs2TJiYmIAKFq0KGPHjrWHKoDJZKJ///5Uq1YNLy8vGjZsaG813u7IkSO89957hISEEBgYSO3atXnttdfYtGlThnV37NhhH08bNmwYN2/e5OOPP6ZJkyYEBgbSsmVL5s2bl25M99a6t0RERNj3AbB06VL78759+6Y7XkxMTLrxxNvFx8czZcoU2rRpQ9WqVXn66aepW7cu/fr1y7T2vxtjPXv2LGPHjqVFixY888wz1KpVi969e/Pzzz/z17ujRkVFpRvjTE1N5auvvqJFixYEBgYSEhLC1KlTMZvNGY7zd6pVq2Z/fHsL9dChQ8TFxWVY56+SkpL4/PPPadu2LVWrVqVy5coEBwfTq1cv1q1bZ1/v1v/Lc+fO2Zd17dqVChUqsGPHDgBCQ0Pt7/PIkSMMHjyYKlWqUKtWLfs5zGyMdfjw4fZlQUFB9r9TgHnz5tlfq1atGmfPns32OZKcoxar5Gm3h0fr1q1xdXXNdL0vv/wSb29vHBwyftf88ccf+eCDD9J1BZrNZjZu3MjGjRvp0aMHI0aMwGQyZdg2Pj6e7t2727ubIW0SzLhx44iJieHtt9++n7d3V0lJSbz44oscPXo03fIrV66wefNmtmzZwoQJE2jXrl2W9rdx40beeuutdC3rpKQktm/fzvbt21m1ahWTJk3CxcUlw7YpKSm89tpr6cYoo6Ki+OKLLzh16hRTpkzJ1nsLDAxkz5499uPfahHeHrI1a9Zk27ZtGba1Wq28+eabbNiwId3y69evs2PHDnbs2MGYMWPo1KlTtmoC+Ne//mU/38nJyZQpU+aO6w4fPpzt27dz7tw54uLiGD9+PJ9++ilRUVFMnTrVvt4777xDiRIlsl2L5By1WCVPO3z4sP1x5cqV77ier69vpqG6Z88eRo0aZQ/VcuXK0b1793RdxWFhYcyePTvT/f7yyy8cPXqUxo0b07NnTwoUKGB/7ZtvvrG31vr160ejRo3srxUvXpx+/frRr1+/LL7TjH766Sf7h7y/vz9dunShd+/e9m5Tm83Gv//97yx1l545c4Z//vOf9lAtXrw4Xbt2pUmTJvbz9ssvvzBu3LhMt9+7dy9bt26lVq1ahIaGUqxYMftr4eHhnD9/PlvvzdnZ2T4GvHv3bvt5vBWsbm5uBAYGZrrtunXr7KHq6+tLt27d6NmzJ6VKlbKvM3/+fCCtl6Nfv354enraX2vXrh39+vWjaNGiGfZ99OhRqlSpQo8ePahYsSINGza843vw9PRkzJgx9i9kP//8M//9738ZOXKk/f9J/fr16datW1ZOiTxC1GKVPO3atWv2xz4+PtnefurUqfbx2ZYtW/LJJ5/g5JT2z2bBggWMGTMGgC+++IKuXbvi5eWVYR/vvvsuvXv3BtJazd27dwfSWntnz56lbNmyDB06lKVLl9pb2KVKlWLo0KHZrvd2t3cfjho1imbNmgFpgTpy5EhSU1N56qmnuHnzJvny5bvrvr788ksSEhKAtPHfWbNm2bdZt24dAwcOBOD777+nT58+PPnkkxn20bt3b4YPH25/3Lp1a5KTkwE4ceJEpkF1NzVr1mT79u0kJSWxd+9eqlWrxp49e4C0bmBnZ+dMt3N1daVTp078/vvvjBw50h7Q0dHR9i83t85diRIlGDp0KCtXrrR/qXjxxRfvOLGrRIkShIWFZdpqz0ydOnXo0aOH/bKhN954w34cb29vxo4dm6X9yKNFwSp52u0X82f3OtVr167Zx9EgLSBvhSqkja19++23nDp1ioSEBLZv307z5s3T7cPFxYUXX3zR/rx69ep4e3vbZ4jeCqsH4emnn7Y/fvvtt2ncuDG1a9emRo0afPTRR9na1+rVq+2P33rrrXRBHBISQr169di2bRtWq5UNGzbQp0+fDPt46aWX7I9LlChBmTJl+P3334F7Ow81a9a0P46IiMDBwYHExMQMr/1Vw4YN07Ukb968yW+//ZaumzqzcfasaNasWZZD9ZahQ4eydetWIiMj03Wzv/fee5pBnEspWCVP8/X1tU8KuX79era2jYqKsk/I8fPzy/AhZzKZqFixIqdOnQLg9OnTGfZRqFChDC0nDw8Pe7AacVOKO+2jZcuWrFu3jp9//pmbN2+ycuVKVq5caa+rVatW9O3b928/vK9evZruA79SpUoZ1qlUqZJ9PDOz82AymTIcx8PD42/fw91UrVoVFxcXzGYz27dvT3fJTa1ate66z6ioKL7//nu2bdvG0aNH7b0St9zrz1Tf3sWdVe7u7owZM4YePXrYl9WsWZP27dvfUw2S8zTGKnna7bNkbx9v/auZM2cyfPhwNm3aZB+vuz0QM5uYBOk/gDNbJ7PWS2Zjudnx1w/9O11faTKZ+PTTT1mwYAGdO3emSJEi9tdiYmKYP38+bdu2JSoq6q7H++t5yOx9/t15cHZ2zvC+7/c8uLq62seLDxw4wPr16+3Ln3nmmTtut3v3btq0acOsWbM4cuQItWrV4h//+Afz5s27r3qAdGOx2bF37950zw8ePJjpFxTJHRSskqfd3uUXHh5uH9O7ndls5vvvv2fJkiW8+uqrTJ8+HSBdEF2+fJmLFy+m285ms6WbcZvZuKJRbg+hW92dt9w+jpyZcuXK8cEHH7Bp0ybWrl3L+PHjKV++PJDWir81UedOvLy87IFhs9ns3be3u33Wc8mSJe/+Zgx0q8s3NTXV/sXpmWeeuWt37Pjx4+2Tg6ZNm8a8efN4/fXXDbkhxp3Gde/mjz/+YNq0aemWJSYm8u677z4St9mU7FOwSp72wgsv4OvrC8CFCxcYPnx4uusmU1NT+eijj+zXKTo6Otq74Hx9fdNdCzlhwoR0Y7a3xlchLXxq1679wN7H7ROvIiMj041J3j7+ebuhQ4dSp04d6tSpw4oVK4C0sc0OHTrw/PPP29eLjo7+2+M3btzY/njSpEnpwn3jxo32bmBHR8eHeqeoWrVqZWnZ7Y4dO2Z/fOtvA9Jm5d7u9lC7/YvN3a67vVPPxp1YLBaGDx9u/8LXqFEj+yVhu3fvZsGCBdnanzwaNMYqeZqnpyfjxo1j4MCB2Gw2fv75Z3bv3m1vye7YsYPIyEj7+r169Up37eGAAQN47bXXsNls/N///R/Hjx8nKCiIyMhI/vvf/9rXGzRo0D13A2ZFxYoV7Y+vXr3KG2+8wXPPPce+fftYsmRJptuUK1fOHqjvv/8+69ato2jRoly4cCHdNZzVq1f/2+O/8sorrFmzBrPZzM6dO2nTpg1169bl8uXL6fb14osvPtRrLm/N/r29O/xuE5cg7VKhEydOAGmzcFu2bElUVBSbN29Ot15SUpJ9ktbt/28nTpxI+fLl6dKly323cufMmWO/YUSBAgWYOHEiYWFhfPbZZwBMnjyZxo0bp7sUSB59arFKnte0aVOmTJli/5C8cOECixYtYtGiRelCtUOHDhkucWnUqBHDhg2zzwY+duwY3377bbpQDQ0NzXQWrJGeeOKJdLca3LZtGyNGjGDJkiU0adIkXbf1LX379rVfYpOSksKaNWuYN28eq1evtre6atWqlW7SzJ1UqlSJCRMm2M/h2bNnWbRoEevWrbO37Fq0aME777xz3+81O9zd3QkICLA/v/361jt5+eWX7Y+vXr1KWFiY/TKn2wP0zJkz9sc1atSwPz5w4ABLlizhjz/+uK/a/9oFPGzYMHx9fenXrx9ly5YF0sJdXcK5j1qs8lh47rnnCAoKYuHChWzcuJGzZ89iNpvx8/OjatWqdOnShXr16mW6bZ8+fahduzZhYWH897//5dKlS+TLl4+qVavSo0ePu94EwEgTJ06kZMmSrFixgsuXL1OyZEk6depEr169MlzmA+Dk5MRnn33G6tWr+eGHH4iMjOTy5cu4ubnx1FNP0bp1a7p165blccFWrVoRGBjIwoUL2bRpE9HR0bi4uFCpUiW6dOlC69ats90VaoSaNWvaJ/9UqVIl3S0rM/PCCy/g6urKnDlzOHXqFB4eHpQtW5aXX36ZvXv32n+m75dffrH3FAwePJjY2Fg2btyI2WymePHi+Pn53XPNVqs1XRdw3bp17XfAcnFx4cMPP6Rnz57YbDb27NnD/Pnz012uJI82k+1e55WLiIhIBuoKFhERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRAClYREREDKVhFREQMpGAVERExkIJVRETEQApWERERAylYRUREDKRgFRERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRATjldQF5iGW3K6RJEHrroUcNyugSRHFHMNC7T5WqxioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIGccroAESOM2V2IXZfcAfgj1pXiHim4OloB+K75WZ5fWYoahRKZUCfavs3BK668ua0oa9ueuu/jX0hwovsvJflPy0jyu6Ydd8dFdz7ZV4hUqwlXRyvDa8RQxS8JgEUnfPjmqC+OJijmmcK/g6Pt2wEcuebCqxuLs7nDSfuy8DOefHHADycHKJwvhRFBlyjmkXrftUvu1rTiUkqX88bB0WRfViHAl6H/rkH3pqtwdnHA1c0RkwlSUqwE1SvMgHcCcXAw3WWvd9e+9s8UKuJuf961bzmatSlpfx6+JJItv5xn7Jd1AbDZbMyZepiN4VG4uTvxdLUCDBxWBRdXRxITUpn43m5O/xGHzWrjuY5P0rVv+Xuu7VGgYJU84b0aMfbHzZaXZmKdCwT4JadbZ/UZT+oV8aJt6ThDj73slBfTDxTkUuKf/5zMFnhr2xPMbHyOygWS2XjOg2ERRVj5fCRR8U5M3V+Qlc+fwtfVytjdhZh+oCAjgi6RaoWwY758/XsBbqb+2aEUGefMBzsLs6DZWcr7mtl1yZ0hW4vyQ4szhr4XyZ0mLWiAT37XTF977+OaVAjMD0CK2cqQ0M0s+/YkHXqWvadjnTkZh7ePC7N+CsnwWux1M7MnH2LtirM8U7OgffmqpafZvjGaGT82wdPbhYVf/M7sKYcZ8E4gi+Ycw9XVkTkrmpEQn8LLz6/lmVoFqRhY4J7qexQoWOWxMbjKFcbu9qd6oUSKe965pRdrdqD3uuIZlrcoGU//p6+mW3bppiProjyZ1TiKVv9X2r7cxRE2tD+JswPYbHA23hlfVwsAFpuJVBskpDjg7WIlyeKAh1Paa4evuXHsuivTGpyn74Y/azh6zZUK+ZMp72sGIMg/kXMJTpyLd6LYXd6LyO2cXRwIDPLjzMn0Xy7jY80M6bUlw/qNnitGz/4V0y07tPcKDo4mBvfYREJcCg1bFKNH/4o4OprYuCoKP383+v8rgIgNf/YOHTt0nXohT+Dp7QJA/ebFGP7afxnwTiBWq42bN1OxpFoxJ1uwWm04O+fuUUoFqzw2avrf5IbZgbf/+wQLm52943reLlb+0zJrLUH/fBY+a3Ah09ecHeByoiOdVj/JtWQHPq2Xtt6TXim8XPEarf6vFN7OVjxdrHzXPO14VfySqOKXxLn49P80K+VP5vh1V36/5kql/MlsOOfB9WRHYpIUrAL/7LUlXVfwxNn1yO/nlmG9yxcTidgQzcuDK6db7umdeQs0MxaLjep1CtHvrQAsqVbefe2/5PN0plPvp2jbrQyQ1kK9XaVnCrB4/nE69CyLl48Lvyw7w9WYtGGRbn3L82avzXRuGE5CfArtXyxD2Yq+2Xn7j5yHGqxRUVGEhIQwZ84c6tWrZ1/etGlTFixYQPHiGVsJ9+Kzzz6jbt26BAUF8d5779GtWzcCAwMN2bfkboMCr7D9Yj4+P+hHSLH4TNfJTov17xR0t7Cx/UkOX3Xl5fXFeerZM5xLcGbNWU/WtztFflcLn+4ryPDtRfii0fk77qekV9o47Ae/+mO2mGhaPIEKvsk4O9iyVY/kTXfrCh7z9q+4ujlis9pwdHKgVadSNGxRLN062WmxPt+ldLrnnfuUY+nCP+jU+6k71vdsu5Jcjk7krd5bcHN3onWXUjj9r1U69aP9BNUrzCtDnuba5SSGvryVp1efy1BjbvLQW6zOzs6MGDGC5cuX4+np+UCO8euvvxIcHAzAmDFjHsgxJHdycoCP60bTeVVJfFwsma6TnRbrncSZHdhxMR/NSqSFd+UCyVTIn8yxG67svJiPJsUT8HNLO/6L5a7TNrzUXfdntpgo6ZXC98+etT9feNSXYh4p91Wn5H23j7HeSXZarGuWnaFsRR/KVvAB0oY6nJzvPhEq9rqZps+X4MXXKgBwcM8Vij3pAcCWX84xe3kzHBxM+Pm706hFMfbuiMnVwfrQO7L9/f2pW7cuEyZMyPDazJkz6dChA23btmXixInYbGnfxhcsWMCzzz7LCy+8wNtvv820adMA+Oabb+jcuTPPP/88HTp04OTJk/z0008cPHiQ999/n6NHjxIaGsqOHTsYNGgQq1evth+rY8eOHD58mNOnT/PSSy/RoUMHunfvzuHDhx/OiZAcU8IzheE1LjFlf8G/X/keOZhsvL+jMHti0rrjjt9w4WSsC1X8kqiUP4nN5z1ISEn7MFpz1otn/BLvuj+z1UTPX0pwISHtu/CCo75UL5SI720ziUUehsjjscz77DAWi43kJAs/hf1B45Z37208evAaI9+IIDXFiiXVynezjhLyfAkAylX2ZcPKKAASb6by69aLVK6aeycuQQ6NsQ4bNow2bdqwbds2e5fwli1bOHjwIIsXL8ZkMvH222+zfPlyKlSoQFhYGEuXLsXZ2ZnQ0FBKlixJfHw8a9euZeHChbi5uTF16lTCwsIYMWIES5YsYdCgQVSoUMF+zHbt2rFixQpatGhBZGQkycnJVK5cmW7dujFy5EgqV67MiRMneP3119MFcHYcabSIJO97m2knxjH/8g+ONZxAapkyd1xWEqj5+eccPXqUfW1+NObA373IgWfX4u3tDcDgSr8zMiwMy3ELTk5O9H+rG9FPP00Zm43yixfTdtt2nJycKFiwIC+//zL7/Pzsu4qJicG65l/sa7PLvuylYjvovWQJVquVYsWK0XdkX/b971g5ak9OF/C4W8rF/W1IzORvwWLezJWjIUSnlMlku3vTol4b5h2fR59nd5KamkpwcF1qlO1K9J4/W603Tm8iOdZK9J5OAJTIB0+XW0SfFjux2WwEBdWkwTNdid7jwCuhjZg7dy7hi3ZgMpmoXTuEwOIdiX7E/66KVF98x9dMtlvNwocgKiqKXr16sX79erZu3crIkSNZvnw5bdu2JSAggN9++w0fn7TuhaSkJJ599lkKFCjAxYsXGTZsGADz588nNjaWN954gytXrrBx40YiIyPZsmULlSpVYty4cYSGhjJo0CCCg4Ptj6tVq0ZISAjh4eHMmzcPZ2dnevbsSXBwMGXL/hmGV69eZfny5eTPf/euk8xYRt/7dWEiuVX0qGE5XYJIjihmGpfp8hybFVy/fv10XcIWi4XevXvz0ksvARAbG4ujoyOLFy/Gas3Y3XXhwgVCQ0Pp2bMnDRs2pGDBgvz+++93PJ6LiwtNmjRh/fr1rFq1iq+++gqr1YqLiwvLli2zrxcdHY2vr6+xb1ZERB4bOXqx0LBhw9i6dSuXLl2idu3aLFu2jISEBFJTU+1dsnXq1GHTpk3Ex8djNptZs2YNJpOJAwcO8OSTT9KnTx8CAwNZu3YtFkvaZBBHR0f749u1a9eOuXPn4uvrS7FixfDy8qJUqVL2YN22bRs9evR4qOdARETylhy9jtXT05OPPvqIvn370qRJE+Li4ujSpQsWi4UGDRrQoUMHTCYTvXr1omvXruTLl4/8+fPj6upKvXr1+O6772jVqhU2m42aNWty/PhxABo0aMCoUaMyTJCqUaMGcXFxdO/e3b7s448/ZvTo0Xz99dc4OzszefJkTCZ16YqIyL15qGOs9+LUqVNs2rSJPn36ADBgwAA6d+5M06ZNc7awTGiMVR5HGmOVx9UjN8aaVcWKFePAgQM8//zzmEwm6tevT5MmTXK6LBERkUw98sHq4uLCp59+mtNliIiIZEnuvtOxiIjII0bBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBjI6U4vhISEZHknJpOJtWvXGlKQiIhIbnbHYD137lyWd2IymQwpRkREJLe7Y7COGzfuYdYhIiKSJ9wxWDt06PAw6xAREckTsjx56caNG8yYMYM+ffrQunVrAObMmcOZM2ceWHEiIiK5zR1brLc7e/YsPXr0ICYmBpvNZh9T/fzzz/nyyy+ZO3cuTz/99AMtVEREJDfIUov1448/JiYmhjZt2uDj4wNAcnIylSpVIjY2lkmTJj3QIkVERHKLLAVrREQE+fLlY9y4cbi5uQHg6urKnDlz8PDwYP/+/Q+0SBERkdwiS8GampqK1WrFZrOlWx4fH09ycrIutxEREfmfLAVrcHAwSUlJDB06lMTERADmz59P7969sVgsBAUFPdAiRUREcguT7a/N0EycOXOG7t27c+XKlXStU5vNho+PD99++y1ly5Z9oIXmBpbRarnL4yd61LCcLkEkRxQzZX6/hyzNCi5ZsiTLly9n7ty5/Prrr1y/fp2CBQtSo0YNQkNDKVSokKHFioiI5FZZClYAPz8/hg4d+iBrERERyfWyHKwHDx5kxowZHDlyhJiYGLy9valRowavvvqqrmEVERH5nyxNXlq7di1du3Zl/fr1nDt3DrPZzOXLl1m9ejXdunUjIiLiQdcpIiKSK2SpxTplyhQsFguVKlUiNDQUf39/Ll++zMKFCzl06BDjx49n2bJlD7pWERGRR16WgvXMmTM4OzuzYMECvLy87MtDQkKoV68ekZGRD6o+ERGRXCVLXcGVK1fG0dHRftelW0wmE1arlapVqz6I2kRERHKdOwbr+fPn7f8NGDAAk8nEP/7xD3bv3s3p06eJiIhgwIABFChQgNGjRz/EkkVERB5dd7xBRKVKlbK0A0dHR5ycnNi3b5+RdeVKukGEPI50gwh5XGX7BhFZuCETkHYf4dTU1HurSkREJI+5Y7CuW7fuYdYhIiKSJ9wxWIsVK5blnRw+fDhb64uIiORVWbrcJjY2lk8++YT9+/dz8+ZNrFYrkNZdHB8fT3x8PIcPH36ghYqIiOQGWQrWCRMmsGTJkju+7uPjY1hBIiIiuVmWrmPdtGkTJpOJUaNGERwcTPXq1Zk9ezatW7fGZDIxbJhmBYqIiEAWg/X69ev4+vrSvXt3WrRowZkzZ6hXrx7jxo3Dzc2NuXPnPug6RUREcoUsBWuBAgW4ceMG586do3r16ly+fJnffvuNa9eukZqaytmzZx90nSIiIrlCloK1YcOGWK1W+vfvT4UKFShYsCChoaE899xzpKamUrhw4Qddp4iISK6QpWAdNmwYISEhlClTBpPJxODBgzGbzSQmJuLo6MiQIUMedJ0iIiK5wh1vaZiZlJQUnJ2dATh+/DgnTpwgICCAEiVKPLACcxPd0lAeR7qloTyusn1Lw8zcClWAcuXKUa5cufurSkREJI+5Y7CGhIRkeScmk4m1a9caUpCIiEhudsdgPXfuXJZ3YjKpC1RERATuMsb6n//8J1s76tChgyEF5WbneC+nSxB56IqMHpvTJYjkCMfRmU9RumOLVUEpIiKSfVm63EZERESyRsEqIiJiIAWriIiIgRSsIiIiBspWsCYnJ7Nr1y5WrlwJQHx8/AMpSkREJLfK8p2XZs6cycyZM0lISMBkMtGqVSs6d+5MnTp1eP/993FwUONXREQkS8EaFhbGpEmTcHJywsHBAavVSmJiIqdOnSIyMpICBQowaNCgB12riIjIIy9LzcxvvvkGBwcHli5dSsGCBQFwd3dn1qxZQPZvJiEiIpJXZSlYo6Ki8PHxoXz58umWN2jQAE9PT2JiYh5IcSIiIrlNloK1cOHC3Lhxg0OHDqVbHhYWRlxcHEWLFn0gxYmIiOQ2WRpj7dmzJ+PHj6dLly72ZTVr1iQ+Ph6TyUTnzp0fWIEiIiK5SZaCtU+fPsTHxzNr1iySk5MBiIuLw93dndDQUPr27ftAixQREckt7vjrNpmJi4tj37593LhxAz8/P55++mm8vb0fZH25in7dRh5H+nUbeVxl+9dtMuPl5UWDBg0MKUhERCQvylKwVqpU6a6vm0wmDh8+bEhBIiIiuVmWgvXveouz0ZssIiKSp2UpWBcsWJDuucViIS4ujmXLlnH48GFmzJjxQIoTERHJbbIUrLVq1cp0eUhICE2bNmXWrFl8+umnhhYmIiKSG93XnfNtNhupqals3LjRoHJERERytyy1WN99990My8xmM4cOHeLKlSsUKlTI8MJERERyoywF63/+8x9MJtMdJyn17t3b0KJERERyqywFa4cOHTIsM5lM+Pj4ULt2bRo1amR4YSIiIrlRloK1Y8eOBAQE4O7u/qDrERERydWyNHlp8ODB1KtXj2vXrj3oekRERHK1LAWrm5sbjo6O+Pr6PuByREREcrcsdQUPGjSIUaNG8corr9CqVSsKFSqEm5sbJpPJvk7NmjUfWJEiIiK5RZZ+3aZixYrpQjTDTnSvYEC/biOPJ/26jTyu7vvXbe6Wv7pXsIiISJo7Buv06dPx9PSkT58+HDly5GHWJCIikmvdcfLS9OnTmTdv3kMsRUREJPe7r3sFi4iISHoKVhEREQPddfLSxYsXqVSp0t/uRLOCRURE0vztrGDN+BUREcm6uwZr/vz5mTJlykMqRUREJPe7a7C6uLhQq1ath1WLiIhIrqfJSyIiIga6Y4u1ffv2uum+iIhINt0xWMePH/8w6xAREckT1BUsIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYSMEqIiJiIAWriIiIgRSsIiIiBlKwioiIGEjBKiIiYiAFq4iIiIEUrCIiIgZSsIqIiBhIwSoiImIgBauIiIiBFKwiIiIGUrCKiIgYyCmnCxAxStMKiyld3hsHB5N9WYWA/AwdE0T3pisJrFGQ4R/Xsr929MBVRg/eznfrW93XcdsHL6dQEXf78659K9CsbUn78/DFp9iy9jxjv6xnX7b/1xhmfnyA5CQLHl7OvDM+iKIlPElKTOWT93dz4vB1rFYbr74dSP1mxe6rPsm7xuwuxK5LaX97f8S6UtwjBVdHKwDfNT/L8ytL4eJgw9XRiglIsZqo98RN/lUthtv+mdyTCwlOdP+lJP9pGUl+17Rj7rjozif7CpFqNeHqaGV4jRiq+CUBsOiED98c9cXRBMU8U/h3cDT5Xa3EmR1o8J8ylPY22/c9rHoMFpuJj/cWtC9LtjgQGefCjy1O83SB5Psr/gFTsEqeMml+I3wKuGb62qZVUdSsX5jm7Z407HhnTsbh7evCrGXNM7wWe93M7EkHWbviDM/U+vMDIib6JqMGRTBxTgPKP52fJfOPM3X0XibMbsD8aYdxz+fEvPAWXDx/k0Fd11MhID+FiuQzrGbJO96rEWN/3Gx5aSbWuUCAX/rQuX2Z2QK915Xgu+O+9Ch//Z6Pu+yUF9MPFORS4p8RYrbAW9ueYGbjc1QukMzGcx4MiyjCyucjiYp3Yur+gqx8/hS+rlbG7i7E9AMFGRF0if1X3AjyT+TrJucyHOc/Lc/YH7+59QmaFY9/5EMVFKzyGOk7JIBp/95HQPWCPFHC447rxceaGRK6KcPyRs8Vp+eASumWHdp7BQcHE4Nf3EBCXCoNWxSjx4BKODqa2Bh+Fj9/N/q/U4WIDeft22xadY5aDYpQ/un8ALTpVoaa9QsDsHXted77JK1VXbhoPoLqFWZjeBSdXyp/3+9fxMURahRK5FSsS7rlsWYHeq8rnmH9FiXj6f/01XTLLt10ZF2UJ7MaR9Hq/0qn2/eG9idxdgCbDc7GO+PragHAYjORaoOEFAe8XawkWRzwcEp7be9ld26YHem2pgRmi4kuT92gW7kb6Y65/JQX5xKc+aTuBUPOw4OmYJU85Z+9N6XrCp44pwH5/dwAeKZmQeJulGXM0B1MDWt8x314emfeAs2MxWKlel1/+r0ViCXVyruvbiOfpzOd+pSjbfeyAKxaGplum6jIONzyOfLRkO2cPRWP/xPuDBz+DACXLtzE/4k/W6cFC7sTE52YpVpE/s6lm45sPO/BP6pcSbfc28WarnV4N/75LHzWIPOAc3aAy4mOdFr9JNeSHfi0Xtp6T3ql8HLFa7T6v1J4O1vxdLHyXfO04zmZbDQuGk+/yte4luxIn/XFKeieSrPiCUBaS3jKbwX5uO4FnHLJrKAcD9aoqCiee+45ypYti8lkIiUlBX9/f8aNG0eRIkWyvJ9169Zx8OBBBg8ezGeffUbdunUJCgrivffeo1u3bgQGBj7AdyGPirt1BQP0eaMyeyIuMW/aYeo3K5rpOtlpsT7fpUy6551fKsfShSfo1KfcHWtITbURseE8U8MaU7yUF0sXHGfUoAhmLWuOzWaDv4x9OdzvYJg81v4V8QSujlZsNhNODjZeKBPLsyXi062TnRbr3ynobmFj+5McvurKy+uL89SzZziX4Myas56sb3eK/K4WPt1XkOHbi/BFo/MMCPhz/4XzpdKl7A3WnfW0B+uas16U8EyhRqGke3j3OSPHgxXA39+fZcuW2Z+PHz+eiRMnMmnSpCzvIyQkhJCQEAB+/fVXgoODARgzZoyxxUqu5ujkwHuf1qJ/x3V4+7pkuk52WqxrfjpN2Yo+lK3oC6R1gTn9zdfqgv5uBFQvSPFSXgC07FSa6WP2k5xkwf+JfFy5lEiBgmmt7MuXEnnqf/sWuReZjbv+VXZarHcSZ3Zgx8V8NPtfaFcukEyF/Mkcu+HKzov5aFI8AT+3tO7fF8tdp214KQC+OeZL02LxFPVIBcAG6Vqm4We86FA69r5qe9geyYZ1cHAwx48fZ9++fXTu3Jm2bdvSu3dvTp8+DcDcuXNp27Yt7du3Z+TIkQAsXbqUYcOG8dNPP3Hw4EHef/99jh49SmhoKDt27GDQoEGsXr3afoyOHTty+PBhTp8+zUsvvUSHDh3o3r07hw8fzpH3LA9P0RKeDHqvKl9POnjf+4o8foN5nx3GYrGRnGThp7ATNG6V8Zv/7eo3L8bBPZe5cDbtG/mWNecoVc4bVzdH6oUU5edFp4C0SU6/brlI7SZP3HedIg+ag8nG+zsKsycm7Uvh8RsunIx1oYpfEpXyJ7H5vAcJKWm9L2vOevGMX9oQx54Yd+b8njbf4HqyA0tPetOyZByQ9kV19yV3ahe5mQPv6N49Ei3W26WkpLB69WoCAgL45z//yZQpU6hSpQrh4eH885//5IcffuCrr75iy5YtODo68t5773Hx4kX79u3bt2fJkiUMGjSIChUq2Je3a9eOFStW0KJFCyIjI0lOTqZy5cp069aNkSNHUrlyZU6cOMHrr7+eLoCz4/KhEFKTfO77HMi9WszF/a1J9PbO8IoleSNXjjQl2pzWdVulBNSq+TlHjx4lenfHez5ii3qtmXd8Hn2abyc1NZXg4LrUKNOV6N1/dt/eiNxE8g2L/TieQO+eAQzv+x9SU1Px8PDg9VdHEL27GC0btGLOnDmENo3AarXSrfPLOMbUJzrmDgU8AqLb3Pv5E+OYf/kHxxpOILVMmbsuM9R3L3Lg2bV4/+/f3OBKvzMyLAzLcQtOTk70f6sb0U8/TRmbjfKLF9N223acnJwoWLAgL7//Mvv8/GjfKJbZs2fTfPN5LBYLz7Z/lnzPPcc+IDY2loQfXye663aiH8w7uGdVVwTd8TWTzWazPcRaMrh9jBXAbDZTpUoVOnXqxJgxY/jpp5/s69asWZP169fzr3/9i/PnzxMSEsJzzz1H+fLlWbp0KTt37mT8+PGEhoYyaNAggoOD7Y+rVatGSEgI4eHhzJs3D2dnZ3r27ElwcLD92ABXr15l+fLl5M+fP9vv5Rzv3ff5EMltiowem9MliOQIx9GZx+cj0WL96xgrwJEjRzKsZ7PZsFgsfPHFF+zbt4/Nmzfzyiuv8Mknn/ztMVxcXGjSpAnr169n1apVfPXVV1itVlxcXNIdOzo6Gl9f3/t+TyIi8nh6JMdYAcqUKcP169f57bffAFi5ciVFixbFarXSqlUrypcvz+DBg6lXrx5Hjx5Nt62joyMWiyXDPtu1a8fcuXPx9fWlWLFieHl5UapUKXuwbtu2jR49ejz4NyciInnWI9FizYyLiwuTJ0/mo48+IjExER8fHyZPnkyBAgXo2rUrnTp1wt3dndKlS/PCCy+watUq+7YNGjRg1KhRTJgwId0+a9SoQVxcHN27d7cv+/jjjxk9ejRff/01zs7OTJ48GZNJlzeIiMi9yfEx1rxEY6zyONIYqzyu7jTG+sh2BYuIiORGClYREREDKVhFREQMpGAVERExkIJVRETEQApWERERAylYRUREDKRgFRERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRAClYREREDKVhFREQMpGAVERExkIJVRETEQApWERERAylYRUREDKRgFRERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRAClYREREDKVhFREQMpGAVERExkIJVRETEQApWERERAylYRUREDKRgFRERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRAClYREREDKVhFREQMpGAVERExkIJVRETEQApWERERAylYRUREDKRgFRERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRAClYREREDKVhFREQMpGAVERExkIJVRETEQApWERERAylYRUREDKRgFRERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRAClYREREDKVhFREQMpGAVERExkIJVRETEQApWERERAylYRUREDKRgFRERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRAClYREREDKVhFREQMpGAVERExkIJVRETEQApWERERAylYRUREDKRgFRERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRAClYREREDKVhFREQMpGAVERExkFNOF5BXpKamEh2dkNNliDx0lnh9jMjjqWhqKk5OGf/+TTabzZYD9eQ5UVFRhISE5HQZIiLykKxbt47ixYtnWK5gNUhaizU6p8t4LEVHR9OjRw/CwsIoUqRITpcj8lDo7z7nFSlSJNMWq/pwDOLk5JTpNxd5eIoUKaL/B/LY0d/9o0eTl0RERAykYBURETGQglVERMRAClbJ9by9vRk0aBDe3t45XYrIQ6O/+0eXZgWLiIgYSC1WERERAylYRUREDKRgFRERMZCCVURExEAKVhEREQMpWEVERAykYBURETGQglVERMRAClZ5rOn+KJKXZfb3bbVac6CSx4uCVR4btz5koqKiiI6Oxmw2YzKZcrgqkQfDZrPZ/76PHz/OyZMnAXBw0Mf+g6ZbGspjZdOmTUyZMoWgoCDWrl3L999/T+HChdN9CInkJQsXLmTNmjUUL16c/fv389133+Hj46O/+QdIX13ksXH8+HGmTJnCZ599RtWqVXF3d8dqtarlKnnWtm3bWL16NbNmzaJ48eI88cQTpKamKlQfMAWr5Gm3OmQsFguurq60a9eOgwcPMnfuXGbPns2ePXsYMmRIDlcpYjyLxYKHhwft2rXjm2++Yffu3cycOZPvv/+eMWPG5HR5eZpTThcg8iCZTCYOHjxIeHg4vXv3ZtasWTg7O7NhwwZMJhOJiYk89dRTOV2miKHWrl3L77//Ttu2bRk7dixlypRhyZIlAJjNZkqXLp3DFeZtarFKnlegQAHCw8OJjo7m008/JTY2lsWLF/Pjjz8yf/58qlevntMlihiqePHi/PTTT1itViZMmMDp06dZvHgxn3/+ORs3bqR27do5XWKepslLkqckJCTg5OSEq6srsbGxQNoPQi9ZsoSYmBj69+/Phg0bWLlyJfny5SMkJISGDRtqzElyrWvXruHl5YWTkxNXrlzBxcUFLy8v5s6di5ubG927d2flypXs2bMHgO7du1O2bNkcrjpvU7BKnhEbG8snn3zCm2++yfXr15k+fTp+fn60bdsWZ2dnPvjgAyZOnEiJEiWwWCw4OjoCKFQl1zp79iyzZ89m2LBhHDhwgLCwMHx9fQkNDeXixYt8/vnnTJ8+nfz58+d0qY8VdQVLnpCcnIy3tzdvvvkmiYmJXLhwgVatWlGuXDkGDx7MH3/8QXJyMvPnz8dsNttDFVCoSq4UHx9PiRIleOeddzh27BjJycl07tyZMmXKMGjQIC5fvsyVK1cICwvTTSEeMgWr5HoJCQl89913nDlzBovFwqpVq5g2bRqOjo506dKFqVOncvPmTTw8PNizZw9JSUk5XbLIfbly5Qrz58/n/PnzXLt2jbVr1zJ79mxMJhO9evVi7NixWK1W3NzcOHToEKmpqTld8mNFs4Il1/Pw8CA+Pp4333wTk8nEokWL8PHxYc6cOVgsFpo1a0ZgYCDt27fnyJEjeHt753TJIvcsKiqK4sWLEx8fz0svvUSxYsWYM2cO8+fPZ+bMmdhsNurVq0e1atV49tlnuX79Oi4uLjld9mNFLVbJ1W51cXXu3Nl+q7aYmBg6depEmzZtCAsLY82aNcTHx+Ps7ExgYGBOlityXy5fvszixYsBaNu2LX5+fphMJi5fvkzv3r1p3Lgxc+fOZdOmTdy8eZN8+fJRtGjRHK768aNglVzLZrPh4ODAhQsXAJgxYwZNmzblgw8+4ODBg3Tp0oXGjRsTFhZGcnJyDlcrcv+8vb159dVXOXToEEuXLmXmzJlUrFiRDz74gD/++IM+ffpQtWpVli5dqrkDOUizgiVX27hxI2PHjqVmzZpUqlSJnj17MnnyZE6dOkWDBg3w9/enTJkylChRIqdLFblnf525Hh4ezi+//ELt2rXp3Lkz48aN4+rVq5QvX56AgAAqVqxIgQIFcrDix5tarJJr7d69m8mTJzNu3Di8vLxYtmwZc+bMYciQIVSrVo3w8HBMJpNCVXK120N148aNrF27ljp16tC6dWt+/fVXvv32W4YPH07lypXZu3cvhQsXVqjmMLVYJdeaP38+Tk5OdO/enTFjxlCmTBnWr19PtWrVGDhwICkpKbi6uuo6VckTvv76azZs2ECJEiXo378//v7+bN26lW3btlGsWDFeffVVzGazJio9AtRilVwnMjKSyMhIAgMDcXBwYMWKFQQGBtKxY0ccHBzYtm0bx44dw9XVFdB1qpL7nTt3joiICMLCwujTpw+7d+9m/Pjx3Lx5k+rVqxMVFaXZv48QXW4jucKtVudvv/3GN998g5ubG/369aN69er07NmTF198kbi4OK5cucLEiRN1Y33J1f7ay+Lu7s7Zs2fp378/169fp1q1aiQlJXH69Gn+8Y9/0KxZMzw8PHKwYrmduoIl19iwYQOTJk2ifv36REZGUq5cOdq1a8fmzZvZvHkzFy5cYMiQIbRo0SKnSxW5Z7eH6rp167BarXh7e1O0aFG2bt1KnTp1KFWqFGvXrmXx4sVMmTIFNze3HK5abqdglVwhOTmZ0aNH06ZNG+rWrcuRI0fYunUrV69epUGDBvj4+JCSksIzzzyjMVXJE+bPn8+yZcto3rw53333HW3btmXo0KGMGTOG+Ph49uzZw+eff67emUeQuoIlV3B1dcVkMrFlyxbq1q1LxYoVuXLlClOmTMHV1ZXQ0FD7TEiFquRGR48e5VY7p0yZMoSHh/PFF19QpEgRQkND6dChA56ennTu3Jljx44xcOBAzXh/RClY5ZF0q9V59OhR4uLi8Pf3p0WLFkRERLBixQratGlDoUKFcHNz4/fff+fkyZO6xEByrU2bNjF+/HhKly7N+fPnCQkJwdvb2/6rNJ6enowaNYply5bRv39/ypcvn8MVy90oWOWRZDKZWLt2LTNmzKBatWqcPHmSxo0bU7RoUVasWMHPP/9s/8msH374gT/++IOgoKCcLlsk27Zt28aUKVOYMGECpUuXZvny5ezatQuz2cyIESOYOHEiAKdOnSI5OZnU1FQcHR3VM/MI0+U28siIiopixowZAFy4cIGwsDAWLFhAQEAACQkJvPDCCwQHBzNx4kReeeUVBg0axLlz51i9ejV16tTJ4epFsi8iIoI333yTSZMmUaVKFby8vAgICMBisTB8+HCsVisdOnRg2rRp/PDDD7zxxhs4OTkpVB9xarHKI8PBwYFvv/0Wq9VK586dKVq0KPPnz2fTpk18/PHHREREEB4ezqeffkqZMmXYu3cvP/zwA5MnT6ZkyZI5Xb5ItpnNZgBOnz5N6dKlAVi1ahXOzs6UK1eOTz75hO+//x5fX1+ef/55+zryaNOsYHkkWK1WHBwcOHv2LK+99hp16tTBarXy66+/MnbsWKpUqcKaNWsIDw9nwoQJODs7YzKZuHHjBj4+Pjldvsg927BhA2PGjOGdd97hjz/+YO/evXz22Wf2G5xI7qNglRx1/fp1nJyc8PT0tE9YOnv2LEOGDCEpKYlKlSrh4OBAqVKl+PHHHxk1ahSNGjWyB7FIXrB+/XpGjBiBh4cHa9asAdDtCXMxBavkmISEBFq0aEFsbCxNmjTBx8eHqlWrUrlyZTw8PBg4cCClS5embt26XLlyhaCgIIKDg3WdquRJmzZt4sMPP2T48OGEhITkdDlyHxSskqN++eUXxo8fT8mSJXnhhRcIDw/nxIkTBAYGsm3bNq5du8Zrr73GkCFDcrpUkQduw4YNvP3223z44Ye0atUqp8uRe6RglRy3detWPvjgA0aNGkX9+vVJTk7m/PnznD59mjNnzlCqVCkaNmyY02WKPBSbN2/mySef5Mknn8zpUuQeKVjlkbB27VrGjRvH66+/TseOHTO8ru5fEcktdLmNPBKaNWuGg4MDEyZMwGaz8cILL6R7XaEqIrmFglUeGU2bNsVisTBmzBjq16+Pv7+/AlVEch11Bcsj58qVK/j5+eV0GSIi90TBKiIiYiBdYS8iImIgBauIiIiBFKwiIiIGUrCKSJZZrdacLkHkkadgFXnAmjZtSoUKFez/VapUiWrVqtG+fXvCw8Mf6LFDQ0OpUKEC06ZNA2Dp0qVUqFCBpk2bZms/sbGxfPjhhyxfvvy+a8pKDdOmTaNChQqEhoZmeb87duywn+P7dS/HF7lF17GKPCQ+Pj64ubmRkpLC9evX+f333xkyZAhubm40adLkodTg7u5O4cKFKVSoULa269GjB8eOHSMgIOABVSaSd6jFKvKQDBs2jM2bNxMREcHGjRspU6YMNpuNhQsXPrQaWrZsyebNm1m0aFG2tktISHhAFYnkPQpWkRxQuHBhe1fo+fPngT+7SPv27ctHH31EUFAQHTt2xGazkZCQwAcffEDt2rWpUqUK3bp1IyIiIt0+o6OjGThwIFWrVqVRo0Z89913GY57p27YhQsX8txzzxEQEECjRo3497//TXx8PJDWlX3u3DkA3n333XTbLl++nFatWhEQEEDTpk2ZPn06FovF/rrNZuOLL76gQYMGVK1albfeeou4uLh7OmfR0dG8+eab1K1bl4CAABo3bsz48eMxm80Z1t21axdt27YlMDCQTp06sWvXrnSvHzhwgNDQUKpUqULt2rV59913uXr16j3VJfJX6goWyQFnzpzhl19+AaBYsWLpXtuxYwfbtm3Dw8ODsmXLAjBw4EC2b9+Ok5MTHh4e7N27l1deeYV58+ZRs2ZNzGYzffr04dSpUwA4ODgwevRo3N3d/7aWKVOmMGPGDAA8PT25dOkSCxcuJDIykq+//ppChQoRHR2NxWLBx8fH3o28dOlS3n33XQB8fX2Jjo5m2rRpXLx4kY8++giA6dOnM336dADy5cvHypUrWbdu3T2ds4EDB3Lo0CEcHR3x9PTkwoULzJ07Fx8fHwYMGJBu3VdeeQWTyURqaioHDhygb9++rF69miJFinDixAlCQ0NJTEzEw8ODmzdvsnTpUg4ePMiSJUv04+Jy39RiFXlIxo8fT8OGDQkODqZ58+acPn0aBwcHXnrppXTrpaSkMG7cOHbt2sW7777Lli1b2L59OyVLlmTLli3s3LmT0aNHk5qaag+ttWvXcurUKRwcHJg3bx579uxh3LhxJCYm3rWm69evM3v2bCCtNbp7926WLFmCk5MTu3fv5tSpUyxatIgiRYoAad3ZixYtwmq1MnnyZCAtPHfs2MG6desoUKAAP/74I+fOncNsNjNv3jwAe6tx/fr1+Pj4ZPvcxcTE4O/vT0BAAFu3bmXnzp288sorAOzfvz/D+m3atLEfr0iRIiQlJfH1118D8Pnnn5OYmEjv3r3ZtWsXO3bsIDg4mGPHjrFy5cps1ybyV2qxijwkN27c4MaNGzg6OuLt7U3ZsmUZMGAA9evXT7eeo6MjrVu3xmQyUaBAAXbu3AnApUuXaN++PfDnZS+7d+8mJSXFHi61atWiTp06AHTs2JFp06bZu5ozs3//fsxmM66urvTq1QuAypUrs2bNGp544gkcHDL/7n3q1CkuXboEwIcffmhvocbFxWGz2fj111+pWLGivTt50KBBODo68sQTT/DCCy/w+eefZ+vcFSpUiC+//JLU1FQOHTrE8uXL7V3hN2/ezLD+wIEDMxzv6NGjAPbzuWzZMlatWgVgr3PHjh32cyxyrxSsIg/JuHHjMv2t2b/y8fFJ1x1548YNAJKSkkhKSkq37q0ZxreCoWDBgule9/f3v2uwXr9+HQBvb+90IfrX7um/ulUTYA/Y2126dInixYvbn99el7+//133fSczZsxgzpw5xMbGUrRoUfLnzw+kjeP+1e0/4nDreLfqvFX7rff+17pF7peCVeQR4+bmlu75rZBo2rSpfSzUbDZjMplwdnYGsHev/jUY/i4ofH19gbSQMZvN9kAPDw/Hy8uLKlWq4O3tnWG724Nyx44d9v0kJCTg4eEBwIkTJ+zrXLx40R60Fy9evGtNmdm0aRNTpkzBz8+PlStXUrZsWRYtWsTIkSMzXf/8+fOUKlUKgMuXLwN/niM/Pz+io6OZPn06zZs3B9Javfny5ct2XSKZ0RiryCPmr79BW6NGDQC2bdvGgQMHgLQbGFSrVo1BgwYBEBQUBMCePXvYtm0bAIsWLbpraxXgmWeewcXFhZSUFObMmQPA0aNH+de//kXfvn3t4ejklPYdPD4+ntTUVIoVK2Yfd505cyY2m41jx44RHBxMo0aNOHXqFKVLl6ZAgQJAWmszNTWVqKgoFi9enO1zcuzYMQCcnZ0pXLgw8fHx/Pzzz0Dmd4OaPHkyZrOZixcvsmTJEgCqV68O/Hk+FyxYQEJCAvHx8XTo0IHg4GBWrFiR7dpE/krBKvKIa9CgAdWqVSM5OZlOnTpRs2ZNZs6cSUpKCq1atQKgUaNGVKlShdTUVF5++WWqVavGyJEj//ZGEL6+vvZJQJMnT6ZGjRq0b98es9lM3bp17WF0q2t44sSJNG7cGEdHR/tM3NmzZ1OjRg06dOhASkoK5cqVo3Tp0jg6OjJw4EAAFi9eTFBQEM2bN8+06/bvVK1aFUi75KZ+/frUqVPHPlZ6qxv8Fh8fHzZv3kxQUBBNmzbl/PnzeHl52ceQX331VVxcXNi5cye1a9emfv36REZG4ubmlmG8W+ReKFhFcoGvvvqKbt26UahQIZKTk6lQoQKTJk2yB6ujoyNfffUVLVu2xN3dHR8fH0aMGJGlWxcOHjyY9957j1KlSpGcnEyRIkXo1asXn332mX2dQYMGUbZsWUwmE/nz5yc1NZVu3boxZswYypcvT0pKCvnz5yc0NJSpU6fatwsNDWX48OEULlwYk8lEq1atGDNmTLbff82aNRkxYgRFixbFZDJRrlw5JkyYgIODA8ePH7d39wIUKFCAOXPm8NRTT+Hg4EDVqlWZN28eRYsWBaBixYrMmzePWrVq4eTkhIuLCyEhISxYsMA+bityP/RD5yIiIgZSi1VERMRAClYREREDKVhFREQMpGAVERExkIJVRETEQApWERERAylYRUREDKRgFRERMdD/AwLaPXgsUjl1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.73      0.73     19017\n",
      "         1.0       0.73      0.73      0.73     19017\n",
      "\n",
      "    accuracy                           0.73     38034\n",
      "   macro avg       0.73      0.73      0.73     38034\n",
      "weighted avg       0.73      0.73      0.73     38034\n",
      "\n",
      "\n",
      "_________________________________________\n",
      "\n",
      "Specificity\n",
      "\n",
      "0.73\n",
      "\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining pipe again just to make verbose=2 in the model\n",
    "d_in = len(X_train.iloc[0])\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "# ('model', tabular_nn_model(d_in=d_in, n_epochs=100, lr=0.01, weight_decay=0, early_stop=True, verbose=2))\n",
    "# ])\n",
    "\n",
    "\n",
    "# manual params setting\n",
    "best_params2 = {'model__lr': 0.01, 'model__drop_out': 0.4}\n",
    "\n",
    "            \n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train)*sample_ratio)\n",
    "X, y = resample(X_train.values, y_train.values, n_samples=n_samples, stratify=y_train.values, random_state=10)\n",
    "model_final = copy.deepcopy(pipe)\n",
    "model_final.set_params(**best_params2)\n",
    "model_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.80      0.85      4754\n",
      "         1.0       0.33      0.55      0.41       852\n",
      "\n",
      "    accuracy                           0.76      5606\n",
      "   macro avg       0.62      0.67      0.63      5606\n",
      "weighted avg       0.82      0.76      0.78      5606\n",
      "\n",
      "\n",
      "_________________________________________\n",
      "\n",
      "Specificity\n",
      "\n",
      "0.8\n",
      "\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "\n",
    "X,y = X_test.values, y_test.values\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.95).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'fpr_ANN_grade123' (ndarray)\n",
      "Stored 'tpr_ANN_grade123' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "fpr_ANN_grade123, tpr_ANN_grade123, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "%store fpr_ANN_grade123\n",
    "%store tpr_ANN_grade123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = model_final._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = RF_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,15)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_imputed_array = model_final.named_steps['imputer'].transform(X_test)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed_array, columns=X_test.columns)\n",
    "X_test_scaled_array = model_final.named_steps['scaler'].transform(X_test_imputed)\n",
    "df_test_imputed_scaled = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(RF_model)\n",
    "shap_values = explainer.shap_values(df_test_imputed_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.query(\"outcome==1\").iloc[[40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_numbers = y_test.loc[31703381,19338519,20471295].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(row_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number_1 = 402\n",
    "row = df_test_imputed_scaled.iloc[[row_number_1]]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test[\"outcome\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[[row_number_1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = RF_model.predict_proba(df_test_imputed_scaled.iloc[[row_number_1]])\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[1], shap_values[1][[row_number_1]], df_test_imputed_scaled.iloc[[row_number_1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.waterfall_plot(explainer.expected_value[1],shap_values[1][[row_number_1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining X_test,y_test and y_pred in one dataset\n",
    "# del(df_test_all)\n",
    "df_test_all = X_test.copy()\n",
    "df_test_all['y_actual'] = y_test\n",
    "df_test_all['y_pred'] = y_pred\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3\n",
    "\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TN = df_test_all[df_test_all.error_category==0]\n",
    "df_FP = df_test_all[df_test_all.error_category==1]\n",
    "\n",
    "df_TP = df_test_all[df_test_all.error_category==2]\n",
    "df_FN = df_test_all[df_test_all.error_category==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the DataFrames\n",
    "common_FP = pd.merge(df_FP, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FP.drop([col for col in common_FP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TN = pd.merge(df_TN, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TN.drop([col for col in common_TN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TP = pd.merge(df_TP, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TP.drop([col for col in common_TP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_FN = pd.merge(df_FN, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FN.drop([col for col in common_FN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_test_all = pd.merge(df_test_all, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_test_all.drop([col for col in common_test_all.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FP, kind=\"hex\", joint_kws={'color':'#66ffcc'})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<90].shape[0])/(common_FP.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_TN[common_TN.egfr_epi_scr<90].shape[0])/(common_TN.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TP, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hist2d(common_FP.egfr_epi_scr, common_FP.age, bins=[x_bins, y_bins])\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hexbin(common_FP.egfr_epi_scr, common_FP.age, bins=50)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(common_FP.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=common_FP, x=col, bins=50, stat='percent', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for True negative and  False positive and compare their distribution.\n",
    "# It plots the distribution and prints Jensen-Shanon distance.\n",
    "# from functions_compare_distribution import compare_hist_df\n",
    "from dfwiz import dfwiz, dfwiz_compare\n",
    "# healthy patients\n",
    "TN = df_test_all.query(\"error_category == 0\")[X_test.columns] # True negative\n",
    "FP = df_test_all.query(\"error_category == 1\")[X_test.columns] # False positive\n",
    "\n",
    "if len(TN) == 0 or len(FP) == 0:\n",
    "    print(\"Error! one of the dataframes are empty\")\n",
    "else:\n",
    "    # compare_hist_df(TN, FP) # plot distributions and output Jensen-Shanon distance.\n",
    "    dfwiz_compare(FP, TN,label=['FP', 'TN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.kdeplot(data=df_test_all, x=col, hue='error_category', bins=50, stat='density', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', common_norm=False, bins=50, stat=\"percent\");\n",
    "    plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_FP, x=df_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"density\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', bins=len(df_test_all), stat='density', element=\"step\", fill=False, cumulative=True,common_norm=False);\n",
    "    plt.title(\"Cumulative distribution function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree on validation set to differentiate between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "# del(df_test_all)\n",
    "\n",
    "# X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_valid)\n",
    "X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "X_valid_scaled_array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "df_test_all = pd.DataFrame(X_valid_scaled_array, columns=X_valid.columns)\n",
    "\n",
    "\n",
    "# df_test_all['y_actual'] = y_valid.values.ravel()\n",
    "df_test_all['y_actual'] = y_train.values.ravel()\n",
    "df_test_all['y_pred'] = y_pred\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP', 'TP', 'FN' ]\n",
    "df1 = df_test_all.copy()\n",
    "X1 = df1[X_test.columns]\n",
    "X1\n",
    "y1 =  df1[['error_category']]\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 5 , class_weight='balanced', random_state=42, criterion=\"gini\", min_impurity_decrease = 0.002)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "plt.figure(figsize=(20,12))\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = list(X1.columns), \n",
    "               rounded=True, \n",
    "               filled = True,\n",
    "               proportion = True,\n",
    "               class_names = class_names);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "# X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "# X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "# X_train_imputed = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "# X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_valid)\n",
    "# X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "# X_valid_scaled__array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "# X_valid_imputed = pd.DataFrame(X_valid_scaled__array, columns=X_valid.columns)\n",
    "\n",
    "# y_error_t = clf.predict(X_train_imputed)\n",
    "# y_error_v = clf.predict(X_valid_imputed)\n",
    "\n",
    "# # True Negatives (0)\n",
    "# X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "# y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "# X_valid_TN = X_valid.loc[(y_error_v==0)]\n",
    "# y_valid_TN = y_valid.loc[(y_error_v==0)]\n",
    "\n",
    "# # False Positives (1)\n",
    "# X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "# y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "# X_valid_FP = X_valid.loc[(y_error_v==1)]\n",
    "# y_valid_FP = y_valid.loc[(y_error_v==1)]\n",
    "\n",
    "# # True Positives (2)\n",
    "# X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "# y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "# X_valid_TP = X_valid.loc[(y_error_v==2)]\n",
    "# y_valid_TP = y_valid.loc[(y_error_v==2)]\n",
    "\n",
    "# # False Negatives (3)\n",
    "# X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "# y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "# X_valid_FN = X_valid.loc[(y_error_v==3)]\n",
    "# y_valid_FN = y_valid.loc[(y_error_v==3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_train_imputed = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "X_test_imputed_array = model_final.named_steps['imputer'].transform(X_test)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed_array, columns=X_test.columns)\n",
    "X_test_scaled_array = model_final.named_steps['scaler'].transform(X_test_imputed)\n",
    "X_test_imputed = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "\n",
    "y_error_t = model_final.predict(X_train_imputed)\n",
    "y_error_v = model_final.predict(X_test_imputed)\n",
    "\n",
    "# True Negatives (0)\n",
    "X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "X_valid_TN = X_test.loc[(y_error_v==0)]\n",
    "y_valid_TN = y_test.loc[(y_error_v==0)]\n",
    "\n",
    "# False Positives (1)\n",
    "X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "X_valid_FP = X_test.loc[(y_error_v==1)]\n",
    "y_valid_FP = y_test.loc[(y_error_v==1)]\n",
    "\n",
    "# True Positives (2)\n",
    "X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "X_valid_TP = X_test.loc[(y_error_v==2)]\n",
    "y_valid_TP = y_test.loc[(y_error_v==2)]\n",
    "\n",
    "# False Negatives (3)\n",
    "X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "X_valid_FN = X_test.loc[(y_error_v==3)]\n",
    "y_valid_FN = y_test.loc[(y_error_v==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_FP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.loc[~(y_error_t==1)]\n",
    "y_train_new = y_train.loc[~(y_error_t==1)]\n",
    "\n",
    "X_valid_new = X_valid.loc[~(y_error_v==1)]\n",
    "y_valid_new = y_valid.loc[~(y_error_v==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new, y_train_new = up_sample(X_train_new, y_train_new,'outcome')\n",
    "X_train_new, y_train_new = up_sample(X_train, y_train,'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 350, 'model__min_samples_split': 350}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_new)*sample_ratio)\n",
    "X, y = resample(X_train_new.values, y_train_new.values, n_samples=n_samples, stratify=y_train_new.values, random_state=10)\n",
    "model_final = copy.deepcopy(pipe)\n",
    "model_final.set_params(**best_params2)\n",
    "model_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_new.values, y_valid_new.values\n",
    "\n",
    "# X,y = X_test.values, y_test.values\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.6).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,20)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_RF = df_test_all.copy()\n",
    "y = df_valid_RF.error_category\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgbm  # standard alias\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "# ('model', lgbm.LGBMClassifier(n_jobs=-1, n_estimators=300))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF to classify 4 error categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### **************************************8\n",
    "# Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "# param_grid ={'model__num_leaves': [6, 10, 20, 50], \n",
    "#              'model__min_child_samples': [100, 200, 300, 400, 500], \n",
    "#              'model__min_child_weight': [1e-5,  1e-2,  1,  1e2,  1e4],\n",
    "#              'model__subsample' : [0.2, 0.5, 0.8], \n",
    "#              'model__reg_alpha': [0, 1e-1, 1, 5,  10, 50, 100],\n",
    "#              'model__reg_lambda': [0, 1e-1, 1,  10,  50, 100]}\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 500 ],\n",
    "    'model__max_depth': [ 30 , 40, 50 , 60 , 80, 100],\n",
    "    'model__min_samples_leaf': [100, 70, 50,20, 10,5],\n",
    "    'model__min_samples_split' : [100, 70, 50,20, 10,5]\n",
    "}\n",
    "\n",
    "# param_grid ={'model__max_depth': [6, 10], \n",
    "#    }\n",
    "df_valid_RF = df_test_all.copy()\n",
    "y = df_valid_RF.error_category\n",
    "X = df_valid_RF.drop(['y_actual','y_pred','error_category'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "score, best_params, model_final = param_graph(X, y, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True, multi_class=True, average_metric=\"micro\")\n",
    "\n",
    "# dump(model_final , open('model_final_LGBM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP', 'TP', 'FN' ]\n",
    "df1 = df_test_all.copy()\n",
    "X1 = df1[X_valid.columns]\n",
    "y1 =  df1[['error_category']]\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "# plt.figure(figsize=(20,12))\n",
    "# tree.plot_tree(clf,\n",
    "#                feature_names = list(X1.columns), \n",
    "#                rounded=True, \n",
    "#                filled = True,\n",
    "#                proportion = True,\n",
    "#                class_names = class_names);\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix,plot_confusion_matrix\n",
    "# cm = multilabel_confusion_matrix(y1, y_pred)\n",
    "plot_confusion_matrix(clf, X1, y1, display_labels=['TN','FP','TP','FN'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = model_final.named_steps['imputer'].transform(X_test)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_test_imputed_scaled = pd.DataFrame(X_train_scaled_array, columns=X_test.columns)\n",
    "\n",
    "y_pred2 =clf.predict(X_test_imputed_scaled)\n",
    "# plot_confusion_matrix(clf, X_test, y_test, display_labels=['TN','FP','TP','FN'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = np.where((y_pred2==0) | (y_pred2==2),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_pred3==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import multilabel_confusion_matrix,plot_confusion_matrix\n",
    "\n",
    "\n",
    "# best_params2 = {'model__n_estimators':100,'model__max_depth': 80\n",
    "# ,'model__min_samples_leaf': 50, 'model__min_samples_split': 50}\n",
    "\n",
    "\n",
    "# df_valid_RF = df_test_all.copy()\n",
    "# y = df_valid_RF.error_category\n",
    "# X = df_valid_RF.drop(['y_actual','y_pred','error_category'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# sample_ratio = 1\n",
    "# n_samples = int(len(X)*sample_ratio)\n",
    "# X, y = resample(X, y, n_samples=n_samples, stratify=y, random_state=10)\n",
    "# model_RF_error_cat = copy.deepcopy(pipe)\n",
    "# model_RF_error_cat.set_params(**best_params2)\n",
    "# model_RF_error_cat.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "# print(\"_\"*150)\n",
    "# print(\"\")\n",
    "# print(\"Train Accuracy:\")\n",
    "# print(\"\")\n",
    "\n",
    "# y_pred = model_RF_error_cat.predict(X)\n",
    "# y_pred_proba = model_RF_error_cat.predict_proba(X)\n",
    "\n",
    "# cm = multilabel_confusion_matrix(y, y_pred)\n",
    "# plot_confusion_matrix(model_RF_error_cat, X, y, display_labels=['TN','FP','TP','FN'])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # display_labels=['TN','FP','TP','FN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_train_imputed_scaled = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_valid)\n",
    "X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "X_valid_scaled__array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "X_valid_imputed_scaled = pd.DataFrame(X_valid_scaled__array, columns=X_valid.columns)\n",
    "\n",
    "\n",
    "y_error_t = clf.predict(X_train_imputed_scaled)\n",
    "y_error_v = clf.predict(X_valid_imputed_scaled)\n",
    "\n",
    "# True Negatives (0)\n",
    "X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "X_valid_TN = X_valid.loc[(y_error_v==0)]\n",
    "y_valid_TN = y_valid.loc[(y_error_v==0)]\n",
    "\n",
    "# False Positives (1)\n",
    "X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "X_valid_FP = X_valid.loc[(y_error_v==1)]\n",
    "y_valid_FP = y_valid.loc[(y_error_v==1)]\n",
    "\n",
    "# True Positives (2)\n",
    "X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "X_valid_TP = X_valid.loc[(y_error_v==2)]\n",
    "y_valid_TP = y_valid.loc[(y_error_v==2)]\n",
    "\n",
    "# False Negatives (3)\n",
    "X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "X_valid_FN = X_valid.loc[(y_error_v==3)]\n",
    "y_valid_FN = y_valid.loc[(y_error_v==3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_error_v==3)\n",
    "# y_valid_TP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y_error_v==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_FN.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_True, y_train_True = up_sample(X_train_True, y_train_True,'outcome')\n",
    "# X_train_False, y_train_False = up_sample(X_train_False, y_train_False,'outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TN estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 250, 'model__min_samples_split': 250}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_TN)*sample_ratio)\n",
    "X, y = resample(X_train_TN.values, y_train_TN.values, n_samples=n_samples, stratify=y_train_TN.values, random_state=10)\n",
    "model_final_TN = copy.deepcopy(pipe)\n",
    "model_final_TN.set_params(**best_params2)\n",
    "model_final_TN.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_TN.predict(X)\n",
    "y_pred_proba = model_final_TN.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_FP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_TN.values, y_valid_TN.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_TN.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 40\n",
    ",'model__min_samples_leaf': 50, 'model__min_samples_split': 50}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_FP)*sample_ratio)\n",
    "X, y = resample(X_train_FP.values, y_train_FP.values, n_samples=n_samples, stratify=y_train_FP.values, random_state=10)\n",
    "model_final_FP = copy.deepcopy(pipe)\n",
    "model_final_FP.set_params(**best_params2)\n",
    "model_final_FP.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_FP.predict(X)\n",
    "y_pred_proba = model_final_FP.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_FP.values, y_valid_FP.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_FP.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 150, 'model__min_samples_split': 150}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_TP)*sample_ratio)\n",
    "X, y = resample(X_train_TP.values, y_train_TP.values, n_samples=n_samples, stratify=y_train_TP.values, random_state=10)\n",
    "model_final_TP = copy.deepcopy(pipe)\n",
    "model_final_TP.set_params(**best_params2)\n",
    "model_final_TP.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_TP.predict(X)\n",
    "y_pred_proba = model_final_TP.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_TP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_TP.values, y_valid_TP.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_TP.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FN estimitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 250, 'model__min_samples_split': 250}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_FN)*sample_ratio)\n",
    "X, y = resample(X_train_FN.values, y_train_FN.values, n_samples=n_samples, stratify=y_train_FN.values, random_state=10)\n",
    "model_final_FN = copy.deepcopy(pipe)\n",
    "model_final_FN.set_params(**best_params2)\n",
    "model_final_FN.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_FN.predict(X)\n",
    "y_pred_proba = model_final_FN.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_FN.values, y_valid_FN.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_FN.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = X_test, y_test\n",
    "\n",
    "y_pred_proba_list = []\n",
    "for i in range(len(X)):\n",
    "    # X_imputed = model_final.named_steps['imputer'].transform(X.iloc[[i]])\n",
    "    X_valid_imputed_array = model_final.named_steps['imputer'].transform(X.iloc[[i]])\n",
    "    X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "    X_valid_scaled_array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "    df_test_all = pd.DataFrame(X_valid_scaled_array, columns=X_valid.columns)\n",
    "    tree_predict = clf.predict(df_test_all)\n",
    "    if(tree_predict == 0): #TN\n",
    "        y_pred_proba_list.insert(i, list(model_final_TN.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 1): #FP\n",
    "        y_pred_proba_list.insert(i, list(model_final_FP.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 2): #TP\n",
    "        y_pred_proba_list.insert(i, list(model_final_TP.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 3): #FN\n",
    "        y_pred_proba_list.insert(i, list(model_final_FN.predict_proba(X.iloc[[i]])[0]))\n",
    "\n",
    "y_pred_proba = np.array(y_pred_proba_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7ea45291871ad6e398ab50f9f84dad559e0de667f49db4aea6ebf0e175149ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
