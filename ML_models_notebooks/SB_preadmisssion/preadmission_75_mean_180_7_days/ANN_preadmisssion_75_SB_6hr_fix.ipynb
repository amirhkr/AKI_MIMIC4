{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/src')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "from dfwiz import dfwiz\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from utils.vis import spy, look, plot_nunique, plot_dists\n",
    "from utils.processing import sort, impute, replace_inf, drop_empty, select, drop_by_nunique, scale, melt, unmelt, \\\n",
    "                             remove_outliers, get_categories, filter_categorical, onehot, filter_regex, match, cap,get_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables representing experiment parameters\n",
    "EXPERIMENT = 'Processing Demo'\n",
    "IMPUTE_NUM = 'constant'\n",
    "IMPUTE_CAT = 'other'\n",
    "FIGSIZE    = [12,3]\n",
    "\n",
    "# parameter dict\n",
    "params = {\n",
    "    'experiment':EXPERIMENT,\n",
    "    'figsize'   :FIGSIZE,\n",
    "    'impute_num':IMPUTE_NUM,\n",
    "    'impute_cat':IMPUTE_CAT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy as sp\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn')\n",
    "sns.set_theme(style=\"ticks\")\n",
    "mpl.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "# Title\n",
    "mpl.rcParams['figure.titlesize'] = 22\n",
    "mpl.rcParams['figure.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlesize'] = 22\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlepad'] = 20\n",
    "\n",
    "# Axes labels\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "\n",
    "# Grid and thicks\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['axes.grid.axis'] = 'y'\n",
    "#mpl.rcParams['axes.xmargin'] = 0\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "\n",
    "# Legend\n",
    "mpl.rcParams['legend.facecolor'] = 'w'\n",
    "mpl.rcParams['legend.title_fontsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['legend.frameon'] = True\n",
    "mpl.rcParams['legend.framealpha'] = 1\n",
    "mpl.rcParams['legend.fancybox'] = True\n",
    "mpl.rcParams['legend.facecolor'] = 'white'\n",
    "mpl.rcParams['legend.edgecolor'] = 'blue'\n",
    "mpl.rcParams['legend.borderpad'] = 0.6\n",
    "\n",
    "# Other\n",
    "mpl.rcParams['lines.linewidth'] = 2.5\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['scatter.edgecolors'] = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### upsampler func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "class upsampler(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        return X\n",
    "\n",
    "    def sample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y[y == 0]], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y[y == 1]], y[y == 1]\n",
    "        else:\n",
    "            print(X[y[y == 0]].shape)\n",
    "            X1, y1 = resample(X[y[y == 1]], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y[y == 0]], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "\n",
    "        return X_out, y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### accuracy func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y, y_pred, y_pred_proba):\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "    score = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.plot(fpr,tpr,label=\"AUC=\"+str(round(score,2)))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    # print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "    cr = classification_report(y, y_pred)\n",
    "    print(\"\\r\\n\"+\"Classification report\"+\"\\r\\n\")\n",
    "    print(cr)\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    print(\"\\r\\n\"+\"Specificity\"+\"\\r\\n\")\n",
    "    print(round(specificity,2))\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def up_sample(X_train_raw, y_train_raw,col_name):\n",
    "\n",
    "    # upsampling X_train and y_train\n",
    "    df_upsampled = pd.merge(X_train_raw, y_train_raw, left_index=True, right_index=True)\n",
    "\n",
    "    X_minority = df_upsampled[df_upsampled[col_name]==1]\n",
    "    X_majority = df_upsampled[df_upsampled[col_name]!=1]\n",
    "\n",
    "    n_samples = X_majority.shape[0]\n",
    "    X_minority_upsampled = resample(X_minority,\n",
    "                                    replace=True,     # sample with replacement\n",
    "                                    n_samples=n_samples,    # to match majority class\n",
    "                                    random_state=42) # reproducible results\n",
    "\n",
    "    df_upsampled = pd.concat([X_majority, X_minority_upsampled]).sample(frac=1)\n",
    "\n",
    "    y_train_out = df_upsampled[[col_name]]\n",
    "    X_train_out = df_upsampled.drop([col_name], axis=1)\n",
    "\n",
    "    return X_train_out, y_train_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### define cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "def param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 5, sample_ratio = 0.2, refit=True, use_error=True, multi_class=False, average_metric='macro'):\n",
    "\n",
    "    print(\"This search selects lower indexes of search list if their score is within the error of maximum score.\")\n",
    "    print(\"Putting parameters for less complicated model on the left side of the grid lists leads to better generalisation. \")\n",
    "    print(\" \")\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    n_train = int(sample_ratio * len(y_train))\n",
    "    X_train_s, y_train_s  = resample(X_train, y_train, n_samples=n_train, stratify=y_train)\n",
    "\n",
    "    best_score = {}\n",
    "    best_params = {}\n",
    "    for k, v in param_grid.items():\n",
    "        # best_params[k] = v[int(len(v)/2)-1]\n",
    "        best_params[k] = v[0]\n",
    "    best_params_m1 = best_params.copy()\n",
    "    print(\"start_params:\", best_params)\n",
    "\n",
    "    score = {}\n",
    "    score_std = {}\n",
    "\n",
    "    for i_iter in range(max_iter):\n",
    "        print(\"_\"*100)\n",
    "        print(\"Iteration\", i_iter)\n",
    "\n",
    "        for k, v in param_grid.items():\n",
    "\n",
    "            best_params1 = best_params.copy()\n",
    "            del best_params1[k]  \n",
    "\n",
    "            score[k] = v.copy()\n",
    "            score_std[k] = v.copy()\n",
    "\n",
    "            for i_param, val_param in enumerate(v):\n",
    "                cv_sc = np.zeros(cv)\n",
    "\n",
    "                for i_cv in range(cv):\n",
    "\n",
    "                    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train_s, y_train_s, test_size=0.2, stratify=y_train_s, shuffle=True) # 80% training and 20% test\n",
    "\n",
    "                    p1 = copy.deepcopy(pipe)\n",
    "                    p1.set_params(**best_params1)\n",
    "                    params2 = {k:val_param}\n",
    "                    p1.set_params(**params2)\n",
    "\n",
    "                    p1.fit(X_train2, y_train2.ravel())\n",
    "                    # X,y = p1.named_steps['resample'].fit_resample(X_test2, y_test2)\n",
    "                    X,y = X_test2, y_test2\n",
    "                    # y_pred_proba = p1.predict_proba(X)\n",
    "                    # cv_sc[i_cv] = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "                    y_pred = p1.predict(X)\n",
    "                    if(multi_class):\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred, average=average_metric)\n",
    "                    else:\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred)\n",
    "\n",
    "                    i_cv = i_cv + 1\n",
    "\n",
    "                score[k][i_param] = cv_sc.mean()\n",
    "                score_std[k][i_param] = cv_sc.std()\n",
    "\n",
    "            print(\"\")\n",
    "            print(k)\n",
    "            print(v)\n",
    "            print(score[k])\n",
    "\n",
    "            best_params[k] = v[np.argmax(score[k])]\n",
    "            best_score[k] = score[k][np.argmax(score[k])]\n",
    "\n",
    "            if use_error:\n",
    "                for i_b in  range(np.argmax(score[k]),-1,-1):\n",
    "                    err1 = (score_std[k][i_b] + score_std[k][v.index(best_params[k])] ) / 4\n",
    "                    # print(\"err1\")\n",
    "                    max_del = max(score[k]) - err1\n",
    "                    # print( i_b, score[k][i_b], max(score[k]), err1, max_del )\n",
    "                    if score[k][i_b] >= max_del:\n",
    "                        best_params[k] = v[i_b]\n",
    "                        best_score[k] = score[k][i_b]\n",
    "\n",
    "            print(\"best_param:\",  v[np.argmax(score[k])], \"score:\", max(score[k]))\n",
    "            print(\"selected_param:\",  best_params[k], \"score:\", best_score[k])\n",
    "            \n",
    "\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"best_params =\", best_params)\n",
    "        print(\"\")\n",
    "        if best_params_m1 == best_params:\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "            print(\"Early stop. No improvement in the last iteration.\")\n",
    "            break\n",
    "        best_params_m1 = best_params.copy()\n",
    "\n",
    "    param_graph_plot(score)\n",
    "\n",
    "    if refit:\n",
    "        print(\"Refitting final model...\")\n",
    "        model_final = copy.deepcopy(pipe)\n",
    "        model_final.set_params(**best_params)\n",
    "        model_final.fit(X_train, y_train.values.ravel())\n",
    "    else:\n",
    "        model_final = None\n",
    "\n",
    "    return score, best_params, model_final\n",
    "    \n",
    "\n",
    "def param_graph_plot(score):\n",
    "    ax = {}\n",
    "    fig = {}\n",
    "    for i, (k, v) in enumerate(score.items()):\n",
    "        fig[k], ax[k] = plt.subplots()\n",
    "\n",
    "    for k, v in score.items():\n",
    "        x = score[k]\n",
    "        y = v\n",
    "        ax[k].plot(x,y,\"-o\", label=\"Score\")\n",
    "        # ax[k].set_ylim([0.5, 1])\n",
    "        ax[k].set_title(k)\n",
    "        ax[k].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Define upsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "class upsampler(BaseEstimator): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def fit_resample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).ravel()\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y == 0], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y == 1], y[y == 1]\n",
    "        else:\n",
    "            X1, y1 = resample(X[y == 1], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y == 0], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "        return X_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Load data and select index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table from database\n",
    "# database = \"data.sqlite\"\n",
    "# con = sqlite3.connect(database)\n",
    "\n",
    "# X_train = pd.read_sql_query(\"SELECT * from X_train\", con)\n",
    "# y_train = pd.read_sql_query(\"SELECT * from y_train\", con)\n",
    "# # select index\n",
    "# index_c = ['USUBJID'] # empty list for no index\n",
    "# X_train = X_train.set_index(index_c)\n",
    "# y_train = y_train.set_index(index_c)\n",
    "\n",
    "# X_train1 = X_train[~X_train.scr_umol_l.isna()]\n",
    "# y_train1 = y_train[~X_train.scr_umol_l.isna()]\n",
    "\n",
    "# X_test = pd.read_sql_query(\"SELECT * from X_test\", con)\n",
    "# y_test = pd.read_sql_query(\"SELECT * from y_test\", con)\n",
    "# # select index\n",
    "# index_c = ['USUBJID'] # empty list for no index\n",
    "# X_test = X_test.set_index(index_c)\n",
    "# y_test = y_test.set_index(index_c)\n",
    "\n",
    "# y_test = y_test[~X_test.scr_umol_l.isna()]\n",
    "# X_test = X_test[~X_test.scr_umol_l.isna()]\n",
    "\n",
    "\n",
    "# X_train, y_train  = resample(X_train, y_train, n_samples=5000, stratify=y_train)\n",
    "# X_test, y_test  = resample(X_test, y_test, n_samples=1000, stratify=y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "sqluser = 'uqhkamel'\n",
    "dbname = 'mimiciv'\n",
    "schema_name = 'mimic_derived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to {}'.format(schema_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select * from all_scr_preadmission_75_JOIN\"\n",
    "# data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id','hadm_id'])\n",
    "\n",
    "query = \"select * from all_scr_preadmission_75_JOIN_6hr_fix\"\n",
    "data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id'])\n",
    "data.drop('hadm_id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ethnicity'] = data['ethnicity'].replace(['OTHER'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNKNOWN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['AMERICAN INDIAN/ALASKA NATIVE'],np.nan)\n",
    "\n",
    "data = data.fillna(value=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data[\"min_day_rrt_present\"]<=1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aki_kdigo = ['aki_kdigo_grade_1','aki_kdigo_grade_2','aki_kdigo_grade_3']\n",
    "\n",
    "# outcome_var = ['day_detection_kdigo_grade_1','day_detection_kdigo_grade_2','day_detection_kdigo_grade_3']\n",
    "\n",
    "# outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "outcome_var = ['day_detection_kdigo_grade_1']\n",
    "\n",
    "first_24h = 1\n",
    "data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = []\n",
    "outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "first_24h = 1\n",
    "data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2276, 111)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"ckd\"]==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['ckd']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 111)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"kidney_transplant\"]==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['kidney_transplant']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data['egfr_mdrd_scr']>60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28030, 111)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aki_kdigo_grade_1</th>\n",
       "      <th>aki_kdigo_grade_2</th>\n",
       "      <th>aki_kdigo_grade_3</th>\n",
       "      <th>day_detection_kdigo_grade_1</th>\n",
       "      <th>day_detection_kdigo_grade_2</th>\n",
       "      <th>day_detection_kdigo_grade_3</th>\n",
       "      <th>aki_mkdigo_grade_1</th>\n",
       "      <th>aki_mkdigo_grade_2</th>\n",
       "      <th>aki_mkdigo_grade_3</th>\n",
       "      <th>day_detection_mkdigo_grade_1</th>\n",
       "      <th>day_detection_mkdigo_grade_2</th>\n",
       "      <th>day_detection_mkdigo_grade_3</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>ckd</th>\n",
       "      <th>is_mdrd</th>\n",
       "      <th>egfr_epi_scr</th>\n",
       "      <th>egfr_mdrd_scr</th>\n",
       "      <th>kidney_transplant</th>\n",
       "      <th>congestive_heart_failure</th>\n",
       "      <th>diabetes_type2</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>obesity_icd</th>\n",
       "      <th>peripheral_vascular_disease</th>\n",
       "      <th>chronic_liver_disease</th>\n",
       "      <th>mild_liver_disease</th>\n",
       "      <th>severe_liver_disease</th>\n",
       "      <th>myocardial_infarct</th>\n",
       "      <th>chronic_pulmonary_disease</th>\n",
       "      <th>chronic_heart_failure</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>hemoglobin_min</th>\n",
       "      <th>hemoglobin_max</th>\n",
       "      <th>platelets_min</th>\n",
       "      <th>platelets_max</th>\n",
       "      <th>wbc_min</th>\n",
       "      <th>wbc_max</th>\n",
       "      <th>wbc_bd_min</th>\n",
       "      <th>wbc_bd_max</th>\n",
       "      <th>albumin_min</th>\n",
       "      <th>albumin_max</th>\n",
       "      <th>globulin_min</th>\n",
       "      <th>globulin_max</th>\n",
       "      <th>total_protein_min</th>\n",
       "      <th>total_protein_max</th>\n",
       "      <th>aniongap_min</th>\n",
       "      <th>aniongap_max</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>bun_min</th>\n",
       "      <th>bun_max</th>\n",
       "      <th>calcium_min</th>\n",
       "      <th>calcium_max</th>\n",
       "      <th>chloride_min</th>\n",
       "      <th>chloride_max</th>\n",
       "      <th>creatinine_min</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>glucose_min</th>\n",
       "      <th>glucose_max</th>\n",
       "      <th>sodium_min</th>\n",
       "      <th>sodium_max</th>\n",
       "      <th>potassium_min</th>\n",
       "      <th>potassium_max</th>\n",
       "      <th>pt_min</th>\n",
       "      <th>pt_max</th>\n",
       "      <th>thrombin_min</th>\n",
       "      <th>thrombin_max</th>\n",
       "      <th>ptt_min</th>\n",
       "      <th>ptt_max</th>\n",
       "      <th>inr_min</th>\n",
       "      <th>inr_max</th>\n",
       "      <th>bilirubin_total_min</th>\n",
       "      <th>bilirubin_total_max</th>\n",
       "      <th>egfr_epi_scr_max</th>\n",
       "      <th>egfr_mdrd_scr_max</th>\n",
       "      <th>heart_rate_min</th>\n",
       "      <th>heart_rate_max</th>\n",
       "      <th>heart_rate_mean</th>\n",
       "      <th>sbp_min</th>\n",
       "      <th>sbp_max</th>\n",
       "      <th>sbp_mean</th>\n",
       "      <th>dbp_min</th>\n",
       "      <th>dbp_max</th>\n",
       "      <th>dbp_mean</th>\n",
       "      <th>resp_rate_min</th>\n",
       "      <th>resp_rate_max</th>\n",
       "      <th>resp_rate_mean</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>arbs_acei</th>\n",
       "      <th>cyclosporine</th>\n",
       "      <th>bmi</th>\n",
       "      <th>urineoutput_24hr</th>\n",
       "      <th>supplemental_oxygen</th>\n",
       "      <th>invasive_vent</th>\n",
       "      <th>hfnc</th>\n",
       "      <th>non_invasive_vent</th>\n",
       "      <th>tracheostomy</th>\n",
       "      <th>min_day_rrt_present</th>\n",
       "      <th>min_day_rrt_active</th>\n",
       "      <th>weight_admit</th>\n",
       "      <th>weight_min</th>\n",
       "      <th>weight_max</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30283046</th>\n",
       "      <th>10777271</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>179.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>15.3</td>\n",
       "      <td>13.6</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.7</td>\n",
       "      <td>32.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>90.150000</td>\n",
       "      <td>111.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>118.550000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.904762</td>\n",
       "      <td>37.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>37.568750</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>83.5</td>\n",
       "      <td>83.5</td>\n",
       "      <td>83.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36223916</th>\n",
       "      <th>10135398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>39.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.3</td>\n",
       "      <td>135.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>135.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.3</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>103.640000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>133.037037</td>\n",
       "      <td>47.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>75.444444</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.944444</td>\n",
       "      <td>37.28</td>\n",
       "      <td>38.39</td>\n",
       "      <td>37.843333</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.04</td>\n",
       "      <td>675.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>87.3</td>\n",
       "      <td>87.3</td>\n",
       "      <td>87.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39625809</th>\n",
       "      <th>19016548</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>194.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>89.387097</td>\n",
       "      <td>88.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>126.965517</td>\n",
       "      <td>31.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>41.724138</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>36.50</td>\n",
       "      <td>39.00</td>\n",
       "      <td>37.701000</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.20</td>\n",
       "      <td>550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>90.3</td>\n",
       "      <td>90.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37944322</th>\n",
       "      <th>12187566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>95.166667</td>\n",
       "      <td>87.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>98.880000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.800000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.680000</td>\n",
       "      <td>35.44</td>\n",
       "      <td>37.22</td>\n",
       "      <td>36.402500</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.73</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>86.5</td>\n",
       "      <td>96.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33754541</th>\n",
       "      <th>19510789</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.2</td>\n",
       "      <td>29.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>68.615385</td>\n",
       "      <td>94.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>120.884615</td>\n",
       "      <td>40.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>52.192308</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.769231</td>\n",
       "      <td>36.78</td>\n",
       "      <td>37.22</td>\n",
       "      <td>36.935000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aki_kdigo_grade_1  aki_kdigo_grade_2  aki_kdigo_grade_3  \\\n",
       "stay_id  subject_id                                                            \n",
       "30283046 10777271                    0                  0                  0   \n",
       "36223916 10135398                    0                  0                  0   \n",
       "39625809 19016548                    1                  0                  0   \n",
       "37944322 12187566                    0                  0                  0   \n",
       "33754541 19510789                    0                  0                  0   \n",
       "\n",
       "                     day_detection_kdigo_grade_1  day_detection_kdigo_grade_2  \\\n",
       "stay_id  subject_id                                                             \n",
       "30283046 10777271                      9999999.0                    9999999.0   \n",
       "36223916 10135398                      9999999.0                    9999999.0   \n",
       "39625809 19016548                            2.0                    9999999.0   \n",
       "37944322 12187566                      9999999.0                    9999999.0   \n",
       "33754541 19510789                      9999999.0                    9999999.0   \n",
       "\n",
       "                     day_detection_kdigo_grade_3  aki_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                                    \n",
       "30283046 10777271                      9999999.0                   1   \n",
       "36223916 10135398                      9999999.0                   1   \n",
       "39625809 19016548                      9999999.0                   1   \n",
       "37944322 12187566                      9999999.0                   0   \n",
       "33754541 19510789                      9999999.0                   0   \n",
       "\n",
       "                     aki_mkdigo_grade_2  aki_mkdigo_grade_3  \\\n",
       "stay_id  subject_id                                           \n",
       "30283046 10777271                     0                   0   \n",
       "36223916 10135398                     0                   0   \n",
       "39625809 19016548                     0                   0   \n",
       "37944322 12187566                     0                   0   \n",
       "33754541 19510789                     0                   0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                 \n",
       "30283046 10777271                             2.0   \n",
       "36223916 10135398                             1.0   \n",
       "39625809 19016548                             2.0   \n",
       "37944322 12187566                       9999999.0   \n",
       "33754541 19510789                       9999999.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_2  \\\n",
       "stay_id  subject_id                                 \n",
       "30283046 10777271                       9999999.0   \n",
       "36223916 10135398                       9999999.0   \n",
       "39625809 19016548                       9999999.0   \n",
       "37944322 12187566                       9999999.0   \n",
       "33754541 19510789                       9999999.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_3   age  female ethnicity  \\\n",
       "stay_id  subject_id                                                         \n",
       "30283046 10777271                       9999999.0  54.0       0       NaN   \n",
       "36223916 10135398                       9999999.0  59.0       0     WHITE   \n",
       "39625809 19016548                       9999999.0  42.0       0       NaN   \n",
       "37944322 12187566                       9999999.0  68.0       1       NaN   \n",
       "33754541 19510789                       9999999.0  85.0       1       NaN   \n",
       "\n",
       "                     ckd  is_mdrd  egfr_epi_scr  egfr_mdrd_scr  \\\n",
       "stay_id  subject_id                                              \n",
       "30283046 10777271      0        1          62.0           58.0   \n",
       "36223916 10135398      0        1          75.0           71.0   \n",
       "39625809 19016548      0        1          67.0           61.0   \n",
       "37944322 12187566      0        1          66.0           62.0   \n",
       "33754541 19510789      0        1          51.0           53.0   \n",
       "\n",
       "                     kidney_transplant  congestive_heart_failure  \\\n",
       "stay_id  subject_id                                                \n",
       "30283046 10777271                    0                         0   \n",
       "36223916 10135398                    0                         0   \n",
       "39625809 19016548                    0                         1   \n",
       "37944322 12187566                    0                         0   \n",
       "33754541 19510789                    0                         0   \n",
       "\n",
       "                     diabetes_type2  chronic_kidney_disease  hypertension  \\\n",
       "stay_id  subject_id                                                         \n",
       "30283046 10777271                 0                       0             1   \n",
       "36223916 10135398                 0                       0             0   \n",
       "39625809 19016548                 1                       0             0   \n",
       "37944322 12187566                 0                       0             1   \n",
       "33754541 19510789                 0                       0             1   \n",
       "\n",
       "                     obesity_icd  peripheral_vascular_disease  \\\n",
       "stay_id  subject_id                                             \n",
       "30283046 10777271              0                            0   \n",
       "36223916 10135398              0                            0   \n",
       "39625809 19016548              0                            0   \n",
       "37944322 12187566              0                            0   \n",
       "33754541 19510789              0                            1   \n",
       "\n",
       "                     chronic_liver_disease  mild_liver_disease  \\\n",
       "stay_id  subject_id                                              \n",
       "30283046 10777271                        0                   0   \n",
       "36223916 10135398                        0                   0   \n",
       "39625809 19016548                        0                   1   \n",
       "37944322 12187566                        0                   0   \n",
       "33754541 19510789                        0                   0   \n",
       "\n",
       "                     severe_liver_disease  myocardial_infarct  \\\n",
       "stay_id  subject_id                                             \n",
       "30283046 10777271                       0                   0   \n",
       "36223916 10135398                       0                   0   \n",
       "39625809 19016548                       0                   1   \n",
       "37944322 12187566                       0                   0   \n",
       "33754541 19510789                       0                   0   \n",
       "\n",
       "                     chronic_pulmonary_disease  chronic_heart_failure  sepsis  \\\n",
       "stay_id  subject_id                                                             \n",
       "30283046 10777271                            0                      0       0   \n",
       "36223916 10135398                            0                      0       0   \n",
       "39625809 19016548                            0                      1       1   \n",
       "37944322 12187566                            0                      0       0   \n",
       "33754541 19510789                            1                      0       0   \n",
       "\n",
       "                     hematocrit_min  hematocrit_max  hemoglobin_min  \\\n",
       "stay_id  subject_id                                                   \n",
       "30283046 10777271              41.0            42.4            13.7   \n",
       "36223916 10135398              30.8            39.2            10.8   \n",
       "39625809 19016548              25.0            25.0             7.9   \n",
       "37944322 12187566              26.0            31.5             8.7   \n",
       "33754541 19510789              37.8            37.8            12.3   \n",
       "\n",
       "                     hemoglobin_max  platelets_min  platelets_max  wbc_min  \\\n",
       "stay_id  subject_id                                                          \n",
       "30283046 10777271              14.7          179.0          204.0     13.6   \n",
       "36223916 10135398              13.3          135.0          185.0      6.8   \n",
       "39625809 19016548               7.9          194.0          194.0      NaN   \n",
       "37944322 12187566              10.6           96.0          143.0     11.0   \n",
       "33754541 19510789              12.3          158.0          158.0      6.7   \n",
       "\n",
       "                     wbc_max  wbc_bd_min  wbc_bd_max  albumin_min  \\\n",
       "stay_id  subject_id                                                 \n",
       "30283046 10777271       15.3        13.6        15.3          3.5   \n",
       "36223916 10135398        9.2         6.8         9.2          4.0   \n",
       "39625809 19016548        NaN         NaN         NaN          NaN   \n",
       "37944322 12187566       17.9        11.0        17.9          NaN   \n",
       "33754541 19510789        6.7         6.7         6.7          NaN   \n",
       "\n",
       "                     albumin_max  globulin_min  globulin_max  \\\n",
       "stay_id  subject_id                                            \n",
       "30283046 10777271            3.5           NaN           NaN   \n",
       "36223916 10135398            4.0           NaN           NaN   \n",
       "39625809 19016548            NaN           NaN           NaN   \n",
       "37944322 12187566            NaN           NaN           NaN   \n",
       "33754541 19510789            NaN           NaN           NaN   \n",
       "\n",
       "                     total_protein_min  total_protein_max  aniongap_min  \\\n",
       "stay_id  subject_id                                                       \n",
       "30283046 10777271                  NaN                NaN          12.0   \n",
       "36223916 10135398                  NaN                NaN          16.0   \n",
       "39625809 19016548                  NaN                NaN          13.0   \n",
       "37944322 12187566                  NaN                NaN           7.0   \n",
       "33754541 19510789                  NaN                NaN          12.0   \n",
       "\n",
       "                     aniongap_max  bicarbonate_min  bicarbonate_max  bun_min  \\\n",
       "stay_id  subject_id                                                            \n",
       "30283046 10777271            14.0             20.0             22.0     10.0   \n",
       "36223916 10135398            23.0             20.0             26.0      7.0   \n",
       "39625809 19016548            13.0             23.0             23.0     55.0   \n",
       "37944322 12187566            12.0             19.0             26.0      8.0   \n",
       "33754541 19510789            12.0             24.0             24.0     22.0   \n",
       "\n",
       "                     bun_max  calcium_min  calcium_max  chloride_min  \\\n",
       "stay_id  subject_id                                                    \n",
       "30283046 10777271       15.0          7.0          8.0         113.0   \n",
       "36223916 10135398        9.0          7.6          8.3         100.0   \n",
       "39625809 19016548       55.0          8.0          8.0          95.0   \n",
       "37944322 12187566       10.0          NaN          NaN         106.0   \n",
       "33754541 19510789       22.0          9.5          9.5         108.0   \n",
       "\n",
       "                     chloride_max  creatinine_min  creatinine_max  \\\n",
       "stay_id  subject_id                                                 \n",
       "30283046 10777271           116.0             1.2             1.3   \n",
       "36223916 10135398           104.0             0.6             0.8   \n",
       "39625809 19016548            95.0             1.0             1.0   \n",
       "37944322 12187566           109.0             0.7             0.9   \n",
       "33754541 19510789           108.0             0.9             0.9   \n",
       "\n",
       "                     glucose_min  glucose_max  sodium_min  sodium_max  \\\n",
       "stay_id  subject_id                                                     \n",
       "30283046 10777271           94.0        151.0       144.0       146.0   \n",
       "36223916 10135398          135.0        185.0       139.0       144.0   \n",
       "39625809 19016548          193.0        193.0       131.0       131.0   \n",
       "37944322 12187566           90.0         90.0       139.0       139.0   \n",
       "33754541 19510789           95.0         95.0       144.0       144.0   \n",
       "\n",
       "                     potassium_min  potassium_max  pt_min  pt_max  \\\n",
       "stay_id  subject_id                                                 \n",
       "30283046 10777271              3.2            3.4    11.3    11.3   \n",
       "36223916 10135398              2.9            3.8    11.0    12.6   \n",
       "39625809 19016548              4.7            4.7    17.7    17.7   \n",
       "37944322 12187566              NaN            NaN    14.1    16.9   \n",
       "33754541 19510789              4.2            4.2    11.0    11.0   \n",
       "\n",
       "                     thrombin_min  thrombin_max  ptt_min  ptt_max  inr_min  \\\n",
       "stay_id  subject_id                                                          \n",
       "30283046 10777271             NaN           NaN     32.7     32.7      1.0   \n",
       "36223916 10135398             NaN           NaN     26.3     27.7      1.0   \n",
       "39625809 19016548             NaN           NaN     30.1     30.1      1.6   \n",
       "37944322 12187566             NaN           NaN     26.0     33.2      1.3   \n",
       "33754541 19510789             NaN           NaN     29.2     29.2      1.0   \n",
       "\n",
       "                     inr_max  bilirubin_total_min  bilirubin_total_max  \\\n",
       "stay_id  subject_id                                                      \n",
       "30283046 10777271        1.0                  0.2                  0.2   \n",
       "36223916 10135398        1.2                  1.3                  1.3   \n",
       "39625809 19016548        1.6                  1.1                  1.1   \n",
       "37944322 12187566        1.6                  NaN                  NaN   \n",
       "33754541 19510789        1.0                  NaN                  NaN   \n",
       "\n",
       "                     egfr_epi_scr_max  egfr_mdrd_scr_max  heart_rate_min  \\\n",
       "stay_id  subject_id                                                        \n",
       "30283046 10777271                62.0               58.0            83.0   \n",
       "36223916 10135398                98.0               99.0            86.0   \n",
       "39625809 19016548                92.0               82.0            71.0   \n",
       "37944322 12187566                66.0               62.0            83.0   \n",
       "33754541 19510789                58.0               60.0            56.0   \n",
       "\n",
       "                     heart_rate_max  heart_rate_mean  sbp_min  sbp_max  \\\n",
       "stay_id  subject_id                                                      \n",
       "30283046 10777271             101.0        90.150000    111.0    143.0   \n",
       "36223916 10135398             127.0       103.640000     85.0    166.0   \n",
       "39625809 19016548             131.0        89.387097     88.0    147.0   \n",
       "37944322 12187566             104.0        95.166667     87.0    127.0   \n",
       "33754541 19510789              79.0        68.615385     94.0    160.0   \n",
       "\n",
       "                       sbp_mean  dbp_min  dbp_max   dbp_mean  resp_rate_min  \\\n",
       "stay_id  subject_id                                                           \n",
       "30283046 10777271    118.550000     62.0    100.0  78.000000           13.0   \n",
       "36223916 10135398    133.037037     47.0    106.0  75.444444           10.0   \n",
       "39625809 19016548    126.965517     31.0     59.0  41.724138           10.0   \n",
       "37944322 12187566     98.880000     57.0     80.0  66.800000           11.0   \n",
       "33754541 19510789    120.884615     40.0    104.0  52.192308           14.0   \n",
       "\n",
       "                     resp_rate_max  resp_rate_mean  temperature_min  \\\n",
       "stay_id  subject_id                                                   \n",
       "30283046 10777271             23.0       16.904762            37.00   \n",
       "36223916 10135398             28.0       15.944444            37.28   \n",
       "39625809 19016548             25.0       23.200000            36.50   \n",
       "37944322 12187566             24.0       17.680000            35.44   \n",
       "33754541 19510789             26.0       17.769231            36.78   \n",
       "\n",
       "                     temperature_max  temperature_mean  spo2_min  spo2_max  \\\n",
       "stay_id  subject_id                                                          \n",
       "30283046 10777271              39.00         37.568750      95.0     100.0   \n",
       "36223916 10135398              38.39         37.843333      91.0     100.0   \n",
       "39625809 19016548              39.00         37.701000      95.0     100.0   \n",
       "37944322 12187566              37.22         36.402500      94.0     100.0   \n",
       "33754541 19510789              37.22         36.935000      93.0      98.0   \n",
       "\n",
       "                     arbs_acei  cyclosporine    bmi  urineoutput_24hr  \\\n",
       "stay_id  subject_id                                                     \n",
       "30283046 10777271            0             0    NaN            1500.0   \n",
       "36223916 10135398            0             0  49.04             675.0   \n",
       "39625809 19016548            1             0  52.20             550.0   \n",
       "37944322 12187566            0             0  53.73             275.0   \n",
       "33754541 19510789            1             0    NaN             400.0   \n",
       "\n",
       "                     supplemental_oxygen  invasive_vent  hfnc  \\\n",
       "stay_id  subject_id                                             \n",
       "30283046 10777271                      0              0     0   \n",
       "36223916 10135398                      0              0     0   \n",
       "39625809 19016548                      0              1     0   \n",
       "37944322 12187566                      1              1     0   \n",
       "33754541 19510789                      0              0     0   \n",
       "\n",
       "                     non_invasive_vent  tracheostomy  min_day_rrt_present  \\\n",
       "stay_id  subject_id                                                         \n",
       "30283046 10777271                    0             0           99999999.0   \n",
       "36223916 10135398                    0             0           99999999.0   \n",
       "39625809 19016548                    0             0           99999999.0   \n",
       "37944322 12187566                    0             0           99999999.0   \n",
       "33754541 19510789                    0             0           99999999.0   \n",
       "\n",
       "                     min_day_rrt_active  weight_admit  weight_min  weight_max  \\\n",
       "stay_id  subject_id                                                             \n",
       "30283046 10777271            99999999.0          83.5        83.5        83.5   \n",
       "36223916 10135398            99999999.0          87.3        87.3        87.3   \n",
       "39625809 19016548            99999999.0          90.3        90.3        90.3   \n",
       "37944322 12187566            99999999.0          86.5        86.5        96.1   \n",
       "33754541 19510789            99999999.0          45.6        45.6        45.6   \n",
       "\n",
       "                     hospital_expire_flag  \n",
       "stay_id  subject_id                        \n",
       "30283046 10777271                       0  \n",
       "36223916 10135398                       0  \n",
       "39625809 19016548                       1  \n",
       "37944322 12187566                       0  \n",
       "33754541 19510789                       0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dropna(axis=1, thresh = int(0.8*data.shape[0]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_window = 3\n",
    "\n",
    "# data.loc[(((data['aki_kdigo_grade_1']== 1)| (data['aki_kdigo_grade_2']== 1) | (data['aki_kdigo_grade_3']==1)) \\\n",
    "#     &( (data['day_detection_kdigo_grade_1']<=prediction_window)| (data['day_detection_kdigo_grade_2']<=prediction_window) | (data['day_detection_kdigo_grade_3']<=prediction_window)) \\\n",
    "#         |(data['min_day_rrt_present']<= prediction_window)), 'outcome'] = 1\n",
    "\n",
    "\n",
    "# data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_window = 3\n",
    "\n",
    "data.loc[(( (data['aki_kdigo_grade_1']== 1)) \\\n",
    "    &( (data['day_detection_kdigo_grade_1']<=prediction_window))), 'outcome'] = 1\n",
    "\n",
    "\n",
    "data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "'day_detection_kdigo_grade_1',\n",
    "'day_detection_kdigo_grade_2',\n",
    "'day_detection_kdigo_grade_3',\n",
    "'day_detection_mkdigo_grade_1',\n",
    "'day_detection_mkdigo_grade_2',\n",
    "'day_detection_mkdigo_grade_3',\n",
    "'min_day_rrt_active',\n",
    "'min_day_rrt_present',\n",
    "'ckd',\n",
    "'chronic_kidney_disease'\n",
    "]\n",
    "# CRP and vomit_nausea as they had mostly empty\n",
    "\n",
    "data.drop(drop_X, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missingness percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.reset_index().drop_duplicates(subset=['stay_id','subject_id','hadm_id']).set_index(['stay_id','subject_id','hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove unpopulated columns\n",
    "# data.pipe(sort)\\\n",
    "#               .pipe(replace_inf).pipe(drop_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by column type\n",
    "data_num = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'numerical')\n",
    "\n",
    "data_cat = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cat = data_cat.pipe(filter_categorical, cutoff=20, plot=False)\\\n",
    "#                                             .pipe(sort).pipe(spy, title='Before onehot', figsize=[12,4])\\\n",
    "#                                             .fillna('other').pipe(onehot)\n",
    "\n",
    "data_cat = data_cat.fillna('other').pipe(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ethnicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>ASIAN</th>\n",
       "      <th>BLACK/AFRICAN AMERICAN</th>\n",
       "      <th>HISPANIC/LATINO</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30000153</th>\n",
       "      <th>12466550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001148</th>\n",
       "      <th>12980335</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001656</th>\n",
       "      <th>19609454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001947</th>\n",
       "      <th>15904173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30002415</th>\n",
       "      <th>17921898</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          len                                               \\\n",
       "variable            ethnicity                                                \n",
       "value                   ASIAN BLACK/AFRICAN AMERICAN HISPANIC/LATINO WHITE   \n",
       "stay_id  subject_id                                                          \n",
       "30000153 12466550           0                      0               0     1   \n",
       "30001148 12980335           0                      0               0     0   \n",
       "30001656 19609454           0                      0               0     1   \n",
       "30001947 15904173           0                      0               0     1   \n",
       "30002415 17921898           0                      0               0     1   \n",
       "\n",
       "                           \n",
       "variable                   \n",
       "value               other  \n",
       "stay_id  subject_id        \n",
       "30000153 12466550       0  \n",
       "30001148 12980335       1  \n",
       "30001656 19609454       0  \n",
       "30001947 15904173       0  \n",
       "30002415 17921898       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pd.merge(data_num, data_cat, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28030, 100)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4259"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.aki_kdigo_grade_1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[processed['is_mdrd']==0].aki_kdigo_grade_1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17995\n",
       "0    10035\n",
       "Name: is_mdrd, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.is_mdrd.value_counts()\n",
    "# processed['is_mdrd'].sum()/len(processed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2 = processed.copy()\n",
    "processed.drop(['egfr_epi_scr','egfr_mdrd_scr'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "    'aki_kdigo_grade_1',\n",
    "    'aki_mkdigo_grade_1',\n",
    "\n",
    "    'aki_kdigo_grade_2',\n",
    "    'aki_mkdigo_grade_2',\n",
    "\n",
    "    'aki_kdigo_grade_3',\n",
    "    'aki_mkdigo_grade_3',\n",
    "\n",
    "    'is_mdrd'\n",
    "\n",
    "]\n",
    " \n",
    "select_y = ['outcome']\n",
    "\n",
    "processed_X = processed.pipe(filter_regex, drop_X+select_y)\n",
    "processed_Y = processed.filter(regex='|'.join(select_y))\n",
    "raw_Y = data_num.pipe(replace_inf).pipe(drop_empty).filter(regex='|'.join(select_y)).pipe(remove_outliers)\n",
    "df_y = raw_Y[select_y]\n",
    "\n",
    "\n",
    "df_X, df_y = match(processed_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28030, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_X, df_y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = df_X, df_y\n",
    "X_train, y_train = up_sample(X_train, y_train,'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# rus = RandomUnderSampler(random_state=42, sampling_strategy='auto')\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0.0        23771\n",
       "1.0         4259\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class tabular_nn_model(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d_in=10, n_epochs=15, batch_size=10, lr = 0.001, drop_out=0, weight_decay=0, early_stop=True, verbose=2):\n",
    "        self.d_in = d_in\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.drop_out = drop_out\n",
    "        self.weight_decay = weight_decay  \n",
    "        self.early_stop = early_stop\n",
    "        self.verbose = verbose  \n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.net(d_in, self.drop_out)\n",
    "        self.model.to(self.device) \n",
    "\n",
    "    class net(nn.Module):\n",
    "        def __init__(self, d_in, drop_out):\n",
    "            super(tabular_nn_model.net, self).__init__()\n",
    "            # Number of input features is D_in.\n",
    "            self.layer_1 = nn.Linear(d_in, 128) \n",
    "            self.layer_2 = nn.Linear(128, 128)\n",
    "            self.layer_3 = nn.Linear(128, 128)\n",
    "            self.layer_4 = nn.Linear(128, 128)\n",
    "            self.layer_out = nn.Linear(128, 2) \n",
    "            \n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(p=drop_out)\n",
    "            self.batchnorm1 = nn.BatchNorm1d(128)\n",
    "            self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "            self.batchnorm3 = nn.BatchNorm1d(128)\n",
    "            self.batchnorm4 = nn.BatchNorm1d(128)\n",
    "\n",
    "            self.sf = nn.Softmax(dim=1)\n",
    "            \n",
    "        def forward(self, inputs):\n",
    "            x = self.relu(self.layer_1(inputs))\n",
    "            x = self.batchnorm1(x)\n",
    "\n",
    "            x = self.relu(self.layer_2(x))\n",
    "            x = self.batchnorm2(x)\n",
    "\n",
    "            x = self.relu(self.layer_3(x))\n",
    "            x = self.batchnorm3(x)\n",
    "\n",
    "            x = self.relu(self.layer_4(x))\n",
    "            x = self.batchnorm4(x)\n",
    "\n",
    "            x = self.dropout(x)\n",
    "            x = self.layer_out(x)\n",
    "            x = self.sf(x)\n",
    "            \n",
    "            return x\n",
    "\n",
    "    def fit(self, X_train, y_train, n_epochs=None):\n",
    "\n",
    "        if n_epochs != None:\n",
    "            self.n_epochs = n_epochs\n",
    "\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "        class TrainData(Dataset):\n",
    "            def __init__(self, X_data, y_data):\n",
    "                self.X_data = X_data\n",
    "                self.y_data = y_data\n",
    "                \n",
    "            def __getitem__(self, index):\n",
    "                return self.X_data[index], self.y_data[index]\n",
    "                \n",
    "            def __len__ (self):\n",
    "                return len(self.X_data)\n",
    "\n",
    "        train_data = TrainData(torch.FloatTensor(X_train), \n",
    "                            torch.FloatTensor(y_train))\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "        self.loss_array = []\n",
    "        for e in range(1, self.n_epochs+1):\n",
    "            epoch_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_pred = self.model(X_batch)\n",
    "                loss = criterion(y_pred,y_batch.long())\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "            if self.verbose == 2:\n",
    "                print(\"epoch:\", e, \", loss:\", epoch_loss/len(train_loader))\n",
    "            self.loss_array.append(epoch_loss/len(train_loader))\n",
    "\n",
    "            if self.early_stop:\n",
    "                n_av = 10\n",
    "                if e > n_av:\n",
    "                    s1 = 0 \n",
    "                    s2 = 0\n",
    "                    for i_l in range(n_av):\n",
    "                        s1 = s1 + self.loss_array[-i_l-1]-self.loss_array[-i_l-2]\n",
    "                        s2 = s2 - abs(self.loss_array[-i_l-1]-self.loss_array[-i_l-2])\n",
    "                    cond1 = s1 > (s2/10.0)\n",
    "                    # print(\"early stop\", s1, s2/10.0)\n",
    "                    if cond1:\n",
    "                        print(\"Early stopping triggered. No. of epochs:\", e)\n",
    "                        break\n",
    "        if self.verbose == 2:\n",
    "            plt.plot(self.loss_array)\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "\n",
    "        if self.verbose == 1:\n",
    "            sample = 5\n",
    "            epoch_s = [0]*sample\n",
    "            loss_s = [0]*sample\n",
    "            l_loss = len(self.loss_array)\n",
    "            for i_s in range(sample-1):\n",
    "                ii = int(i_s/(sample-1)* l_loss)\n",
    "                epoch_s[i_s] = ii+1\n",
    "                loss_s[i_s] = self.loss_array[ii]\n",
    "\n",
    "            epoch_s[i_s+1] = l_loss\n",
    "            loss_s[i_s+1] = self.loss_array[-1]            \n",
    "\n",
    "            print(\"epoch:\", epoch_s)\n",
    "            print(\"loss:\", loss_s)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        y_proba = self.model(torch.from_numpy(X).float()).detach().numpy()\n",
    "        return y_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        y_proba = self.model(torch.from_numpy(X).float()).detach().numpy()\n",
    "        y_pred = (y_proba[:,1] >= 0.5).astype(int)\n",
    "        return y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = len(X_train.iloc[0])\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "('scaler', MinMaxScaler()),\n",
    "('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "('model', tabular_nn_model(d_in=d_in, n_epochs=100, lr=0.01, weight_decay=0, early_stop=True, verbose=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Cross validation search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### **************************************8\n",
    "# # Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "\n",
    "\n",
    "# param_grid ={\n",
    "#             'model__lr' : [0.1, 0.01, 0.001],\n",
    "#             'model__drop_out' : [0.4, 0.25, 0.1, 0.05, 0]\n",
    "#              }\n",
    "\n",
    "\n",
    "\n",
    "# score, best_params, model_final = param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True)\n",
    "\n",
    "# # dump(model_final , open('model_final_rf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Fitting Pipeline one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No. of epochs: 23\n",
      "epoch: [1, 6, 12, 18, 23]\n",
      "loss: [0.6306589281678074, 0.6057774702911622, 0.5968950177796506, 0.5948249676845553, 0.5967443114700879]\n",
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "Train Accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.74      0.73     19017\n",
      "         1.0       0.73      0.70      0.72     19017\n",
      "\n",
      "    accuracy                           0.72     38034\n",
      "   macro avg       0.72      0.72      0.72     38034\n",
      "weighted avg       0.72      0.72      0.72     38034\n",
      "\n",
      "\n",
      "_________________________________________\n",
      "\n",
      "Specificity\n",
      "\n",
      "0.74\n",
      "\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining pipe again just to make verbose=2 in the model\n",
    "d_in = len(X_train.iloc[0])\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "# ('model', tabular_nn_model(d_in=d_in, n_epochs=100, lr=0.01, weight_decay=0, early_stop=True, verbose=2))\n",
    "# ])\n",
    "\n",
    "\n",
    "# manual params setting\n",
    "best_params2 = {'model__lr': 0.01, 'model__drop_out': 0.4}\n",
    "\n",
    "            \n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train)*sample_ratio)\n",
    "X, y = resample(X_train.values, y_train.values, n_samples=n_samples, stratify=y_train.values, random_state=10)\n",
    "model_final = copy.deepcopy(pipe)\n",
    "model_final.set_params(**best_params2)\n",
    "model_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.82      0.86      4754\n",
      "         1.0       0.35      0.54      0.42       852\n",
      "\n",
      "    accuracy                           0.78      5606\n",
      "   macro avg       0.63      0.68      0.64      5606\n",
      "weighted avg       0.82      0.78      0.79      5606\n",
      "\n",
      "\n",
      "_________________________________________\n",
      "\n",
      "Specificity\n",
      "\n",
      "0.82\n",
      "\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "\n",
    "X,y = X_test.values, y_test.values\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.95).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_ANN_grade123, tpr_ANN_grade123, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "%store fpr_ANN_grade123\n",
    "%store tpr_ANN_grade123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = model_final._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = RF_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,15)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_imputed_array = model_final.named_steps['imputer'].transform(X_test)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed_array, columns=X_test.columns)\n",
    "X_test_scaled_array = model_final.named_steps['scaler'].transform(X_test_imputed)\n",
    "df_test_imputed_scaled = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(RF_model)\n",
    "shap_values = explainer.shap_values(df_test_imputed_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.query(\"outcome==1\").iloc[[40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_numbers = y_test.loc[31703381,19338519,20471295].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(row_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number_1 = 402\n",
    "row = df_test_imputed_scaled.iloc[[row_number_1]]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test[\"outcome\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[[row_number_1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = RF_model.predict_proba(df_test_imputed_scaled.iloc[[row_number_1]])\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[1], shap_values[1][[row_number_1]], df_test_imputed_scaled.iloc[[row_number_1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.waterfall_plot(explainer.expected_value[1],shap_values[1][[row_number_1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining X_test,y_test and y_pred in one dataset\n",
    "# del(df_test_all)\n",
    "df_test_all = X_test.copy()\n",
    "df_test_all['y_actual'] = y_test\n",
    "df_test_all['y_pred'] = y_pred\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3\n",
    "\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TN = df_test_all[df_test_all.error_category==0]\n",
    "df_FP = df_test_all[df_test_all.error_category==1]\n",
    "\n",
    "df_TP = df_test_all[df_test_all.error_category==2]\n",
    "df_FN = df_test_all[df_test_all.error_category==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the DataFrames\n",
    "common_FP = pd.merge(df_FP, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FP.drop([col for col in common_FP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TN = pd.merge(df_TN, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TN.drop([col for col in common_TN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TP = pd.merge(df_TP, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TP.drop([col for col in common_TP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_FN = pd.merge(df_FN, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FN.drop([col for col in common_FN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_test_all = pd.merge(df_test_all, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_test_all.drop([col for col in common_test_all.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FP, kind=\"hex\", joint_kws={'color':'#66ffcc'})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<90].shape[0])/(common_FP.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_TN[common_TN.egfr_epi_scr<90].shape[0])/(common_TN.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TP, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hist2d(common_FP.egfr_epi_scr, common_FP.age, bins=[x_bins, y_bins])\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hexbin(common_FP.egfr_epi_scr, common_FP.age, bins=50)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(common_FP.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=common_FP, x=col, bins=50, stat='percent', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for True negative and  False positive and compare their distribution.\n",
    "# It plots the distribution and prints Jensen-Shanon distance.\n",
    "# from functions_compare_distribution import compare_hist_df\n",
    "from dfwiz import dfwiz, dfwiz_compare\n",
    "# healthy patients\n",
    "TN = df_test_all.query(\"error_category == 0\")[X_test.columns] # True negative\n",
    "FP = df_test_all.query(\"error_category == 1\")[X_test.columns] # False positive\n",
    "\n",
    "if len(TN) == 0 or len(FP) == 0:\n",
    "    print(\"Error! one of the dataframes are empty\")\n",
    "else:\n",
    "    # compare_hist_df(TN, FP) # plot distributions and output Jensen-Shanon distance.\n",
    "    dfwiz_compare(FP, TN,label=['FP', 'TN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.kdeplot(data=df_test_all, x=col, hue='error_category', bins=50, stat='density', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', common_norm=False, bins=50, stat=\"percent\");\n",
    "    plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_FP, x=df_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"density\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', bins=len(df_test_all), stat='density', element=\"step\", fill=False, cumulative=True,common_norm=False);\n",
    "    plt.title(\"Cumulative distribution function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree on validation set to differentiate between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "# del(df_test_all)\n",
    "\n",
    "# X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_valid)\n",
    "X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "X_valid_scaled_array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "df_test_all = pd.DataFrame(X_valid_scaled_array, columns=X_valid.columns)\n",
    "\n",
    "\n",
    "# df_test_all['y_actual'] = y_valid.values.ravel()\n",
    "df_test_all['y_actual'] = y_train.values.ravel()\n",
    "df_test_all['y_pred'] = y_pred\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP', 'TP', 'FN' ]\n",
    "df1 = df_test_all.copy()\n",
    "X1 = df1[X_test.columns]\n",
    "X1\n",
    "y1 =  df1[['error_category']]\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 5 , class_weight='balanced', random_state=42, criterion=\"gini\", min_impurity_decrease = 0.002)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "plt.figure(figsize=(20,12))\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = list(X1.columns), \n",
    "               rounded=True, \n",
    "               filled = True,\n",
    "               proportion = True,\n",
    "               class_names = class_names);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "# X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "# X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "# X_train_imputed = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "# X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_valid)\n",
    "# X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "# X_valid_scaled__array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "# X_valid_imputed = pd.DataFrame(X_valid_scaled__array, columns=X_valid.columns)\n",
    "\n",
    "# y_error_t = clf.predict(X_train_imputed)\n",
    "# y_error_v = clf.predict(X_valid_imputed)\n",
    "\n",
    "# # True Negatives (0)\n",
    "# X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "# y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "# X_valid_TN = X_valid.loc[(y_error_v==0)]\n",
    "# y_valid_TN = y_valid.loc[(y_error_v==0)]\n",
    "\n",
    "# # False Positives (1)\n",
    "# X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "# y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "# X_valid_FP = X_valid.loc[(y_error_v==1)]\n",
    "# y_valid_FP = y_valid.loc[(y_error_v==1)]\n",
    "\n",
    "# # True Positives (2)\n",
    "# X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "# y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "# X_valid_TP = X_valid.loc[(y_error_v==2)]\n",
    "# y_valid_TP = y_valid.loc[(y_error_v==2)]\n",
    "\n",
    "# # False Negatives (3)\n",
    "# X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "# y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "# X_valid_FN = X_valid.loc[(y_error_v==3)]\n",
    "# y_valid_FN = y_valid.loc[(y_error_v==3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_train_imputed = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "X_test_imputed_array = model_final.named_steps['imputer'].transform(X_test)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed_array, columns=X_test.columns)\n",
    "X_test_scaled_array = model_final.named_steps['scaler'].transform(X_test_imputed)\n",
    "X_test_imputed = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "\n",
    "y_error_t = model_final.predict(X_train_imputed)\n",
    "y_error_v = model_final.predict(X_test_imputed)\n",
    "\n",
    "# True Negatives (0)\n",
    "X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "X_valid_TN = X_test.loc[(y_error_v==0)]\n",
    "y_valid_TN = y_test.loc[(y_error_v==0)]\n",
    "\n",
    "# False Positives (1)\n",
    "X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "X_valid_FP = X_test.loc[(y_error_v==1)]\n",
    "y_valid_FP = y_test.loc[(y_error_v==1)]\n",
    "\n",
    "# True Positives (2)\n",
    "X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "X_valid_TP = X_test.loc[(y_error_v==2)]\n",
    "y_valid_TP = y_test.loc[(y_error_v==2)]\n",
    "\n",
    "# False Negatives (3)\n",
    "X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "X_valid_FN = X_test.loc[(y_error_v==3)]\n",
    "y_valid_FN = y_test.loc[(y_error_v==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_FP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.loc[~(y_error_t==1)]\n",
    "y_train_new = y_train.loc[~(y_error_t==1)]\n",
    "\n",
    "X_valid_new = X_valid.loc[~(y_error_v==1)]\n",
    "y_valid_new = y_valid.loc[~(y_error_v==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new, y_train_new = up_sample(X_train_new, y_train_new,'outcome')\n",
    "X_train_new, y_train_new = up_sample(X_train, y_train,'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 350, 'model__min_samples_split': 350}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_new)*sample_ratio)\n",
    "X, y = resample(X_train_new.values, y_train_new.values, n_samples=n_samples, stratify=y_train_new.values, random_state=10)\n",
    "model_final = copy.deepcopy(pipe)\n",
    "model_final.set_params(**best_params2)\n",
    "model_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_new.values, y_valid_new.values\n",
    "\n",
    "# X,y = X_test.values, y_test.values\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.6).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,20)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_RF = df_test_all.copy()\n",
    "y = df_valid_RF.error_category\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgbm  # standard alias\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "# ('model', lgbm.LGBMClassifier(n_jobs=-1, n_estimators=300))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF to classify 4 error categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### **************************************8\n",
    "# Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "# param_grid ={'model__num_leaves': [6, 10, 20, 50], \n",
    "#              'model__min_child_samples': [100, 200, 300, 400, 500], \n",
    "#              'model__min_child_weight': [1e-5,  1e-2,  1,  1e2,  1e4],\n",
    "#              'model__subsample' : [0.2, 0.5, 0.8], \n",
    "#              'model__reg_alpha': [0, 1e-1, 1, 5,  10, 50, 100],\n",
    "#              'model__reg_lambda': [0, 1e-1, 1,  10,  50, 100]}\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 500 ],\n",
    "    'model__max_depth': [ 30 , 40, 50 , 60 , 80, 100],\n",
    "    'model__min_samples_leaf': [100, 70, 50,20, 10,5],\n",
    "    'model__min_samples_split' : [100, 70, 50,20, 10,5]\n",
    "}\n",
    "\n",
    "# param_grid ={'model__max_depth': [6, 10], \n",
    "#    }\n",
    "df_valid_RF = df_test_all.copy()\n",
    "y = df_valid_RF.error_category\n",
    "X = df_valid_RF.drop(['y_actual','y_pred','error_category'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "score, best_params, model_final = param_graph(X, y, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True, multi_class=True, average_metric=\"micro\")\n",
    "\n",
    "# dump(model_final , open('model_final_LGBM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP', 'TP', 'FN' ]\n",
    "df1 = df_test_all.copy()\n",
    "X1 = df1[X_valid.columns]\n",
    "y1 =  df1[['error_category']]\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "# plt.figure(figsize=(20,12))\n",
    "# tree.plot_tree(clf,\n",
    "#                feature_names = list(X1.columns), \n",
    "#                rounded=True, \n",
    "#                filled = True,\n",
    "#                proportion = True,\n",
    "#                class_names = class_names);\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix,plot_confusion_matrix\n",
    "# cm = multilabel_confusion_matrix(y1, y_pred)\n",
    "plot_confusion_matrix(clf, X1, y1, display_labels=['TN','FP','TP','FN'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = model_final.named_steps['imputer'].transform(X_test)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_test_imputed_scaled = pd.DataFrame(X_train_scaled_array, columns=X_test.columns)\n",
    "\n",
    "y_pred2 =clf.predict(X_test_imputed_scaled)\n",
    "# plot_confusion_matrix(clf, X_test, y_test, display_labels=['TN','FP','TP','FN'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = np.where((y_pred2==0) | (y_pred2==2),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_pred3==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import multilabel_confusion_matrix,plot_confusion_matrix\n",
    "\n",
    "\n",
    "# best_params2 = {'model__n_estimators':100,'model__max_depth': 80\n",
    "# ,'model__min_samples_leaf': 50, 'model__min_samples_split': 50}\n",
    "\n",
    "\n",
    "# df_valid_RF = df_test_all.copy()\n",
    "# y = df_valid_RF.error_category\n",
    "# X = df_valid_RF.drop(['y_actual','y_pred','error_category'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# sample_ratio = 1\n",
    "# n_samples = int(len(X)*sample_ratio)\n",
    "# X, y = resample(X, y, n_samples=n_samples, stratify=y, random_state=10)\n",
    "# model_RF_error_cat = copy.deepcopy(pipe)\n",
    "# model_RF_error_cat.set_params(**best_params2)\n",
    "# model_RF_error_cat.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "# print(\"_\"*150)\n",
    "# print(\"\")\n",
    "# print(\"Train Accuracy:\")\n",
    "# print(\"\")\n",
    "\n",
    "# y_pred = model_RF_error_cat.predict(X)\n",
    "# y_pred_proba = model_RF_error_cat.predict_proba(X)\n",
    "\n",
    "# cm = multilabel_confusion_matrix(y, y_pred)\n",
    "# plot_confusion_matrix(model_RF_error_cat, X, y, display_labels=['TN','FP','TP','FN'])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # display_labels=['TN','FP','TP','FN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_train_imputed_scaled = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_valid)\n",
    "X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "X_valid_scaled__array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "X_valid_imputed_scaled = pd.DataFrame(X_valid_scaled__array, columns=X_valid.columns)\n",
    "\n",
    "\n",
    "y_error_t = clf.predict(X_train_imputed_scaled)\n",
    "y_error_v = clf.predict(X_valid_imputed_scaled)\n",
    "\n",
    "# True Negatives (0)\n",
    "X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "X_valid_TN = X_valid.loc[(y_error_v==0)]\n",
    "y_valid_TN = y_valid.loc[(y_error_v==0)]\n",
    "\n",
    "# False Positives (1)\n",
    "X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "X_valid_FP = X_valid.loc[(y_error_v==1)]\n",
    "y_valid_FP = y_valid.loc[(y_error_v==1)]\n",
    "\n",
    "# True Positives (2)\n",
    "X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "X_valid_TP = X_valid.loc[(y_error_v==2)]\n",
    "y_valid_TP = y_valid.loc[(y_error_v==2)]\n",
    "\n",
    "# False Negatives (3)\n",
    "X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "X_valid_FN = X_valid.loc[(y_error_v==3)]\n",
    "y_valid_FN = y_valid.loc[(y_error_v==3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_error_v==3)\n",
    "# y_valid_TP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y_error_v==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_FN.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_True, y_train_True = up_sample(X_train_True, y_train_True,'outcome')\n",
    "# X_train_False, y_train_False = up_sample(X_train_False, y_train_False,'outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TN estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 250, 'model__min_samples_split': 250}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_TN)*sample_ratio)\n",
    "X, y = resample(X_train_TN.values, y_train_TN.values, n_samples=n_samples, stratify=y_train_TN.values, random_state=10)\n",
    "model_final_TN = copy.deepcopy(pipe)\n",
    "model_final_TN.set_params(**best_params2)\n",
    "model_final_TN.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_TN.predict(X)\n",
    "y_pred_proba = model_final_TN.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_FP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_TN.values, y_valid_TN.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_TN.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 40\n",
    ",'model__min_samples_leaf': 50, 'model__min_samples_split': 50}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_FP)*sample_ratio)\n",
    "X, y = resample(X_train_FP.values, y_train_FP.values, n_samples=n_samples, stratify=y_train_FP.values, random_state=10)\n",
    "model_final_FP = copy.deepcopy(pipe)\n",
    "model_final_FP.set_params(**best_params2)\n",
    "model_final_FP.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_FP.predict(X)\n",
    "y_pred_proba = model_final_FP.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_FP.values, y_valid_FP.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_FP.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 150, 'model__min_samples_split': 150}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_TP)*sample_ratio)\n",
    "X, y = resample(X_train_TP.values, y_train_TP.values, n_samples=n_samples, stratify=y_train_TP.values, random_state=10)\n",
    "model_final_TP = copy.deepcopy(pipe)\n",
    "model_final_TP.set_params(**best_params2)\n",
    "model_final_TP.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_TP.predict(X)\n",
    "y_pred_proba = model_final_TP.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_TP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_TP.values, y_valid_TP.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_TP.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FN estimitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 250, 'model__min_samples_split': 250}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_FN)*sample_ratio)\n",
    "X, y = resample(X_train_FN.values, y_train_FN.values, n_samples=n_samples, stratify=y_train_FN.values, random_state=10)\n",
    "model_final_FN = copy.deepcopy(pipe)\n",
    "model_final_FN.set_params(**best_params2)\n",
    "model_final_FN.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_FN.predict(X)\n",
    "y_pred_proba = model_final_FN.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_FN.values, y_valid_FN.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_FN.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = X_test, y_test\n",
    "\n",
    "y_pred_proba_list = []\n",
    "for i in range(len(X)):\n",
    "    # X_imputed = model_final.named_steps['imputer'].transform(X.iloc[[i]])\n",
    "    X_valid_imputed_array = model_final.named_steps['imputer'].transform(X.iloc[[i]])\n",
    "    X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "    X_valid_scaled_array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "    df_test_all = pd.DataFrame(X_valid_scaled_array, columns=X_valid.columns)\n",
    "    tree_predict = clf.predict(df_test_all)\n",
    "    if(tree_predict == 0): #TN\n",
    "        y_pred_proba_list.insert(i, list(model_final_TN.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 1): #FP\n",
    "        y_pred_proba_list.insert(i, list(model_final_FP.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 2): #TP\n",
    "        y_pred_proba_list.insert(i, list(model_final_TP.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 3): #FN\n",
    "        y_pred_proba_list.insert(i, list(model_final_FN.predict_proba(X.iloc[[i]])[0]))\n",
    "\n",
    "y_pred_proba = np.array(y_pred_proba_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7ea45291871ad6e398ab50f9f84dad559e0de667f49db4aea6ebf0e175149ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
