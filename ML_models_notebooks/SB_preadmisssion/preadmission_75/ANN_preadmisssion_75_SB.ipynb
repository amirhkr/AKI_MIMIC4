{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/src')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "from dfwiz import dfwiz\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from utils.vis import spy, look, plot_nunique, plot_dists\n",
    "from utils.processing import sort, impute, replace_inf, drop_empty, select, drop_by_nunique, scale, melt, unmelt, \\\n",
    "                             remove_outliers, get_categories, filter_categorical, onehot, filter_regex, match, cap,get_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables representing experiment parameters\n",
    "EXPERIMENT = 'Processing Demo'\n",
    "IMPUTE_NUM = 'constant'\n",
    "IMPUTE_CAT = 'other'\n",
    "FIGSIZE    = [12,3]\n",
    "\n",
    "# parameter dict\n",
    "params = {\n",
    "    'experiment':EXPERIMENT,\n",
    "    'figsize'   :FIGSIZE,\n",
    "    'impute_num':IMPUTE_NUM,\n",
    "    'impute_cat':IMPUTE_CAT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy as sp\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn')\n",
    "sns.set_theme(style=\"ticks\")\n",
    "mpl.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "# Title\n",
    "mpl.rcParams['figure.titlesize'] = 22\n",
    "mpl.rcParams['figure.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlesize'] = 22\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlepad'] = 20\n",
    "\n",
    "# Axes labels\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "\n",
    "# Grid and thicks\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['axes.grid.axis'] = 'y'\n",
    "#mpl.rcParams['axes.xmargin'] = 0\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "\n",
    "# Legend\n",
    "mpl.rcParams['legend.facecolor'] = 'w'\n",
    "mpl.rcParams['legend.title_fontsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['legend.frameon'] = True\n",
    "mpl.rcParams['legend.framealpha'] = 1\n",
    "mpl.rcParams['legend.fancybox'] = True\n",
    "mpl.rcParams['legend.facecolor'] = 'white'\n",
    "mpl.rcParams['legend.edgecolor'] = 'blue'\n",
    "mpl.rcParams['legend.borderpad'] = 0.6\n",
    "\n",
    "# Other\n",
    "mpl.rcParams['lines.linewidth'] = 2.5\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['scatter.edgecolors'] = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### upsampler func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "class upsampler(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        return X\n",
    "\n",
    "    def sample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y[y == 0]], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y[y == 1]], y[y == 1]\n",
    "        else:\n",
    "            print(X[y[y == 0]].shape)\n",
    "            X1, y1 = resample(X[y[y == 1]], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y[y == 0]], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "\n",
    "        return X_out, y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### accuracy func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y, y_pred, y_pred_proba):\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "    score = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.plot(fpr,tpr,label=\"AUC=\"+str(round(score,2)))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    # print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "    cr = classification_report(y, y_pred)\n",
    "    print(\"\\r\\n\"+\"Classification report\"+\"\\r\\n\")\n",
    "    print(cr)\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    print(\"\\r\\n\"+\"Specificity\"+\"\\r\\n\")\n",
    "    print(round(specificity,2))\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def up_sample(X_train_raw, y_train_raw,col_name):\n",
    "\n",
    "    # upsampling X_train and y_train\n",
    "    df_upsampled = pd.merge(X_train_raw, y_train_raw, left_index=True, right_index=True)\n",
    "\n",
    "    X_minority = df_upsampled[df_upsampled[col_name]==1]\n",
    "    X_majority = df_upsampled[df_upsampled[col_name]!=1]\n",
    "\n",
    "    n_samples = X_majority.shape[0]\n",
    "    X_minority_upsampled = resample(X_minority,\n",
    "                                    replace=True,     # sample with replacement\n",
    "                                    n_samples=n_samples,    # to match majority class\n",
    "                                    random_state=42) # reproducible results\n",
    "\n",
    "    df_upsampled = pd.concat([X_majority, X_minority_upsampled]).sample(frac=1)\n",
    "\n",
    "    y_train_out = df_upsampled[[col_name]]\n",
    "    X_train_out = df_upsampled.drop([col_name], axis=1)\n",
    "\n",
    "    return X_train_out, y_train_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### define cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "def param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 5, sample_ratio = 0.2, refit=True, use_error=True, multi_class=False, average_metric='macro'):\n",
    "\n",
    "    print(\"This search selects lower indexes of search list if their score is within the error of maximum score.\")\n",
    "    print(\"Putting parameters for less complicated model on the left side of the grid lists leads to better generalisation. \")\n",
    "    print(\" \")\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    n_train = int(sample_ratio * len(y_train))\n",
    "    X_train_s, y_train_s  = resample(X_train, y_train, n_samples=n_train, stratify=y_train)\n",
    "\n",
    "    best_score = {}\n",
    "    best_params = {}\n",
    "    for k, v in param_grid.items():\n",
    "        # best_params[k] = v[int(len(v)/2)-1]\n",
    "        best_params[k] = v[0]\n",
    "    best_params_m1 = best_params.copy()\n",
    "    print(\"start_params:\", best_params)\n",
    "\n",
    "    score = {}\n",
    "    score_std = {}\n",
    "\n",
    "    for i_iter in range(max_iter):\n",
    "        print(\"_\"*100)\n",
    "        print(\"Iteration\", i_iter)\n",
    "\n",
    "        for k, v in param_grid.items():\n",
    "\n",
    "            best_params1 = best_params.copy()\n",
    "            del best_params1[k]  \n",
    "\n",
    "            score[k] = v.copy()\n",
    "            score_std[k] = v.copy()\n",
    "\n",
    "            for i_param, val_param in enumerate(v):\n",
    "                cv_sc = np.zeros(cv)\n",
    "\n",
    "                for i_cv in range(cv):\n",
    "\n",
    "                    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train_s, y_train_s, test_size=0.2, stratify=y_train_s, shuffle=True) # 80% training and 20% test\n",
    "\n",
    "                    p1 = copy.deepcopy(pipe)\n",
    "                    p1.set_params(**best_params1)\n",
    "                    params2 = {k:val_param}\n",
    "                    p1.set_params(**params2)\n",
    "\n",
    "                    p1.fit(X_train2, y_train2.ravel())\n",
    "                    # X,y = p1.named_steps['resample'].fit_resample(X_test2, y_test2)\n",
    "                    X,y = X_test2, y_test2\n",
    "                    # y_pred_proba = p1.predict_proba(X)\n",
    "                    # cv_sc[i_cv] = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "                    y_pred = p1.predict(X)\n",
    "                    if(multi_class):\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred, average=average_metric)\n",
    "                    else:\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred)\n",
    "\n",
    "                    i_cv = i_cv + 1\n",
    "\n",
    "                score[k][i_param] = cv_sc.mean()\n",
    "                score_std[k][i_param] = cv_sc.std()\n",
    "\n",
    "            print(\"\")\n",
    "            print(k)\n",
    "            print(v)\n",
    "            print(score[k])\n",
    "\n",
    "            best_params[k] = v[np.argmax(score[k])]\n",
    "            best_score[k] = score[k][np.argmax(score[k])]\n",
    "\n",
    "            if use_error:\n",
    "                for i_b in  range(np.argmax(score[k]),-1,-1):\n",
    "                    err1 = (score_std[k][i_b] + score_std[k][v.index(best_params[k])] ) / 4\n",
    "                    # print(\"err1\")\n",
    "                    max_del = max(score[k]) - err1\n",
    "                    # print( i_b, score[k][i_b], max(score[k]), err1, max_del )\n",
    "                    if score[k][i_b] >= max_del:\n",
    "                        best_params[k] = v[i_b]\n",
    "                        best_score[k] = score[k][i_b]\n",
    "\n",
    "            print(\"best_param:\",  v[np.argmax(score[k])], \"score:\", max(score[k]))\n",
    "            print(\"selected_param:\",  best_params[k], \"score:\", best_score[k])\n",
    "            \n",
    "\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"best_params =\", best_params)\n",
    "        print(\"\")\n",
    "        if best_params_m1 == best_params:\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "            print(\"Early stop. No improvement in the last iteration.\")\n",
    "            break\n",
    "        best_params_m1 = best_params.copy()\n",
    "\n",
    "    param_graph_plot(score)\n",
    "\n",
    "    if refit:\n",
    "        print(\"Refitting final model...\")\n",
    "        model_final = copy.deepcopy(pipe)\n",
    "        model_final.set_params(**best_params)\n",
    "        model_final.fit(X_train, y_train.values.ravel())\n",
    "    else:\n",
    "        model_final = None\n",
    "\n",
    "    return score, best_params, model_final\n",
    "    \n",
    "\n",
    "def param_graph_plot(score):\n",
    "    ax = {}\n",
    "    fig = {}\n",
    "    for i, (k, v) in enumerate(score.items()):\n",
    "        fig[k], ax[k] = plt.subplots()\n",
    "\n",
    "    for k, v in score.items():\n",
    "        x = score[k]\n",
    "        y = v\n",
    "        ax[k].plot(x,y,\"-o\", label=\"Score\")\n",
    "        # ax[k].set_ylim([0.5, 1])\n",
    "        ax[k].set_title(k)\n",
    "        ax[k].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Define upsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "class upsampler(BaseEstimator): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def fit_resample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).ravel()\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y == 0], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y == 1], y[y == 1]\n",
    "        else:\n",
    "            X1, y1 = resample(X[y == 1], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y == 0], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "        return X_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Load data and select index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table from database\n",
    "# database = \"data.sqlite\"\n",
    "# con = sqlite3.connect(database)\n",
    "\n",
    "# X_train = pd.read_sql_query(\"SELECT * from X_train\", con)\n",
    "# y_train = pd.read_sql_query(\"SELECT * from y_train\", con)\n",
    "# # select index\n",
    "# index_c = ['USUBJID'] # empty list for no index\n",
    "# X_train = X_train.set_index(index_c)\n",
    "# y_train = y_train.set_index(index_c)\n",
    "\n",
    "# X_train1 = X_train[~X_train.scr_umol_l.isna()]\n",
    "# y_train1 = y_train[~X_train.scr_umol_l.isna()]\n",
    "\n",
    "# X_test = pd.read_sql_query(\"SELECT * from X_test\", con)\n",
    "# y_test = pd.read_sql_query(\"SELECT * from y_test\", con)\n",
    "# # select index\n",
    "# index_c = ['USUBJID'] # empty list for no index\n",
    "# X_test = X_test.set_index(index_c)\n",
    "# y_test = y_test.set_index(index_c)\n",
    "\n",
    "# y_test = y_test[~X_test.scr_umol_l.isna()]\n",
    "# X_test = X_test[~X_test.scr_umol_l.isna()]\n",
    "\n",
    "\n",
    "# X_train, y_train  = resample(X_train, y_train, n_samples=5000, stratify=y_train)\n",
    "# X_test, y_test  = resample(X_test, y_test, n_samples=1000, stratify=y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "sqluser = 'uqhkamel'\n",
    "dbname = 'mimiciv'\n",
    "schema_name = 'mimic_derived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to {}'.format(schema_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select * from all_scr_preadmission_75_JOIN\"\n",
    "# data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id','hadm_id'])\n",
    "\n",
    "query = \"select * from all_scr_preadmission_75_JOIN\"\n",
    "data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id'])\n",
    "data.drop('hadm_id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ethnicity'] = data['ethnicity'].replace(['OTHER'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNKNOWN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['AMERICAN INDIAN/ALASKA NATIVE'],np.nan)\n",
    "\n",
    "data = data.fillna(value=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data[\"min_day_rrt_present\"]<=1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aki_kdigo = ['aki_kdigo_grade_1','aki_kdigo_grade_2','aki_kdigo_grade_3']\n",
    "\n",
    "# outcome_var = ['day_detection_kdigo_grade_1','day_detection_kdigo_grade_2','day_detection_kdigo_grade_3']\n",
    "\n",
    "# outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "# first_24h = 1\n",
    "# data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = []\n",
    "outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "first_24h = 1\n",
    "data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7141, 110)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"ckd\"]==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['ckd']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 110)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"kidney_transplant\"]==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['kidney_transplant']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data['egfr_mdrd_scr']>60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36939, 110)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aki_kdigo_grade_1</th>\n",
       "      <th>aki_kdigo_grade_2</th>\n",
       "      <th>aki_kdigo_grade_3</th>\n",
       "      <th>day_detection_kdigo_grade_1</th>\n",
       "      <th>day_detection_kdigo_grade_2</th>\n",
       "      <th>day_detection_kdigo_grade_3</th>\n",
       "      <th>aki_mkdigo_grade_1</th>\n",
       "      <th>aki_mkdigo_grade_2</th>\n",
       "      <th>aki_mkdigo_grade_3</th>\n",
       "      <th>day_detection_mkdigo_grade_1</th>\n",
       "      <th>day_detection_mkdigo_grade_2</th>\n",
       "      <th>day_detection_mkdigo_grade_3</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>ckd</th>\n",
       "      <th>is_mdrd</th>\n",
       "      <th>egfr_epi_scr</th>\n",
       "      <th>egfr_mdrd_scr</th>\n",
       "      <th>kidney_transplant</th>\n",
       "      <th>congestive_heart_failure</th>\n",
       "      <th>diabetes_type2</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>obesity_icd</th>\n",
       "      <th>peripheral_vascular_disease</th>\n",
       "      <th>chronic_liver_disease</th>\n",
       "      <th>mild_liver_disease</th>\n",
       "      <th>severe_liver_disease</th>\n",
       "      <th>myocardial_infarct</th>\n",
       "      <th>chronic_pulmonary_disease</th>\n",
       "      <th>chronic_heart_failure</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>hemoglobin_min</th>\n",
       "      <th>hemoglobin_max</th>\n",
       "      <th>platelets_min</th>\n",
       "      <th>platelets_max</th>\n",
       "      <th>wbc_min</th>\n",
       "      <th>wbc_max</th>\n",
       "      <th>wbc_bd_min</th>\n",
       "      <th>wbc_bd_max</th>\n",
       "      <th>albumin_min</th>\n",
       "      <th>albumin_max</th>\n",
       "      <th>globulin_min</th>\n",
       "      <th>globulin_max</th>\n",
       "      <th>total_protein_min</th>\n",
       "      <th>total_protein_max</th>\n",
       "      <th>aniongap_min</th>\n",
       "      <th>aniongap_max</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>bun_min</th>\n",
       "      <th>bun_max</th>\n",
       "      <th>calcium_min</th>\n",
       "      <th>calcium_max</th>\n",
       "      <th>chloride_min</th>\n",
       "      <th>chloride_max</th>\n",
       "      <th>creatinine_min</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>glucose_min</th>\n",
       "      <th>glucose_max</th>\n",
       "      <th>sodium_min</th>\n",
       "      <th>sodium_max</th>\n",
       "      <th>potassium_min</th>\n",
       "      <th>potassium_max</th>\n",
       "      <th>pt_min</th>\n",
       "      <th>pt_max</th>\n",
       "      <th>thrombin_min</th>\n",
       "      <th>thrombin_max</th>\n",
       "      <th>ptt_min</th>\n",
       "      <th>ptt_max</th>\n",
       "      <th>inr_min</th>\n",
       "      <th>inr_max</th>\n",
       "      <th>bilirubin_total_min</th>\n",
       "      <th>bilirubin_total_max</th>\n",
       "      <th>egfr_epi_scr_max</th>\n",
       "      <th>egfr_mdrd_scr_max</th>\n",
       "      <th>heart_rate_min</th>\n",
       "      <th>heart_rate_max</th>\n",
       "      <th>heart_rate_mean</th>\n",
       "      <th>sbp_min</th>\n",
       "      <th>sbp_max</th>\n",
       "      <th>sbp_mean</th>\n",
       "      <th>dbp_min</th>\n",
       "      <th>dbp_max</th>\n",
       "      <th>dbp_mean</th>\n",
       "      <th>resp_rate_min</th>\n",
       "      <th>resp_rate_max</th>\n",
       "      <th>resp_rate_mean</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>arbs_acei</th>\n",
       "      <th>cyclosporine</th>\n",
       "      <th>bmi</th>\n",
       "      <th>urineoutput_24hr</th>\n",
       "      <th>supplemental_oxygen</th>\n",
       "      <th>invasive_vent</th>\n",
       "      <th>hfnc</th>\n",
       "      <th>non_invasive_vent</th>\n",
       "      <th>tracheostomy</th>\n",
       "      <th>min_day_rrt_present</th>\n",
       "      <th>min_day_rrt_active</th>\n",
       "      <th>weight_admit</th>\n",
       "      <th>weight_min</th>\n",
       "      <th>weight_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30000153</th>\n",
       "      <th>12466550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>15.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>144.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>13.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.8</td>\n",
       "      <td>25.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>106.576923</td>\n",
       "      <td>108.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>134.857143</td>\n",
       "      <td>55.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>67.178571</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>38.22</td>\n",
       "      <td>37.312500</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001148</th>\n",
       "      <th>12980335</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>32.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.520000</td>\n",
       "      <td>92.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>108.155172</td>\n",
       "      <td>48.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>58.620690</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>35.33</td>\n",
       "      <td>38.17</td>\n",
       "      <td>36.390000</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>65.7</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001446</th>\n",
       "      <th>16513856</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.6</td>\n",
       "      <td>23.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.4</td>\n",
       "      <td>40.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>75.916667</td>\n",
       "      <td>75.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>98.090909</td>\n",
       "      <td>41.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>54.045455</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>35.89</td>\n",
       "      <td>36.72</td>\n",
       "      <td>36.220000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>119.3</td>\n",
       "      <td>119.3</td>\n",
       "      <td>119.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001656</th>\n",
       "      <th>19609454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>37.9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>245.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>10.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>97.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>82.148148</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>138.333333</td>\n",
       "      <td>58.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.375000</td>\n",
       "      <td>36.33</td>\n",
       "      <td>37.50</td>\n",
       "      <td>36.928571</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>375.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001947</th>\n",
       "      <th>15904173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>28.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.7</td>\n",
       "      <td>161.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>137.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>49.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>73.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>87.606061</td>\n",
       "      <td>91.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>121.212121</td>\n",
       "      <td>41.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>59.984848</td>\n",
       "      <td>9.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>16.720588</td>\n",
       "      <td>36.39</td>\n",
       "      <td>37.78</td>\n",
       "      <td>36.990909</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>80.4</td>\n",
       "      <td>80.4</td>\n",
       "      <td>80.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aki_kdigo_grade_1  aki_kdigo_grade_2  aki_kdigo_grade_3  \\\n",
       "stay_id  subject_id                                                            \n",
       "30000153 12466550                    0                  0                  0   \n",
       "30001148 12980335                    1                  0                  0   \n",
       "30001446 16513856                    1                  1                  0   \n",
       "30001656 19609454                    0                  0                  0   \n",
       "30001947 15904173                    0                  0                  0   \n",
       "\n",
       "                     day_detection_kdigo_grade_1  day_detection_kdigo_grade_2  \\\n",
       "stay_id  subject_id                                                             \n",
       "30000153 12466550                      9999999.0                    9999999.0   \n",
       "30001148 12980335                            2.0                    9999999.0   \n",
       "30001446 16513856                            1.0                          1.0   \n",
       "30001656 19609454                      9999999.0                    9999999.0   \n",
       "30001947 15904173                      9999999.0                    9999999.0   \n",
       "\n",
       "                     day_detection_kdigo_grade_3  aki_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                                    \n",
       "30000153 12466550                      9999999.0                   1   \n",
       "30001148 12980335                      9999999.0                   1   \n",
       "30001446 16513856                      9999999.0                   1   \n",
       "30001656 19609454                      9999999.0                   1   \n",
       "30001947 15904173                      9999999.0                   0   \n",
       "\n",
       "                     aki_mkdigo_grade_2  aki_mkdigo_grade_3  \\\n",
       "stay_id  subject_id                                           \n",
       "30000153 12466550                     0                   0   \n",
       "30001148 12980335                     0                   0   \n",
       "30001446 16513856                     1                   0   \n",
       "30001656 19609454                     1                   0   \n",
       "30001947 15904173                     0                   0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                 \n",
       "30000153 12466550                             2.0   \n",
       "30001148 12980335                             1.0   \n",
       "30001446 16513856                             1.0   \n",
       "30001656 19609454                             1.0   \n",
       "30001947 15904173                       9999999.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_2  \\\n",
       "stay_id  subject_id                                 \n",
       "30000153 12466550                       9999999.0   \n",
       "30001148 12980335                       9999999.0   \n",
       "30001446 16513856                             1.0   \n",
       "30001656 19609454                       9999999.0   \n",
       "30001947 15904173                       9999999.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_3   age  female ethnicity  \\\n",
       "stay_id  subject_id                                                         \n",
       "30000153 12466550                       9999999.0  61.0       0     WHITE   \n",
       "30001148 12980335                       9999999.0  68.0       0       NaN   \n",
       "30001446 16513856                       9999999.0  56.0       0     WHITE   \n",
       "30001656 19609454                       9999999.0  68.0       1     WHITE   \n",
       "30001947 15904173                       9999999.0  46.0       0     WHITE   \n",
       "\n",
       "                     ckd  is_mdrd  egfr_epi_scr  egfr_mdrd_scr  \\\n",
       "stay_id  subject_id                                              \n",
       "30000153 12466550      0        1          72.0           68.0   \n",
       "30001148 12980335      0        1          73.0           71.0   \n",
       "30001446 16513856      0        0          25.0           25.0   \n",
       "30001656 19609454      0        1          75.0           71.0   \n",
       "30001947 15904173      0        0          96.0           85.0   \n",
       "\n",
       "                     kidney_transplant  congestive_heart_failure  \\\n",
       "stay_id  subject_id                                                \n",
       "30000153 12466550                    0                         0   \n",
       "30001148 12980335                    0                         0   \n",
       "30001446 16513856                    0                         0   \n",
       "30001656 19609454                    0                         0   \n",
       "30001947 15904173                    0                         0   \n",
       "\n",
       "                     diabetes_type2  chronic_kidney_disease  hypertension  \\\n",
       "stay_id  subject_id                                                         \n",
       "30000153 12466550                 0                       0             0   \n",
       "30001148 12980335                 0                       0             1   \n",
       "30001446 16513856                 0                       0             0   \n",
       "30001656 19609454                 0                       0             0   \n",
       "30001947 15904173                 1                       0             1   \n",
       "\n",
       "                     obesity_icd  peripheral_vascular_disease  \\\n",
       "stay_id  subject_id                                             \n",
       "30000153 12466550              0                            0   \n",
       "30001148 12980335              0                            0   \n",
       "30001446 16513856              0                            0   \n",
       "30001656 19609454              0                            0   \n",
       "30001947 15904173              0                            0   \n",
       "\n",
       "                     chronic_liver_disease  mild_liver_disease  \\\n",
       "stay_id  subject_id                                              \n",
       "30000153 12466550                        0                   0   \n",
       "30001148 12980335                        0                   0   \n",
       "30001446 16513856                        1                   1   \n",
       "30001656 19609454                        0                   0   \n",
       "30001947 15904173                        0                   0   \n",
       "\n",
       "                     severe_liver_disease  myocardial_infarct  \\\n",
       "stay_id  subject_id                                             \n",
       "30000153 12466550                       0                   0   \n",
       "30001148 12980335                       0                   0   \n",
       "30001446 16513856                       1                   0   \n",
       "30001656 19609454                       0                   0   \n",
       "30001947 15904173                       0                   0   \n",
       "\n",
       "                     chronic_pulmonary_disease  chronic_heart_failure  sepsis  \\\n",
       "stay_id  subject_id                                                             \n",
       "30000153 12466550                            0                      0       0   \n",
       "30001148 12980335                            1                      0       0   \n",
       "30001446 16513856                            0                      0       1   \n",
       "30001656 19609454                            0                      0       0   \n",
       "30001947 15904173                            0                      0       0   \n",
       "\n",
       "                     hematocrit_min  hematocrit_max  hemoglobin_min  \\\n",
       "stay_id  subject_id                                                   \n",
       "30000153 12466550              29.1            39.1             9.8   \n",
       "30001148 12980335              25.2            32.3             8.5   \n",
       "30001446 16513856              20.6            23.6             7.2   \n",
       "30001656 19609454              32.9            37.9            12.4   \n",
       "30001947 15904173              21.7            28.6             6.9   \n",
       "\n",
       "                     hemoglobin_max  platelets_min  platelets_max  wbc_min  \\\n",
       "stay_id  subject_id                                                          \n",
       "30000153 12466550              13.0          162.0          177.0     15.2   \n",
       "30001148 12980335              11.0          160.0          198.0      7.4   \n",
       "30001446 16513856               7.9           51.0           51.0     13.0   \n",
       "30001656 19609454              13.6          245.0          304.0     10.8   \n",
       "30001947 15904173               8.7          161.0          371.0      4.9   \n",
       "\n",
       "                     wbc_max  wbc_bd_min  wbc_bd_max  albumin_min  \\\n",
       "stay_id  subject_id                                                 \n",
       "30000153 12466550       17.9        15.2        17.9          NaN   \n",
       "30001148 12980335       11.7         7.4        11.7          NaN   \n",
       "30001446 16513856       14.1        13.0        14.1          1.8   \n",
       "30001656 19609454       14.5        10.8        14.5          3.8   \n",
       "30001947 15904173       13.5         4.9        13.5          2.4   \n",
       "\n",
       "                     albumin_max  globulin_min  globulin_max  \\\n",
       "stay_id  subject_id                                            \n",
       "30000153 12466550            NaN           NaN           NaN   \n",
       "30001148 12980335            NaN           NaN           NaN   \n",
       "30001446 16513856            1.8           NaN           NaN   \n",
       "30001656 19609454            3.8           NaN           NaN   \n",
       "30001947 15904173            2.7           NaN           NaN   \n",
       "\n",
       "                     total_protein_min  total_protein_max  aniongap_min  \\\n",
       "stay_id  subject_id                                                       \n",
       "30000153 12466550                  NaN                NaN          12.0   \n",
       "30001148 12980335                  NaN                NaN          10.0   \n",
       "30001446 16513856                  NaN                NaN          14.0   \n",
       "30001656 19609454                  NaN                NaN           9.0   \n",
       "30001947 15904173                  NaN                NaN           8.0   \n",
       "\n",
       "                     aniongap_max  bicarbonate_min  bicarbonate_max  bun_min  \\\n",
       "stay_id  subject_id                                                            \n",
       "30000153 12466550            12.0             19.0             23.0     22.0   \n",
       "30001148 12980335            10.0             25.0             27.0      9.0   \n",
       "30001446 16513856            19.0             13.0             17.0     70.0   \n",
       "30001656 19609454            16.0             26.0             26.0     13.0   \n",
       "30001947 15904173            34.0             21.0             29.0     14.0   \n",
       "\n",
       "                     bun_max  calcium_min  calcium_max  chloride_min  \\\n",
       "stay_id  subject_id                                                    \n",
       "30000153 12466550       25.0          7.4          8.0         115.0   \n",
       "30001148 12980335       12.0          NaN          NaN         108.0   \n",
       "30001446 16513856       70.0          7.0          7.6         102.0   \n",
       "30001656 19609454       18.0          7.7          7.7          97.0   \n",
       "30001947 15904173       21.0          7.7          8.6          93.0   \n",
       "\n",
       "                     chloride_max  creatinine_min  creatinine_max  \\\n",
       "stay_id  subject_id                                                 \n",
       "30000153 12466550           115.0             0.9             1.2   \n",
       "30001148 12980335           111.0             0.6             0.6   \n",
       "30001446 16513856           104.0             2.5             2.9   \n",
       "30001656 19609454            99.0             0.5             0.6   \n",
       "30001947 15904173           106.0             0.8             0.9   \n",
       "\n",
       "                     glucose_min  glucose_max  sodium_min  sodium_max  \\\n",
       "stay_id  subject_id                                                     \n",
       "30000153 12466550          144.0        192.0       142.0       145.0   \n",
       "30001148 12980335          119.0        119.0       138.0       138.0   \n",
       "30001446 16513856           75.0         94.0       128.0       132.0   \n",
       "30001656 19609454           83.0        103.0       128.0       137.0   \n",
       "30001947 15904173          137.0        309.0       136.0       143.0   \n",
       "\n",
       "                     potassium_min  potassium_max  pt_min  pt_max  \\\n",
       "stay_id  subject_id                                                 \n",
       "30000153 12466550              4.4            4.8    13.1    13.2   \n",
       "30001148 12980335              4.2            4.7    13.6    14.9   \n",
       "30001446 16513856              3.7            4.0    22.4    24.1   \n",
       "30001656 19609454              3.5            3.7    11.7    11.7   \n",
       "30001947 15904173              3.9            5.2    11.5    49.8   \n",
       "\n",
       "                     thrombin_min  thrombin_max  ptt_min  ptt_max  inr_min  \\\n",
       "stay_id  subject_id                                                          \n",
       "30000153 12466550             NaN           NaN     22.8     25.3      1.1   \n",
       "30001148 12980335             NaN           NaN     27.3     29.5      1.2   \n",
       "30001446 16513856             NaN           NaN     38.4     40.6      2.1   \n",
       "30001656 19609454             NaN           NaN     20.1     20.1      1.0   \n",
       "30001947 15904173             NaN           NaN     31.0     73.3      1.1   \n",
       "\n",
       "                     inr_max  bilirubin_total_min  bilirubin_total_max  \\\n",
       "stay_id  subject_id                                                      \n",
       "30000153 12466550        1.1                  NaN                  NaN   \n",
       "30001148 12980335        1.3                  NaN                  NaN   \n",
       "30001446 16513856        2.3                  5.5                  6.4   \n",
       "30001656 19609454        1.0                  0.6                  0.6   \n",
       "30001947 15904173        4.7                  1.3                  1.3   \n",
       "\n",
       "                     egfr_epi_scr_max  egfr_mdrd_scr_max  heart_rate_min  \\\n",
       "stay_id  subject_id                                                        \n",
       "30000153 12466550                65.0               62.0            83.0   \n",
       "30001148 12980335               103.0              134.0            64.0   \n",
       "30001446 16513856                23.0               23.0            72.0   \n",
       "30001656 19609454                94.0               99.0            69.0   \n",
       "30001947 15904173               102.0               91.0            54.0   \n",
       "\n",
       "                     heart_rate_max  heart_rate_mean  sbp_min  sbp_max  \\\n",
       "stay_id  subject_id                                                      \n",
       "30000153 12466550             128.0       106.576923    108.0    169.0   \n",
       "30001148 12980335              80.0        75.520000     92.0    125.0   \n",
       "30001446 16513856              83.0        75.916667     75.0    111.0   \n",
       "30001656 19609454             102.0        82.148148    103.0    174.0   \n",
       "30001947 15904173             112.0        87.606061     91.0    177.0   \n",
       "\n",
       "                       sbp_mean  dbp_min  dbp_max   dbp_mean  resp_rate_min  \\\n",
       "stay_id  subject_id                                                           \n",
       "30000153 12466550    134.857143     55.0     90.0  67.178571           10.0   \n",
       "30001148 12980335    108.155172     48.0     76.0  58.620690            3.0   \n",
       "30001446 16513856     98.090909     41.0     63.0  54.045455           14.0   \n",
       "30001656 19609454    138.333333     58.0    107.0  72.000000           11.0   \n",
       "30001947 15904173    121.212121     41.0     95.0  59.984848            9.0   \n",
       "\n",
       "                     resp_rate_max  resp_rate_mean  temperature_min  \\\n",
       "stay_id  subject_id                                                   \n",
       "30000153 12466550             22.0       15.000000            36.00   \n",
       "30001148 12980335             23.0       14.750000            35.33   \n",
       "30001446 16513856             28.0       20.333333            35.89   \n",
       "30001656 19609454             24.0       15.375000            36.33   \n",
       "30001947 15904173             38.0       16.720588            36.39   \n",
       "\n",
       "                     temperature_max  temperature_mean  spo2_min  spo2_max  \\\n",
       "stay_id  subject_id                                                          \n",
       "30000153 12466550              38.22         37.312500      92.0     100.0   \n",
       "30001148 12980335              38.17         36.390000      92.0     100.0   \n",
       "30001446 16513856              36.72         36.220000      90.0     100.0   \n",
       "30001656 19609454              37.50         36.928571      99.0     100.0   \n",
       "30001947 15904173              37.78         36.990909      96.0     100.0   \n",
       "\n",
       "                     arbs_acei  cyclosporine   bmi  urineoutput_24hr  \\\n",
       "stay_id  subject_id                                                    \n",
       "30000153 12466550            0             0   NaN             280.0   \n",
       "30001148 12980335            0             0  35.9             205.0   \n",
       "30001446 16513856            0             0   NaN              40.0   \n",
       "30001656 19609454            0             0   NaN             375.0   \n",
       "30001947 15904173            0             0   NaN             300.0   \n",
       "\n",
       "                     supplemental_oxygen  invasive_vent  hfnc  \\\n",
       "stay_id  subject_id                                             \n",
       "30000153 12466550                      1              1     0   \n",
       "30001148 12980335                      1              0     0   \n",
       "30001446 16513856                      0              0     0   \n",
       "30001656 19609454                      1              1     0   \n",
       "30001947 15904173                      0              1     0   \n",
       "\n",
       "                     non_invasive_vent  tracheostomy  min_day_rrt_present  \\\n",
       "stay_id  subject_id                                                         \n",
       "30000153 12466550                    0             0           99999999.0   \n",
       "30001148 12980335                    0             0           99999999.0   \n",
       "30001446 16513856                    0             0           99999999.0   \n",
       "30001656 19609454                    0             0           99999999.0   \n",
       "30001947 15904173                    0             0           99999999.0   \n",
       "\n",
       "                     min_day_rrt_active  weight_admit  weight_min  weight_max  \n",
       "stay_id  subject_id                                                            \n",
       "30000153 12466550            99999999.0          70.0        70.0        73.0  \n",
       "30001148 12980335            99999999.0          65.7        65.7        69.9  \n",
       "30001446 16513856            99999999.0         119.3       119.3       119.3  \n",
       "30001656 19609454            99999999.0          71.0        71.0        75.7  \n",
       "30001947 15904173            99999999.0          80.4        80.4        80.4  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dropna(axis=1, thresh = int(0.8*data.shape[0]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_window = 3\n",
    "\n",
    "# data.loc[(((data['aki_kdigo_grade_1']== 1)| (data['aki_kdigo_grade_2']== 1) | (data['aki_kdigo_grade_3']==1)) \\\n",
    "#     &( (data['day_detection_kdigo_grade_1']<=prediction_window)| (data['day_detection_kdigo_grade_2']<=prediction_window) | (data['day_detection_kdigo_grade_3']<=prediction_window)) \\\n",
    "#         |(data['min_day_rrt_present']<= prediction_window)), 'outcome'] = 1\n",
    "\n",
    "\n",
    "# data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_window = 3\n",
    "\n",
    "data.loc[(( (data['aki_kdigo_grade_1']== 1)) \\\n",
    "    &( (data['day_detection_kdigo_grade_1']<=prediction_window))), 'outcome'] = 1\n",
    "\n",
    "\n",
    "data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "'day_detection_kdigo_grade_1',\n",
    "'day_detection_kdigo_grade_2',\n",
    "'day_detection_kdigo_grade_3',\n",
    "'day_detection_mkdigo_grade_1',\n",
    "'day_detection_mkdigo_grade_2',\n",
    "'day_detection_mkdigo_grade_3',\n",
    "'min_day_rrt_active',\n",
    "'min_day_rrt_present',\n",
    "'ckd',\n",
    "'chronic_kidney_disease'\n",
    "]\n",
    "# CRP and vomit_nausea as they had mostly empty\n",
    "\n",
    "data.drop(drop_X, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missingness percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.reset_index().drop_duplicates(subset=['stay_id','subject_id','hadm_id']).set_index(['stay_id','subject_id','hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove unpopulated columns\n",
    "# data.pipe(sort)\\\n",
    "#               .pipe(replace_inf).pipe(drop_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by column type\n",
    "data_num = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'numerical')\n",
    "\n",
    "data_cat = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cat = data_cat.pipe(filter_categorical, cutoff=20, plot=False)\\\n",
    "#                                             .pipe(sort).pipe(spy, title='Before onehot', figsize=[12,4])\\\n",
    "#                                             .fillna('other').pipe(onehot)\n",
    "\n",
    "data_cat = data_cat.fillna('other').pipe(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ethnicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>ASIAN</th>\n",
       "      <th>BLACK/AFRICAN AMERICAN</th>\n",
       "      <th>HISPANIC/LATINO</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30000153</th>\n",
       "      <th>12466550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001148</th>\n",
       "      <th>12980335</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001446</th>\n",
       "      <th>16513856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001656</th>\n",
       "      <th>19609454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001947</th>\n",
       "      <th>15904173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          len                                               \\\n",
       "variable            ethnicity                                                \n",
       "value                   ASIAN BLACK/AFRICAN AMERICAN HISPANIC/LATINO WHITE   \n",
       "stay_id  subject_id                                                          \n",
       "30000153 12466550           0                      0               0     1   \n",
       "30001148 12980335           0                      0               0     0   \n",
       "30001446 16513856           0                      0               0     1   \n",
       "30001656 19609454           0                      0               0     1   \n",
       "30001947 15904173           0                      0               0     1   \n",
       "\n",
       "                           \n",
       "variable                   \n",
       "value               other  \n",
       "stay_id  subject_id        \n",
       "30000153 12466550       0  \n",
       "30001148 12980335       1  \n",
       "30001446 16513856       0  \n",
       "30001656 19609454       0  \n",
       "30001947 15904173       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pd.merge(data_num, data_cat, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36939, 99)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11676"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.aki_kdigo_grade_1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4308"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[processed['is_mdrd']==0].aki_kdigo_grade_1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23795\n",
       "0    13144\n",
       "Name: is_mdrd, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.is_mdrd.value_counts()\n",
    "# processed['is_mdrd'].sum()/len(processed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2 = processed.copy()\n",
    "processed.drop(['egfr_epi_scr','egfr_mdrd_scr'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "    'aki_kdigo_grade_1',\n",
    "    'aki_mkdigo_grade_1',\n",
    "\n",
    "    'aki_kdigo_grade_2',\n",
    "    'aki_mkdigo_grade_2',\n",
    "\n",
    "    'aki_kdigo_grade_3',\n",
    "    'aki_mkdigo_grade_3',\n",
    "\n",
    "    'is_mdrd'\n",
    "\n",
    "]\n",
    " \n",
    "select_y = ['outcome']\n",
    "\n",
    "processed_X = processed.pipe(filter_regex, drop_X+select_y)\n",
    "processed_Y = processed.filter(regex='|'.join(select_y))\n",
    "raw_Y = data_num.pipe(replace_inf).pipe(drop_empty).filter(regex='|'.join(select_y)).pipe(remove_outliers)\n",
    "df_y = raw_Y[select_y]\n",
    "\n",
    "\n",
    "df_X, df_y = match(processed_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36939, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_X, df_y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = df_X, df_y\n",
    "X_train, y_train = up_sample(X_train, y_train,'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# rus = RandomUnderSampler(random_state=42, sampling_strategy='auto')\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0.0        25263\n",
       "1.0        11676\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class tabular_nn_model(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d_in=10, n_epochs=15, batch_size=10, lr = 0.001, drop_out=0, weight_decay=0, early_stop=True, verbose=2):\n",
    "        self.d_in = d_in\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.drop_out = drop_out\n",
    "        self.weight_decay = weight_decay  \n",
    "        self.early_stop = early_stop\n",
    "        self.verbose = verbose  \n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.net(d_in, self.drop_out)\n",
    "        self.model.to(self.device) \n",
    "\n",
    "    class net(nn.Module):\n",
    "        def __init__(self, d_in, drop_out):\n",
    "            super(tabular_nn_model.net, self).__init__()\n",
    "            # Number of input features is D_in.\n",
    "            self.layer_1 = nn.Linear(d_in, 128) \n",
    "            self.layer_2 = nn.Linear(128, 128)\n",
    "            self.layer_3 = nn.Linear(128, 128)\n",
    "            self.layer_4 = nn.Linear(128, 128)\n",
    "            self.layer_out = nn.Linear(128, 2) \n",
    "            \n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(p=drop_out)\n",
    "            self.batchnorm1 = nn.BatchNorm1d(128)\n",
    "            self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "            self.batchnorm3 = nn.BatchNorm1d(128)\n",
    "            self.batchnorm4 = nn.BatchNorm1d(128)\n",
    "\n",
    "            self.sf = nn.Softmax(dim=1)\n",
    "            \n",
    "        def forward(self, inputs):\n",
    "            x = self.relu(self.layer_1(inputs))\n",
    "            x = self.batchnorm1(x)\n",
    "\n",
    "            x = self.relu(self.layer_2(x))\n",
    "            x = self.batchnorm2(x)\n",
    "\n",
    "            x = self.relu(self.layer_3(x))\n",
    "            x = self.batchnorm3(x)\n",
    "\n",
    "            x = self.relu(self.layer_4(x))\n",
    "            x = self.batchnorm4(x)\n",
    "\n",
    "            x = self.dropout(x)\n",
    "            x = self.layer_out(x)\n",
    "            x = self.sf(x)\n",
    "            \n",
    "            return x\n",
    "\n",
    "    def fit(self, X_train, y_train, n_epochs=None):\n",
    "\n",
    "        if n_epochs != None:\n",
    "            self.n_epochs = n_epochs\n",
    "\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "        class TrainData(Dataset):\n",
    "            def __init__(self, X_data, y_data):\n",
    "                self.X_data = X_data\n",
    "                self.y_data = y_data\n",
    "                \n",
    "            def __getitem__(self, index):\n",
    "                return self.X_data[index], self.y_data[index]\n",
    "                \n",
    "            def __len__ (self):\n",
    "                return len(self.X_data)\n",
    "\n",
    "        train_data = TrainData(torch.FloatTensor(X_train), \n",
    "                            torch.FloatTensor(y_train))\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "        self.loss_array = []\n",
    "        for e in range(1, self.n_epochs+1):\n",
    "            epoch_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_pred = self.model(X_batch)\n",
    "                loss = criterion(y_pred,y_batch.long())\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "            if self.verbose == 2:\n",
    "                print(\"epoch:\", e, \", loss:\", epoch_loss/len(train_loader))\n",
    "            self.loss_array.append(epoch_loss/len(train_loader))\n",
    "\n",
    "            if self.early_stop:\n",
    "                n_av = 10\n",
    "                if e > n_av:\n",
    "                    s1 = 0 \n",
    "                    s2 = 0\n",
    "                    for i_l in range(n_av):\n",
    "                        s1 = s1 + self.loss_array[-i_l-1]-self.loss_array[-i_l-2]\n",
    "                        s2 = s2 - abs(self.loss_array[-i_l-1]-self.loss_array[-i_l-2])\n",
    "                    cond1 = s1 > (s2/10.0)\n",
    "                    # print(\"early stop\", s1, s2/10.0)\n",
    "                    if cond1:\n",
    "                        print(\"Early stopping triggered. No. of epochs:\", e)\n",
    "                        break\n",
    "        if self.verbose == 2:\n",
    "            plt.plot(self.loss_array)\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "\n",
    "        if self.verbose == 1:\n",
    "            sample = 5\n",
    "            epoch_s = [0]*sample\n",
    "            loss_s = [0]*sample\n",
    "            l_loss = len(self.loss_array)\n",
    "            for i_s in range(sample-1):\n",
    "                ii = int(i_s/(sample-1)* l_loss)\n",
    "                epoch_s[i_s] = ii+1\n",
    "                loss_s[i_s] = self.loss_array[ii]\n",
    "\n",
    "            epoch_s[i_s+1] = l_loss\n",
    "            loss_s[i_s+1] = self.loss_array[-1]            \n",
    "\n",
    "            print(\"epoch:\", epoch_s)\n",
    "            print(\"loss:\", loss_s)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        y_proba = self.model(torch.from_numpy(X).float()).detach().numpy()\n",
    "        return y_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        y_proba = self.model(torch.from_numpy(X).float()).detach().numpy()\n",
    "        y_pred = (y_proba[:,1] >= 0.5).astype(int)\n",
    "        return y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = len(X_train.iloc[0])\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "('scaler', MinMaxScaler()),\n",
    "('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "('model', tabular_nn_model(d_in=d_in, n_epochs=100, lr=0.01, weight_decay=0, early_stop=True, verbose=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Cross validation search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### **************************************8\n",
    "# # Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "\n",
    "\n",
    "# param_grid ={\n",
    "#             'model__lr' : [0.1, 0.01, 0.001],\n",
    "#             'model__drop_out' : [0.4, 0.25, 0.1, 0.05, 0]\n",
    "#              }\n",
    "\n",
    "\n",
    "\n",
    "# score, best_params, model_final = param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True)\n",
    "\n",
    "# # dump(model_final , open('model_final_rf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Fitting Pipeline one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered. No. of epochs: 18\n",
      "epoch: [1, 5, 10, 14, 18]\n",
      "loss: [0.5766750717519947, 0.5528284022414053, 0.5441823957698998, 0.5494515562429102, 0.5550030671697864]\n",
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "Train Accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.80      0.78     20210\n",
      "         1.0       0.79      0.74      0.76     20210\n",
      "\n",
      "    accuracy                           0.77     40420\n",
      "   macro avg       0.77      0.77      0.77     40420\n",
      "weighted avg       0.77      0.77      0.77     40420\n",
      "\n",
      "\n",
      "_________________________________________\n",
      "\n",
      "Specificity\n",
      "\n",
      "0.8\n",
      "\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining pipe again just to make verbose=2 in the model\n",
    "d_in = len(X_train.iloc[0])\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "# ('model', tabular_nn_model(d_in=d_in, n_epochs=100, lr=0.01, weight_decay=0, early_stop=True, verbose=2))\n",
    "# ])\n",
    "\n",
    "\n",
    "# manual params setting\n",
    "best_params2 = {'model__lr': 0.01, 'model__drop_out': 0.4}\n",
    "\n",
    "            \n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train)*sample_ratio)\n",
    "X, y = resample(X_train.values, y_train.values, n_samples=n_samples, stratify=y_train.values, random_state=10)\n",
    "model_final = copy.deepcopy(pipe)\n",
    "model_final.set_params(**best_params2)\n",
    "model_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAFICAYAAABDQMnoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA/wUlEQVR4nO3deVxU9f4/8Ncww8Ag++5uaoEiCCpqLuRSoiTilmtoV8UszX5eNdfy2s20Tc1vN7fbzTJLszTyakiuWZq4o7hvKSq7IoMMzHJ+f3AdHGHggDNzWF7Px8PH46xz3ofzcN7z+ZzPIhMEQQAREVEF7KQOgIiIagYmDCIiEoUJg4iIRGHCICIiUZgwiIhIFCYMIiIShQmDiIhEYcIgIiJRmDCIiEgUJgwiIhKFCYOIiERhwiAiIlGYMIiISBQmDCIiEoUJg4iIRLF5wlCr1ejfvz9SU1NL7Tt37hwGDx6MyMhIzJs3DzqdztbhERGRGTZNGKdOncLIkSNx/fr1MvfPnDkT77zzDnbu3AlBEPD999/bMjwiIiqHwpYX+/7777FgwQK89dZbpfbdunULGo0GoaGhAIDBgwdjxYoVGDVqlC1DJCKqdvR6Ax4U6lCk1SO/QIuMuwW4e1+DW5lq2Cvk0Or0SDqbjuzcAgBA84ZumD0mHG7ODhaNw6YJY9GiRWb3ZWRkwMfHx7ju4+OD9PT0J7peSkoKNBrNE30GEZG1CYIArV7AXbUemiIDdHoBt3OKcOeuFmdvFFT6885cycb2PUcQ0FBV6XPbt29vdp9NE0Z5DAYDZDKZcV0QBJP1qggKCnrSsIiILKJIq8ed7HwUFunx+6nbuHTzLu7lFSI1Q/3En62Q20Fpb4cHGh283BwR2MwTL0W1h73Csm8dqk3C8Pf3R2ZmpnE9KysLvr6+EkZERCSeXm/A7ax83EjLw5mrWXBUKqDVGXAzPQ/HL2Q80WerHOTw86yHF7s+BaW9HQAZmtV3hbOTPXzcVU/841qsapMwGjZsCAcHBxw7dgzt27dHfHw8IiIipA6LiOo4vUGA5n/vD7JyC/CgQIcinR7X79zHxRt38eeZNNRT2SO/QFulz3dxskfrp7zg5eaI+t714OnqCC83FZT2dvD3qgdnlb3NEkJFJE8YcXFxmDp1KoKDg/Hxxx9j/vz5UKvVCAoKwpgxY6QOj4jqAEEQcCU1Fxf+yoHOIOC7xAvw93LCldRcUeebSxYKuR2cHBVQyGXIuV8IXw8VXh0UAgelHE81cINrPaUlb8PqZIIgCFIHQURkSwaDgNOXs/DDnku4dicXueqiJ/7MHu0awVlljzYtvdGioRt83FWQy2tX32jJSxhERNZ2/EIGNiZegMpRgePnxb9P8HR1QIdW/tAU6tC6uRfsFXZQKRXw83KC0l4ODxcHizddrc6YMIioxsq5r8Hpy1k4ey0bcrkdsu4V4NKNu/DxcIJWb4BOZ8D1O/dFfVaXkPp4PrwJApp6QuUgh0JuV23eHVQXrJIiomrNYBBwIz0PGXcf4OzVbJy7noOCQh2u3RaXCB5X36seFAoZ/DzrYUjPlgho6gF7hdzCUddOLGEQUbVgMAi4eOMu0nIe4NTFTJy4mAE7Oxky74rvuObu4gCFnQxZuRq0D/SFQm4HhcIOWq0BA59rgeCW3la8g9qPCYOIJHPxxl38tP8KDpy8VelzQ5/xgbpAi6hnmyGwmSca+TqzCsnKmDCIyCYKCnXYkHAe6oIi/H7qNgqL9BWeY6+ww3NhjSCXyxD6jA+a+LnAy02Feip7G0RMj2PCICKLyntQhAt/3cXZa9k4fiEDer0g+sXz8+FN0D20IZrWd4GnqyNLDNUMEwYRVYpWp8f9/CIUFulx/EIG0nMe4Kf9V+DiZI+8B+J7Ozfxd4GLkxIxEc0R3tofilrWZ6E2YispIjKhKdTh4s27uPDXXRgMAjb+egGu9RwACMi5X1ilz/RwcUDr5l5o5OuMwT1awsmRVUo1ERMGUR1WqNXjrzv3cepSJq7fuY9bmWrRw2GU5fnwJvD3doK93A5tWnijaX1XONizyWptwSopojpGbxDwXeJ5bPr1YqXO8/dyMlYdFRbpENjME0p7OVo0dIO/Vz0rRUvVCRMGUR2Qc1+Djb9ewPHzxe8cytOykRsMBmDyS21R37seXJxq1gB5ZD1MGES1iF5vQFauBhf+ykHm3QJ8k3AeOr2h3HNe7PoUurZtgMa+LnB3qTvjIlHlMWEQ1WAPNFr8dScPOw5dw75jqaLO8fV0grPKHv+I6wwPF0crR0i1CRMGUQ1y9Fw6tu67jOTLWaLPkcmA4BbeeK5dI/Tu0LjWDblNtsOEQVSN5KoLkXw5C1dS70FdoIXSXo4jZ9Ngr7DDzXRxcz+/0LEJApt5ovVTnqjv7Qy5HTu/kWUwYRBJTKvT47PNp7Dn6M1KndeqmSdaNnaHaz0l2jT3Qqtmniw9kFUxYRBJQBAEXE69h2XfHa+w5PBwvmg/Tye0fdoHzwbXR4dWfjaKlKgEEwaRjej1Bhw8fQfLN55Akdb8wHsTBwaj7dPe8PeqByU7vVE1woRBZAM//3YFa+PPmN3fspEb5o/rBC83lQ2jIqocJgwiK9EbBCQcvIZVW0+Xub95AzeM7huIsAAfzvhGNQITBpGF/XzgCtb+ZL40sWJ6DzzVwM2GERFZBhMG0RPS6w3Yf+IWTl/Owq4jN8weN31UO/Ro39iGkRFZFhMGkQhFWj2u3s5FYZEe567nYPeRG9AbBBgMArJzNWbP6xrSAC/3C0QjXxcbRktkHUwYRGYUafX4Yc8lfJd4oVLnNfF3wXNhjTDs+WesFBmRNJgwiP7ndpYaO/64jjtZ+Ug6mybqHH8vJ7QP9EN+gRYvdnsKgU09rRwlkXSYMKjOeqDR4tz1HMTvv4ITFzMrPL5Xh8Z4vmMTONjL4eOh4sB9VOcwYVCdodcb8N6XSdDrDaIShK+nEzoF+SMmogX8PJ1sECFR9caEQbWaIAi4nZWPhEPX8dP+K+Ue6+3miOjuzdGnczM4qzjnNNHjmDCo1jp3LQdvfXagzH3e7irU96qHpv4u6NymPkKe9oZMxlFdicrDhEG1Qs59DX7ccwl6g4DDKWnIuldg9tjPZvZEU39XG0ZHVDswYVCNtvfYTaz88RQKCs0P5gcAfx/VDuGt/ODM+amJqowJg2oUg0HA5j0XkXwpy+ysc97uKjycM2hCTDA6BfnDjpMIET0xJgyq9vQGATfT85ByNRurtiSbPa5DKz/MfLk9nBz5wprIGpgwqNq6naXGP9b8iTvZ+WaPeaqBK8ZHt0HbZ3xsGBlR3cSEQdWOVqfHgZO3sey742aP+fytXmjsx/GZiGyJCYOqhZz7Gvz396vYcfA68gu0pfY3q++KMVGt0LyhGzxdHdkElkgCTBgkmb/u3MfeYzfx497L5R733XtR7EhHVA0wYZDN6fUGDHxrm9n9CrkdQp/xwdBeTyOouZcNIyOi8jBhkM3kF2ix8dcLZofoiO7eHGNfbA0He05XSlQd2TxhbNu2DStXroROp8PYsWMxevRok/0pKSl45513oNVqUb9+fXz00UdwdWWv3JpMbxDwzuqDZfabGBUZiJiI5mwKS1QDyARBEGx1sfT0dIwcORJbtmyBUqnEiBEjsHTpUrRs2dJ4zKhRo/Dqq6/iueeew5IlS+Dg4IBp06bZKkSyoKx7Bdh/PBXrtp8ttc/FSYkV03vA210lQWREVBU2LWEcPHgQnTt3hru7OwAgMjISCQkJmDJlivEYg8GA/PzidvcFBQVwc3OzZYj0hDRFOqz8MRl7jt4sc3+vDo0xLjoIbs4ONo6MiJ6UTRNGRkYGfHxKOlj5+voiOdm05+7s2bMxbtw4vP/++1CpVPj+++9tGSJV0YGTt/Dh+qPlHvPuxGcRFuBro4iIyNJsmjAMBoNJ+3lBEEzWNRoN5s2bh3Xr1iEkJARffvklZs2ahTVr1lTpeikpKdBoNE8cN5Xvv0l3cfRy2b2xe7d1RWjzenBRyWFQ38SxY2WXPIioemjfvr3ZfTZNGP7+/jh6tORXaGZmJnx9S35xXrx4EQ4ODggJCQEADB8+HJ9++mmVrxcUFFT1YKlCOr0Bg8poHtujXSO8PrQtVA5shEdUm9jZ8mJdunTBoUOHkJOTg4KCAiQmJiIiIsK4v2nTpkhLS8PVq1cBALt370ZwcLAtQ6RKeDxZ+Hk6YdsnMZg+uj2TBVEtZNNWUkBxs9rVq1dDq9Vi6NChiIuLQ1xcHKZOnYrg4GDs378fn3zyCQRBgJeXF/75z3+icePGtgyRKpCrLsTUT/Yi536hcdvgHi3xt2iW6IhqM5snDKrZ0rLzEff+LpNtXUMaYPbYcIkiIiJbYb0Bifb1jrPYvPuSybaxL7bG0F5PSxQREdlSpRJGYWEhTp8+jYyMDERFRUGtVsPZ2dlasVE1Mm/lH6V6an/5dh92vCOqQ0RXSa1ZswZr1qxBfn4+ZDIZzp49i379+uHZZ5/F/PnzYWdn0/fnZAN6vQFnr+dg7ud/lNr3n/l94OPBZEFUl4gqYWzYsAFLly6FQqGAnZ0dDAYDCgoKcO3aNVy/fh2enp4mvbWp5nvvP4dxOCWt1HaF3A5bP4yWICIikpqoYsE333wDOzs7bNmyBd7e3gAAlUqFtWvXAgC2bt1qvQjJpg6fuYPo6fFlJotpI8OYLIjqMFEljNTUVLi5ueGZZ54x2d69e3c4OzsjMzPTKsGR7dxMz8PrH+4ptd3DxQFvxXZAUHMvznJHVMeJShh+fn64ffs2UlJSTLZv2LABeXl5aNasmTViIxvQ6Q2Ytmw/rt+5X2rfksndOIERERmJShgvv/wylixZgmHDhhm3hYeHQ61WQyaT4aWXXrJagGQ96TkPMGHRr6W2j4oMxMg+ARJERETVmaiE8corr0CtVmPt2rUoLCzu3ZuXlweVSoXY2FiMGzfOqkGS5f1+6hY++Np0dFmVgxz/md8Hzk5KiaIiouqsUj298/LycPLkSeTm5sLLywtBQUGcDa8G0hTp8NKc7Sbblv2/59Cysbs0ARFRjSAqYYwZMwZeXl5YtmyZyXa9Xo+RI0fC1dUV//73v60WJFnO+l/O4ftdF022/fTRAMjt+EKbiMpXZpWUIAg4duwYHuaSpKQkeHp64siRIybHqdVqXLhwga1naoiyhvbY8G4/JgsiEsVsCWP69OnYsWMHgNITHT1KEAQ0atQIu3btKnM/Sc9gEPDGJ3txIy3PuM1BKccX817gVKlEJJrZjntvvfUWVCqVSbIQBMHkn1wuR9OmTTF79mybBUyVc/pyFmJm/mySLFQOCvywuD+TBRFViqh3GIGBgfD398e+fftsEBJZyoxPf8OFG3dNtoW39sPb4zqxGpGIKs0i82Hk5OTA09PTEvGQhby/LgmHTt8x2caWUET0JET1w9BqtfjPf/6DU6dO4cGDBzAYDACKq6jUajUuXbqEM2fOWDVQEi/x8F8mycLT1QFfLegrYUREVBuIShhLly7FunXrYK4wIpfLLRoUVd2IeduRr9EZ1+0VdkwWRGQRokarTUhIAABMmDABQUFBaNOmDd59912Eh4dDJpNh8eLFVg2SxHnzk30myQIAvlnIZEFEliEqYWRlZcHV1RUzZsxAdHQ0cnJyMGzYMKxcuRL29vZYv369teOkCuxK+gtXb+ca12MiWmDbJzFwcrSXMCoiqk1EJQxXV1fk5+cjNzcXYWFhuHPnDq5duwaZTAa5XI4rV65YO04qhyAI+HTTSeN6rw6NMSGmjXQBEVGtJCphhIeHQ6fTIS4uDm3atIGLiwtiY2PRv39/FBQUwN3d3cphUnnmPDaF6v8bESZRJERUm4lKGHPmzEHr1q3h5eUFuVyOv/3tb8jKysKdO8UtccaPH2/VIMm8FZtOIOVqtnF9yeRu7GNBRFZRqX4YWVlZxila9+/fj0uXLiE0NBQdOnSwWoBk3p2sfExcXDIkS79nm+H1oW0ljIiIarMn7rhXWFiIVatW4c0337RUTCRS9PR443LLRm5YNq2HZLEQUe1XbpXUjh07EBsbi+joaMyaNQs3b9402b9z507069cPq1atsmqQVNoXP5t2lPzkzeckioSI6gqzHfd++OEHvP322wCKW+FcvnwZSUlJiI+Ph8FgwJw5c7Bv375yR7Il69iy9xJ+2l/SMi1uYBvYcYhyIrIyswlj06ZNEAQBwcHBaN++PXbv3o3U1FRs2rQJP//8My5fvgxBENCwYUMsXLjQljHXaWWNETWgewuJoiGiusTsO4zw8HAUFRXh0KFDcHJywuXLl9G/f38oFArodDrY2dlhzJgxePPNN6FSqWwdd520efdFfL3jnMm2TYui2DmPiGzCbAkjPz8f3t7ecHJyAgA0a9YMQPG0rI0bN8Ynn3yCkJAQmwRJwH+2pWDrvsvG9ab+LvhsZi8JIyKiusZswjAYDLCzK3knrlAUHyqTybB27VpjAiHre3xei5CW3lj0WlcJIyKiukhUx71HeXl5MVnY0P38IpNk4ayyx7uvdpEwIiKqq8y+wwgMDIRSqURoaKhxW1JSUqltQHGp46uvvrJmnHWSplCHl+ZuN67LZMDPH8dIGBER1WXlJgzRHyKT4dy5cxUfSKIZDAJiZv5ssm3je1Gop+ILbiKShtl3GFOmTLFlHPSYf/7nsMn6v2b2ZLIgIklZZE5vsixBEDBgRknp4vUhIejX5SkJIyIiqsJLb7K+tfGmw34wWRBRdcCEUc1odQZsO3DVuP7x1O4SRkNEVIIJo5oZPGubyXpAU0+JIiEiMsWEUY2cvJhhsr5qdm+JIiEiKq3SCSMtLQ3JyckAil/OVta2bdsQFRWFPn36YMOGDaX2X716FbGxsRgwYADGjx+P3NzcSl+jJlr67TG8vfqQcb1r2wZo6OMsYURERKZEJ4zt27ejT58+6NmzJ0aMGAEAGDlyJL744gvRF0tPT8eyZcvw7bff4qeffsKmTZtw+XLJ+EiCIOC1115DXFwcfv75Z7Rq1Qpr1qypxO3UTJpCHfYeSzXZNoUz5xFRNWO2H8ajfvnlF8yYMcOkRFFUVITk5GScOnUKjo6OGD16dIWfc/DgQXTu3Bnu7u4AgMjISCQkJBj7fKSkpMDJyQkREREAgEmTJuH+/fuVvaca59He3K2f8sQHU/iim4iqH1EljNWrVwMA1q5dCz8/PwCAvb093nnnHQiCgG+++UbUxTIyMuDj42Nc9/X1RXp6unH9xo0b8Pb2xty5czFo0CAsWLDAOFpubaQ3CJj9r99Ntr09vrNE0RARlU9UCePq1atwd3dH9+4lv3xlMhlGjBiBZcuW4datW6IuZjAYTGbne3y2Pp1Oh6SkJHzzzTcIDg7G8uXLsWTJEixZskTs/ZhISUmBRqOp0rm28MEPt1FQZDCuvxjujgtnkyWMiIjquvbt25vdJyphuLu7Izs7G6mppvXse/fuRW5uLho0aCAqEH9/fxw9etS4npmZCV9fX+O6j48PmjZtiuDgYABA//79MXXqVFGfXZagoKAqn2tthVo9Cr4t+XsO6N4ccQODJYyIiKh8oqqkBg0aBL1ejyFDhiAnJwcAMHDgQEyePBkymQzR0dGiLtalSxccOnQIOTk5KCgoQGJiovF9BQCEhYUhJycH58+fBwDs2bOnWn/pP4k3PtprXPb1UDFZEFG1J6qEMXXqVGRkZGDr1q3GbefPn4dMJkNUVBQmT54s6mJ+fn6YNm0axowZA61Wi6FDhyIkJARxcXGYOnUqgoOD8a9//Qvz589HQUEB/P398eGHH1btzqqxG2n3cSc737j+fzN6ShgNEZE4lRp88OrVq0hKSkJubi68vLzQrl07NG/e3Jrx1UrR0+ONy13bNsDsMeESRkNEJI6oEsZbb72FgQMH4tlnn2WCeEJ6vcFkfVZsB4kiISKqHFEljMDAQMhkMvj4+GDAgAGIiYnB008/bYv4ap1HSxdDerbEK/1r5zsaIqp9RL30HjZsGNzd3ZGRkYEvvvgCAwYMwKBBg/DVV18hOzvb2jHWGilXTf9WAyJaSBQJEVHliX6HodfrcfDgQWzfvh27d+9GXl4eZDIZ5HI5unXrhlWrVlk71hrvndUHceJiJgCgU5A/5o/rJHFERETiVWnGvZycHHz88cfYunWrsfMd5/Su2KPVUds+iZEwEiKiyhP10hsA8vPzsXv3buzYsQN//PEHdDodBEGAk5MTIiMjrRljraAp0kkdAhHRExGVMN544w389ttvKCoqMpYoOnXqhIEDByIyMhIqlcracdZ4I+btMC736dRUwkiIiKpGVML49ddfAQDNmjXDwIEDERMTg/r161s1sNpEEAToDSU1f6P7BkoYDRFR1YhKGMOGDcPgwYMRGhpq5XBqpzmf/2Gy7unqKFEkRERVV6WX3iTe+b9yMHPFAeP652/1QmM/FwkjIiKqGrMljFatWsHf3x979+5Fq1atyv0QmUyGs2fPWjy42mDphuPGZWeVPZMFEdVYZhOGIAjGGfZYCKmagkKdySCD370XJWE0RERPxmzC+Prrr6FUKo3LVHkXb9w1Ljdv6CZhJERET85swujYsaNxWSaTQalUom3btibH6PV67Nu3DwqF6O4cdcr8VQeNy68NDpEwEiKiJyfqmz42Nhb169fH3r17TbbL5XLMmjULKpUKBw4cMHN23XQ7S22y3qKRuzSBEBFZSJkJQxAEzJgxA5mZmcZt2dnZGDNmjMlxarUaarUaBoPh8Y+o875LvGBc9vdygr1C1DiPRETVVpkJQyaToUePHpg5c6ZxXavVIikpqcwP6datm/UirKH2HSuZr/vTv/eQLhAiIgsxWyUVHR2N7OxsqNVqfPbZZ3B2dsYrr7xierJCgYYNG6J3797WjrNGMRhMW5U5OdpLFAkRkeWU+w7jYYIQBAEuLi6lEgaV7dz1HONypyB/CSMhIrIcswnj9u3bkMvl8PPzw5AhQ4zbzGnQoIHlo6uhvtpe0omxZ4fGEkZCRGQ5ZhNGr169jC2jevXqBZlMZvZD2NO7xAON1qSE0aGVn4TREBFZTrlVUo/28C6vtzd7gpdY+WOycblja3842MsljIaIyHLMJozdu3cbO+Tt3r3bZgHVZIIgYN/xktZRM15uL2E0RESWZTZhNGzYsMxlMm/xV0dM1lUO7AFPRLWH6N5kJ0+exL59+wAA58+fx4gRIxAZGYmVK1daK7Yap1CrNy5/NLW7hJEQEVmeqISxa9cuvPzyy9iyZQsA4O9//ztOnjyJv/76CytWrMCGDRusGmRNcfx8BgCgWX1XBDb1lDgaIiLLEpUwVq9eDZ1OBy8vL5w5cwZXr15FSEgI5s6dC0EQsGnTJmvHWe1pdYYyl4mIagtRCePatWtwdnbG22+/jT///BMymQwDBw7EmDFj4ObmhtTU1Io/pJab+/nvxuXw1mxKS0S1j6iEIZPJIJPJYGdnh0OHDgEAwsPDUVhYCI1GA0fHuj1HdZFWj/N/lcx9Ed2tuYTREBFZh6iE8dRTT0GtVmPKlCn4888/0aBBAzRp0gRTpkxBUVERWrdube04q7V/rP3TZN3X00miSIiIrEdUwnjttddgZ2eHXbt2wWAwYPLkyVAqlUhKSoJSqcTkyZOtHWe1duXWPePy6tkciJGIaidRHQV69uyJzZs3IykpCW3atEGHDh0AAKNGjUK/fv0QElJ3Z5M7fTkLDzQ6AIDKQY4GPs4SR0REZB0yoZLjety8eRPZ2dnw9vZGo0aNrBVXjRE9Pd643K1tA8waEy5hNERE1iO6K/LRo0excOFCXL582bjtmWeewcKFCxEaGmqN2Kq9BxqtyTqTBRHVZqLeYZw+fRrjxo3DpUuXIAiC8d+FCxfwyiuv1NmRamf/q6QpbfMGbhJGQkRkfaISxvLly1FUVIQePXpg+/btSE5Oxvbt29GzZ09oNBosW7bM2nFWS9du3zcuL57cVcJIiIisT1TCOHHiBJRKJT799FO0aNECSqUSLVq0wLJly6BUKnHs2DFrx1ntJJ1NMy57u6s4DSsR1XqiEsbDYc7NTaL0cH9d8tvxW8blKS+1lTASIiLbEJUwQkJCoNVq8eabb+Lq1asoKirCtWvXMH36dGi12jr50nv/ieLhUGQyoH0ghwIhotpPVNHgYQ/vffv2GYc4B4onDFIoFHj99detFV+1pH5QZFx2VHJGPSKqG0SVMEJDQ/Hvf/8bzZs3N2kl1bRpU3z++ed1roRx4NRt43JISx8JIyEisp0qd9zz8vJC48aNK33Bbdu2YeXKldDpdBg7dixGjx5d5nH79u3Du+++iz179lT6Gtb2xsd7cf1OcQupz9/qhcZ+LhJHRERkfRVWSZ08eRK3b99Go0aNEBISgsaNG1cpUQBAeno6li1bhi1btkCpVGLEiBHo1KkTWrZsaXJcVlYWPvjggypdwxYeJgsAqO9dT8JIiIhsx2yV1L179zB8+HCMHDkS06dPx/DhwxEbGwu1Wl3lix08eBCdO3eGu7s7nJycEBkZiYSEhFLHzZ8/H1OmTKnydazJYDAtkCnkome5JSKq0cx+233wwQc4deqUyTuLo0ePYvny5VW+WEZGBnx8Sur8fX19kZ6ebnLM119/jdatW6Nt2+rZVDXj7gPjsruLg4SREBHZltkqqd9++w0ymQxz5szB8OHD8cUXX2DFihXYu3cv5s+fX6WLGQwGk74cgiCYrF+8eBGJiYlYt24d0tLSyvqISklJSYFGo3niz3nUXxmFxuVugao62WmRiGqv9u3bm91nNmHk5uZCpVJhzJgxAIrnxFi9ejWys7OrHIi/vz+OHj1qXM/MzISvr69xPSEhAZmZmRgyZAi0Wi0yMjIwatQofPvtt1W6XlBQUJVjNefcL+cAZAIAunVsg6DmXha/BhFRdWS2Skqv18PZuWRuB5lMBhcXFxQVFZk7pUJdunTBoUOHkJOTg4KCAiQmJiIiIsK4f+rUqdi5cyfi4+OxZs0a+Pr6VjlZWMuN9Dzj8lMNXCWMhIjItswmDEEQYGdnulsul6OSrXBN+Pn5Ydq0aRgzZgwGDhyI/v37IyQkBHFxcTh9+nSVP9eWLt4ombub40cRUV1ith9GYGAgFAoF/PxKhr1IT0+HXq9HgwYNTD9EJsOuXbusG2k1MeitbdDpDQCAbZ/ESBwNEZHtlNsPQ6fT4datW6W2P77N3KCEtdHDZKFUsDktEdUtZhPG4sWLbRlHjaD/X7IAgBaN3KULhIhIAmYTxqBBg2wZR41w4mKmcdnXw0nCSIiIbI/1KpXw6AvvFzo2kTASIiLbY8KohO1/XDMut2zsLl0gREQSYMKohPv5JX1Q6qnYpJaI6hYmDCIiEqVSCaOwsBBHjx7Fjh07AOCJRq6tyYJbeEsdAhGRzYmaohUA1qxZgzVr1iA/Px8ymQxRUVF46aWX8Oyzz2L+/PmleoXXNo++8H6mibt0gRARSURUwtiwYQOWLl0KhUIBOzs7GAwGFBQU4Nq1a7h+/To8PT2r7fwVlpKeUzKs+VMN3CSMhIhIGqKKBd988w3s7OywZcsWeHsXV8eoVCqsXbsWALB161brRVhNJKWUDLf+NEsYRFQHiUoYqampcHNzwzPPPGOyvXv37nB2dkZmZqaZM2uPk5dK7tHHnZ32iKjuEZUw/Pz8kJubi5SUFJPtGzZsQF5eXqnBCGuje3klEyfZcxwpIqqDRL3DePnll7FkyRIMGzbMuC08PBxqtRoymQwvvfSS1QKsDvSPzOPd0Me5nCOJiGovUQnjlVdegVqtxtq1a1FYWPxLOy8vDyqVCrGxsRg/frxVg5TaodO3jcudgvwljISISDpm58MoS15eHk6ePInc3Fx4eXkhKCgIrq61f9a5D74+gt9PFSeNVbN7s5RBRHWS6H4YAODi4oLu3btbK5Zq69rtXOMykwUR1VWiEkarVq3K3S+TyXD27FmLBFQd3cl+UPFBRES1nKiEUVGt1ZPM810j/O/+/L3YnJaI6i5RCePrr782Wdfr9cjLy0N8fDzOnj2LlStXWiW46kCnN+BhIylOmkREdZmohNGxY8cyt/fu3Ru9evXC2rVr8cknn1g0sOriyNl047Lcru7MXU5E9Lgn6oEmCAJ0Oh327dtnoXCqnwcarXF5RJ8ACSMhIpKWqBLGnDlzSm0rKipCSkoKsrOz4ePjY/HAqotHO+15u6skjISISFqiEsbWrVshk8nMvtweO3asRYOqTh6dZU8h55AgRFR3iUoYgwYNKrVNJpPBzc0NnTt3xnPPPWfxwKqL67fvG5cdlXIJIyEikpaohDF48GC0adMGKlXdq5K5nFoycZKTI+fxJqK6S1Qdy5tvvomuXbvi7t27FR9cy9zKzAcAyNhAiojqOFEJw9HREXK5HO7u7lYOp3p59IV3U//aP2YWEVF5RFVJTZkyBQsWLMCECRMQFRUFHx8fODo6QvbIz+7w8HCrBSmVe3ka43Kb5l4SRkJEJD1RCWPu3LmQyWQ4ePAgDh48WGp/bR1LKu9BSR+Mlo3dpQuEiKgaED1abXnjRdXWsaQ0hTrjcm29RyIiscwmjM8++wzOzs545ZVXcP78eVvGVG3cfWRaVj/PehJGQkQkPbMvvT/77DOsW7fOhqFUP6evZBmXfT058CAR1W3sulyOR6uhPF0dJYyEiEh6TBjlyMgpAFDcB8NewT8VEdVt5b70Tk9Pr3C2PaD2tpLSFBW/9H6aLaSIiCpuJVWXWwclXy5+hyG3Y+mCiKjchOHh4YHly5fbKJTqp75XPdzJzsf1O7lSh0JEJLlyE4ZSqTQ7215dkH2/uKd3l5AGEkdCRCQ91rWYodcbUKTVAwA8XNhCiojIbMIYOHAg+vbta/ELbtu2DVFRUejTpw82bNhQav+uXbsQExODAQMG4PXXX0durjTVQfmakl7ezioOa05EJBNs+FY7PT0dI0eOxJYtW6BUKjFixAgsXboULVu2BACo1Wr07dsXP/74I/z8/PDpp58iLy8P8+fPt1WIRpdv3sO05fsBANNGhqFXhyY2j4GIqDqxaZXUwYMH0blzZ7i7u8PJyQmRkZFISEgw7tdqtViwYAH8/PwAAAEBAbhz544tQyyJ9fRt47Kbs4MkMRARVSc2TRgZGRnw8fExrvv6+iI9Pd247uHhgRdeeAEAoNFosGbNGjz//PO2DLFMzepzLgwiItGj1VqCwWAwmUNDEAST9Yfy8vIwefJkBAYGljmfuFgpKSnQaDQVH1iGzIySubyvXkrBdU65R0R1QPv27c3us2nC8Pf3x9GjR43rmZmZ8PX1NTkmIyMD48ePR+fOnTF37twnul5QUFCVz9385+8AADs7GcI7dHiiOIiIagObVkl16dIFhw4dQk5ODgoKCpCYmIiIiAjjfr1ej0mTJqFfv36YN29emaUPW9HqipvUGgx1t6c7EdGjbFrC8PPzw7Rp0zBmzBhotVoMHToUISEhiIuLw9SpU5GWloazZ89Cr9dj586dAIA2bdpg0aJFtgwTAJB1r3jgQYWcXVWIiAAbN6utSd74eC+u37kPe4UdtnwQLXU4RESS489nM3L+NyxIpyB/iSMhIqoemDDMuJ9fBADw4MRJREQAmDDKdO+RubzZmpaIqBgTRhkeaLTGZS+WMIiIADBhlOnBIwMP1vd2ljASIqLqgwmjDHqDwbjMubyJiIrx27AMj+QL2NnxJQYREcCEUab7+SUvveVMGEREAJgwypSVWzJgoVIhlzASIqLqgwmjDDfSSkaqre9dT8JIiIiqDyaMMjw6YZKLE6dnJSICmDDK9OgItXIOPkhEBIAJo0yG/43HyBfeREQlmDDK8LCEIeV8HERE1Q0TRhkeDvjOPhhERCWYMMqgNzyskpI4ECKiaoRfiWW4ficXAODlppI4EiKi6oMJowx/3ckDADT04cCDREQPMWGU4Z66eGgQDjxIRFSC34hlqOeoAACkZedLHAkRUfXBhPEYvd6AgiI9AKDt0z4SR0NEVH0wYTzmnrrQ2A+DL72JiEowYTym8H+lCwCop1JIGAkRUfXChPEYdUHJfN4O9kwYREQPMWE8Rq8vGXhQ5cCEQUT0EBPGYwSUJAwOJUVEVIIJ4zFCSb5gwiB6QqmpQHg4IJcX/3/iP+n/yeXFzyQ1tfLPkwnjMYLwaAmDGYPoSQwaBAweDBQUFP8Y4z/p/xUUFD+XQYMq/zyZMB7DEgaR5Rw/DkyfDiiVUkdCDymVwIwZxc+mspgwHmN4JGOwhEH0ZAwGJovqSKksfjaVxYTxuEdKGHZMGERERkwYj3m0hEFERCWYMB7zaLpgCYOIqAQTxmP0+pKKPTv+dYiIjPiV+BjNI2NJOSrZ05uoLtFqtejWrRsmTJhgsj0gIAA5OTkm2xISEhAbG2tcv3//Pt577z1ER0cjJiYGAwcOxObNm0VdNycnBxMmTEBUVBT69++P42aaMKWnp2P8+PEYMGAAoqOjER8fX+qYXbt2ISwsTNR1K4vfiI95tB+GnR2rpIjqkl9//RWBgYE4c+YMrly5ghYtWog6r7CwEC+//DKio6OxdetWKBQK3Lp1C6+88goA4KWXXir3/IULF6JDhw6YNGkSzp07h4kTJyIxMREqlemI2cuWLUNISAjefPNNpKeno2/fvujSpQt8fIqnYrh+/To++OCDyt+4SEwYjzE82kqKCYPIKi7euIuNv15AQaHOatdQOSgw4oUAPNPEQ/Q53333HaKiotCkSRN89dVXePfdd0Wdt2PHDjg5OSEuLs64rWHDhli+fDm02uIBTUeMGIGCggKT89q1a4d58+Zh3759WLBgAQCgVatWaNasGQ4cOIA+ffqYHK/X65GXlwdBEFBQUACFQgG7/9WdFxQUYObMmZg9ezZmzJgh+p4rgwnjMaY9vSUMhKgWi//tCo6cTbf6dZwc7DHj5faijr18+TJOnDiBFStWICgoCLGxsZg2bRo8PCpOOGfOnEG7du1KbQ8KCjIub9y4scxzMzMzYTAY4Onpadzm5+eHtLS0UsdOnz4do0aNQkJCAu7evYtZs2bBy8sLAPDOO+9g+PDhCAgIqDDeqmLCeIxJlRQzBpFVxES0QEGhzuoljAERzUUf/91336Fnz57w8PCAh4cHGjVqhO+//x6vvvpqmZ14DQaD8de9TCYz+e4oi7kSxqRJk0p9viAIkMvlpT5jxowZmDBhAkaNGoXr168jNjYWoaGhOH36NBQKBYYOHYrUqgwSJRITxmPYDYPI+p5p4oF3xneWOgyjBw8eID4+HkqlEr169QIAqNVqfPPNNxg3bhw8PDxw7949k1JAdnY23N3dAQChoaHYsGFDqc/dvXs3jh49ilmzZpktYeh0OgiCgHv37hk/LyMjA35+fibH5eTk4NixY1i3bh0AoFmzZujatSuOHDmCX375BRqNBjExMdBqtcblNWvWlPqcJ8FWUo9hCYOo7tm2bRvc3d1x4MAB7NmzB3v27MGuXbvw4MEDJCQkICIiAuvXr4fhf+Np5ObmYuvWrXjuuecAAH369IFarcbatWuh1xe3tLx58yaWLFlS4YtzhUKBHj164PvvvwcAnD9/HleuXEGnTp1MjvPw8IC/vz927twJoDiBHDlyBG3btsUPP/yA//73v4iPj8eaNWvg6OiI+Ph4iyYLQIISxrZt27By5UrodDqMHTsWo0ePNtl/7tw5zJs3D/n5+ejQoQMWLlwIhcJ2YRpMBh9kwiCqC7777jv87W9/M6kGcnV1RWxsLNatW4cvv/wSS5YsQf/+/Y3HxMTEYND/hnxVKpX48ssv8dFHHyE6OhpyuRxyuRyvvfYaBg8eXOH1FyxYgPnz56N///6QyWT48MMP4eLiAgCIi4vDiBEj0Lt3b6xcuRL//Oc/8fnnn8POzg6vvvoqOnToYIW/SNlkQkUVbxaUnp6OkSNHYsuWLVAqlRgxYgSWLl2Kli1bGo/p378/3nvvPYSGhmLu3Llo06YNRo0aZasQsfPPv/DZ5pMAgHXv9IGXm6r8E4jILJmM1bzVVVWejU2rpA4ePIjOnTvD3d0dTk5OiIyMREJCgnH/rVu3oNFoEBoaCgAYPHiwyX5b0Jn09GYJg4joIZtWSWVkZBg7mACAr68vkpOTze738fFBenrVm96lpKRAo9FU6pzbt/IBAAo5cOHcGdjLmTSIqk5ck1aSxrFjx0pta9/e/DOzacIwGAwm7wUEQTBZr2h/ZT3aBlqswNZayBwuIKCJBzqHNazytYmIqrvykkNZbJow/P39cfToUeN6ZmYmfH19TfZnZmYa17Oyskz220I9lT0mxLSx6TWJiGoCm77D6NKlCw4dOoScnBwUFBQgMTERERERxv0NGzaEg4ODsZgUHx9vsp+IiKRj01ZSQHGz2tWrV0Or1WLo0KGIi4tDXFwcpk6diuDgYJw/fx7z58+HWq1GUFAQFi9eDCXneCSqkezsgKIiwIYt40kEnQ5wcAD0+oqPfZTNEwYR1R3+/sDBg0Bz8SN0kA1cuQJ06wbcuVO589jTm4isZvx44O9/Bx4bQokkVFBQ/EzGjav8uSxhEJHVFBYCMTHA7t3F1SAkPYUC6N0biI8vrpaqDCYMIiIShVVSREQkChMGERGJwoRBRESi1NrW0TqdrswpDomIqHz+/v5lTitRaxNGWloaevfuLXUYREQ1zu7du9GoUaNS22ttK6knKWGkpaVh9OjR2LBhA/z9/S0cWfXEe67991zX7hfgPVf1nutcCUOhUJSZISvD39//iT+jpuE913517X4B3rOl8KU3ERGJwoRBRESiMGEQEZEoTBhlcHV1xZQpU+Dq6ip1KDbDe6796tr9ArxnS6u1raSIiMiyWMIgIiJRmDCIiEgUJgwiIhKFCYOIiERhwiAiIlHqfMLYtm0boqKi0KdPH2zYsKHU/nPnzmHw4MGIjIzEvHnzoKvh80xWdL+7du1CTEwMBgwYgNdffx25ubkSRGlZFd3zQ/v27UOvXr1sGJn1VHTPV69eRWxsLAYMGIDx48fXieeckpKCIUOGYMCAAXj11Vdx//59CaK0PLVajf79+yM1NbXUPot/fwl1WFpamtCzZ0/h7t27Qn5+vhAdHS1cunTJ5JgXX3xROHHihCAIgjBnzhxhw4YNEkRqGRXdb15entC1a1chLS1NEARBWL58ufDPf/5TqnAtQswzFgRByMzMFPr27Sv07NlTgigtq6J7NhgMQp8+fYT9+/cLgiAIH330kfDhhx9KFa5FiHnOI0eOFPbt2ycIgiAsXrxYWLp0qRShWtTJkyeF/v37C0FBQcLNmzdL7bf091edLmEcPHgQnTt3hru7O5ycnBAZGYmEhATj/lu3bkGj0SA0NBQAMHjwYJP9NU1F96vVarFgwQL4+fkBAAICAnDnzh2pwrWIiu75ofnz52PKlCkSRGh5Fd1zSkoKnJycEBERAQCYNGkSRo8eLVW4FiHmORsMBuTn5wMACgoK4OjoKEWoFvX9999jwYIF8PX1LbXPGt9fdTphZGRkwMfHx7ju6+uL9PR0s/t9fHxM9tc0Fd2vh4cHXnjhBQCARqPBmjVr8Pzzz9s8Tkuq6J4B4Ouvv0br1q3Rtm1bW4dnFRXd840bN+Dt7Y25c+di0KBBWLBgAZycnKQI1WLEPOfZs2dj/vz56NatGw4ePIgRI0bYOkyLW7RoETp06FDmPmt8f9XphGEwGCCTyYzrgiCYrFe0v6YRez95eXmYOHEiAgMDMWjQIFuGaHEV3fPFixeRmJiI119/XYrwrKKie9bpdEhKSsLIkSOxdetWNG7cGEuWLJEiVIup6J41Gg3mzZuHdevW4ffff8eoUaMwa9YsKUK1GWt8f9XphOHv74/MzEzjemZmpknR7vH9WVlZZRb9aoqK7hco/lUyatQoBAQEYNGiRbYO0eIquueEhARkZmZiyJAhmDhxovH+a7KK7tnHxwdNmzZFcHAwAKB///5ITk62eZyWVNE9X7x4EQ4ODggJCQEADB8+HElJSTaP05as8f1VpxNGly5dcOjQIeTk5KCgoACJiYnGel0AaNiwIRwcHHDs2DEAQHx8vMn+mqai+9Xr9Zg0aRL69euHefPm1ejS1EMV3fPUqVOxc+dOxMfHY82aNfD19cW3334rYcRPrqJ7DgsLQ05ODs6fPw8A2LNnD4KCgqQK1yIquuemTZsiLS0NV69eBVA8BenDhFlbWeX764lemdcCP//8s/Diiy8Kffr0EdasWSMIgiBMmDBBSE5OFgRBEM6dOycMGTJEiIyMFP7+978LhYWFUob7xMq738TERCEgIEAYMGCA8d/cuXMljvjJVfSMH7p582ataCUlCBXf88mTJ4UhQ4YIUVFRwrhx44SsrCwpw7WIiu553759QnR0tNC/f39h7Nixwo0bN6QM16J69uxpbCVlze8vjlZLRESi1OkqKSIiEo8Jg4iIRGHCICIiUZgwiIhIFCYMomrKYDBIHYLF1cZ7qkuYMMgqevXqhYCAALP/xDp8+HClz6mq//u//zOJMTAwEG3atEFERAQWLVoEjUZj8WuWdX96vR7r16/H4sWLjdu2bNmCgIAAm4ymO3v27FLPq3Xr1ujYsSNGjx6N3bt3V/ozr127hnHjxuH27dtWiJhsRSF1AFS7ubm51bhB3uzt7eHp6QmDwYD79+8jPT0dX3/9NdLT07FixQqLXkupVBoHe3xo8eLFWL9+vcmwLCqVCn5+fiZjA1mbSqWCq6srgOKSwd27d3H06FEcP34c69evNzuG0eMyMjIQHR0NrVZrzXDJBpgwyKpmz56NwYMHSx1GpYSFhWH9+vUAisdd+vjjj/Hll19i586dSE9PL/UF/6TX+u2330y2qdXqUsf169cP/fr1s9h1xejbt6/JGFNZWVkYNmwYbt26hc2bN4tOGEVFRUwWtQSrpEhSly5dQlxcHDp16oTg4GC88MIL+Pzzz1Fef9JLly5h0qRJ6Nq1K9q2bYvIyEisXr3a5BydTodly5YhIiICwcHBiImJwY4dOyodn0KhwEsvvWRcf3S49/3792P06NEICwtDeHg43njjDVy7ds3k/C1btiAmJgZhYWHo2LEjYmNjceTIEeP+x6ukZs+eja1btwIAtm7dioCAAKSmppaqkho/fjwCAgLw/vvvm1zv4fZly5YBAPLz87Fw4UJ07twZISEhGDFiBA4dOlTpvwMAeHt7o3Xr1gCAe/fuGbeX9wxTU1PRu3dv47G9e/fG7NmzAVjuGZHtMGGQZDQaDcaNG4fffvsN+fn5cHBwwI0bN/Dpp59i27Zt5Z6zd+9e5OXlwdHREdevX8fSpUuxdu1a43Fvv/02Vq1ahczMTDg5OeH8+fOYNm2a2c81p6ioCF999RUAQCaToX79+gCAn376Ca+++iqOHj1qnGchMTERw4YNM45XtGvXLsyZMwfnz5+HUqlEUVERkpKSEBcXh5s3b5Z5PTc3N6hUKgAl1VAKRemKgIfVVQkJCcZEmZOTgz///BMAEBMTA0EQ8Prrr+Pbb781/q1OnDiBCRMmmCQtsX+HkydPGs8LDAwEUPEzVCgUpYbYdnNzA2C5Z0S2w4RBVjVnzpxSL1APHz4MALh58yaeeeYZdO3aFUeOHMGRI0cQFRUFAGZHT71y5QoyMjLg5eWFI0eO4PDhw/jHP/6Brl27Qi6XG4/ZsmULXF1dkZiYiMOHDxuTyaefflphzCdOnEBERAS6du2Kdu3aYdOmTQCKR3X18/NDUVER3n//fQiCgGHDhuHYsWP4448/EBwcjPv37xtfVj/88o6NjcXhw4dx+PBhREZGomfPniajiD7+9+rbty+A4iqh3377Df7+/qWOe/755+Hs7Iz09HTj4HI7d+6ETqdDSEgImjdvjgMHDuDPP/9EkyZNcODAASQlJeEf//gHdDodPvvsswr/Dg9LOAEBAQgODsbw4cNx7949tGzZEuPGjQNQ8TP09/fHxo0bjZ+5ceNGzJkz54mfEUmD7zDIqsp66a1UKgEATz/9NL744gsUFhYiOTkZx48fx9mzZwHAODPa45o1awYXFxdkZ2dj+PDhiIiIQMeOHbFq1Srj5z4ctrqgoKDUTHI3b97E7du30aBBA7Mxa7VapKenQyaTwcHBAQ0aNEC/fv0wefJkAMCxY8eQm5sLuVyO2bNnQ6FQwMPDA2+88QYmTpyIgwcPorCw0Dga6qZNm3Dr1i08++yzmDp1Klq2bFnZP2Mpjo6O6NevHzZv3owdO3agQ4cOxuqcgQMHmvwdMjIyjNseNms9duwYtFot7O3tzV5DpVJBpVIhJyfHuD579mzExMQYS0FVeYaPxlbVZ0TSYMIgqyrvpbder8fixYuxefNmaDQaNGvWzFj9Yu4dRr169fDvf/8bixYtQnJyMs6dO4fVq1fD3d0d8+bNw4ABA5Cbmwug5Iv/cRkZGeV+GXXs2NH40rss2dnZAIpnKKxXr55xe6NGjQAU183fu3cPMTExSEtLw1dffYU9e/Zgz549AICQkBAsX74cDRs2NHsNMQYOHIjNmzdj586dxuoxe3t74y/8h38HjUZTqkmwVqvFvXv3ym119fCld3JyMuLi4nDv3j3897//NWm9VZVn+GhsVX1GJA1WSZFkNm7ciPXr16NRo0bYv38/du7cafKC1JzQ0FCsW7cO+/fvxwcffIC+ffvi3r17mDt3LtRqNby8vAAUz0l+4cIFXLhwAWfPnkVycjIuXLhgnOO4qh5+/t27d01+RaempgIobpbr4eEBABg3bhx2796NzZs3Y9asWWjevDmSk5Px8ccfm/18sfOQdOjQAU2aNEFWVhaWL18Og8GAiIgI47UfxtmrVy/j3+H06dM4c+YMLly4ILqJbkhICN59910AwJEjR/Dhhx8a94l5hmXdj7WfEVkHEwZJ5tKlSwCKq1c8PT2RmZmJXbt2ATDfI/iXX35BeHi4sYnpwIED8dprrwEo/rWqVqvRrl07yGQyXLx40firfvPmzQgLC8OwYcOg1+ufKO6wsDDUq1cPer0eH374obFE8fC9QLdu3aBUKjF16lSEhYXhvffeQ+vWrfG3v/3NOIHN3bt3zX7+w3cxarUagiCU2zs6JiYGAIwtqx5WPQFA+/btAQB//PEHTp8+DaC4c2JYWBimTJlSqXuOjIw0zvf+7bff4tSpUwDEPcNHX9qr1WrodDqrPyOyDlZJkWRCQ0Px3Xff4cyZM+jcuTMKCwuh0+kAlN0XASieWc3FxQW3bt1Cr1694ObmZmzi2alTJ+ML4qioKGzfvh2vvfYa3NzcjFUgzz//vPELuaocHR0xa9YsvPPOO9i4cSPi4+Oh1Wqh0+ng7u5ubDYaHR2NxMRE/PDDD9ixYwfs7OyM9/Xwi74sD6uqfv31V7Rv3x4bNmwwe+zAgQPx2WefQRAEuLu7o0ePHsZ93bt3R1hYGE6cOIGhQ4fC1dUV9+/fN/59Kuvtt9/Gn3/+iby8PLz77rvYvHmzqGfo4eEBJycnPHjwACNHjkT37t2xYsUKqz4jsg6WMEgyMTExmDRpEnx8fCCTydC2bVssXLgQQMlL2ce5ubnhm2++waBBg+Dt7Q21Wo2GDRti7NixJi1/Fi9ejIkTJ6JBgwZ48OABmjVrhvnz52PixIkWiX348OFYtWoVOnToAJlMBpVKhcjISGzatAnNmjUDALzwwgtYuXIl2rVrZ/yV3aZNG3z88ccm7wEeN3ToUHTu3BmOjo5wdXUtt4TRqFEjhIeHAyju3Pfwxf9Dq1evxogRI+Dj44PCwkIEBARg6dKlVUoYfn5+mDlzJgDgzJkz+PHHH0U9Q6VSiZkzZ8LHxweCIMDZ2RmA9Z8RWR5n3CMiIlFYwiAiIlGYMIiISBQmDCIiEoUJg4iIRGHCICIiUZgwiIhIFCYMIiIShQmDiIhEYcIgIiJR/j+DhBVRbj25JwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.76      0.82      5053\n",
      "         1.0       0.60      0.77      0.68      2335\n",
      "\n",
      "    accuracy                           0.77      7388\n",
      "   macro avg       0.74      0.77      0.75      7388\n",
      "weighted avg       0.79      0.77      0.77      7388\n",
      "\n",
      "\n",
      "_________________________________________\n",
      "\n",
      "Specificity\n",
      "\n",
      "0.76\n",
      "\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "\n",
    "X,y = X_test.values, y_test.values\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.65).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0.0        25263\n",
       "1.0        11676\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'fpr_ANN_grade123' (ndarray)\n",
      "Stored 'tpr_ANN_grade123' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "fpr_ANN_grade123, tpr_ANN_grade123, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "%store fpr_ANN_grade123\n",
    "%store tpr_ANN_grade123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = model_final._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tabular_nn_model' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/notebooks/models/ICU_firstread/new/SB_preadmisssion/ANN_preadmisssion_75_SB.ipynb Cell 69\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/notebooks/models/ICU_firstread/new/SB_preadmisssion/ANN_preadmisssion_75_SB.ipynb#Y124sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m importances \u001b[39m=\u001b[39m RF_model\u001b[39m.\u001b[39;49mfeature_importances_\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/notebooks/models/ICU_firstread/new/SB_preadmisssion/ANN_preadmisssion_75_SB.ipynb#Y124sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(importances)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/notebooks/models/ICU_firstread/new/SB_preadmisssion/ANN_preadmisssion_75_SB.ipynb#Y124sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m features \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mcolumns\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tabular_nn_model' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "importances = RF_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,15)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_imputed_array = model_final.named_steps['imputer'].transform(X_test)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed_array, columns=X_test.columns)\n",
    "X_test_scaled_array = model_final.named_steps['scaler'].transform(X_test_imputed)\n",
    "df_test_imputed_scaled = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(RF_model)\n",
    "shap_values = explainer.shap_values(df_test_imputed_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.query(\"outcome==1\").iloc[[40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_numbers = y_test.loc[31703381,19338519,20471295].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(row_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number_1 = 402\n",
    "row = df_test_imputed_scaled.iloc[[row_number_1]]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test[\"outcome\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[[row_number_1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = RF_model.predict_proba(df_test_imputed_scaled.iloc[[row_number_1]])\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[1], shap_values[1][[row_number_1]], df_test_imputed_scaled.iloc[[row_number_1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.waterfall_plot(explainer.expected_value[1],shap_values[1][[row_number_1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining X_test,y_test and y_pred in one dataset\n",
    "# del(df_test_all)\n",
    "df_test_all = X_test.copy()\n",
    "df_test_all['y_actual'] = y_test\n",
    "df_test_all['y_pred'] = y_pred\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3\n",
    "\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TN = df_test_all[df_test_all.error_category==0]\n",
    "df_FP = df_test_all[df_test_all.error_category==1]\n",
    "\n",
    "df_TP = df_test_all[df_test_all.error_category==2]\n",
    "df_FN = df_test_all[df_test_all.error_category==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the DataFrames\n",
    "common_FP = pd.merge(df_FP, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FP.drop([col for col in common_FP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TN = pd.merge(df_TN, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TN.drop([col for col in common_TN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TP = pd.merge(df_TP, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TP.drop([col for col in common_TP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_FN = pd.merge(df_FN, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FN.drop([col for col in common_FN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_test_all = pd.merge(df_test_all, processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_test_all.drop([col for col in common_test_all.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FP, kind=\"hex\", joint_kws={'color':'#66ffcc'})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<90].shape[0])/(common_FP.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_TN[common_TN.egfr_epi_scr<90].shape[0])/(common_TN.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TP, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hist2d(common_FP.egfr_epi_scr, common_FP.age, bins=[x_bins, y_bins])\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hexbin(common_FP.egfr_epi_scr, common_FP.age, bins=50)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(common_FP.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=common_FP, x=col, bins=50, stat='percent', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for True negative and  False positive and compare their distribution.\n",
    "# It plots the distribution and prints Jensen-Shanon distance.\n",
    "# from functions_compare_distribution import compare_hist_df\n",
    "from dfwiz import dfwiz, dfwiz_compare\n",
    "# healthy patients\n",
    "TN = df_test_all.query(\"error_category == 0\")[X_test.columns] # True negative\n",
    "FP = df_test_all.query(\"error_category == 1\")[X_test.columns] # False positive\n",
    "\n",
    "if len(TN) == 0 or len(FP) == 0:\n",
    "    print(\"Error! one of the dataframes are empty\")\n",
    "else:\n",
    "    # compare_hist_df(TN, FP) # plot distributions and output Jensen-Shanon distance.\n",
    "    dfwiz_compare(FP, TN,label=['FP', 'TN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.kdeplot(data=df_test_all, x=col, hue='error_category', bins=50, stat='density', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', common_norm=False, bins=50, stat=\"percent\");\n",
    "    plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_FP, x=df_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"density\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', bins=len(df_test_all), stat='density', element=\"step\", fill=False, cumulative=True,common_norm=False);\n",
    "    plt.title(\"Cumulative distribution function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree on validation set to differentiate between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "# del(df_test_all)\n",
    "\n",
    "# X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_valid)\n",
    "X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "X_valid_scaled_array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "df_test_all = pd.DataFrame(X_valid_scaled_array, columns=X_valid.columns)\n",
    "\n",
    "\n",
    "# df_test_all['y_actual'] = y_valid.values.ravel()\n",
    "df_test_all['y_actual'] = y_train.values.ravel()\n",
    "df_test_all['y_pred'] = y_pred\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP', 'TP', 'FN' ]\n",
    "df1 = df_test_all.copy()\n",
    "X1 = df1[X_test.columns]\n",
    "X1\n",
    "y1 =  df1[['error_category']]\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 5 , class_weight='balanced', random_state=42, criterion=\"gini\", min_impurity_decrease = 0.002)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "plt.figure(figsize=(20,12))\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = list(X1.columns), \n",
    "               rounded=True, \n",
    "               filled = True,\n",
    "               proportion = True,\n",
    "               class_names = class_names);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "# X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "# X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "# X_train_imputed = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "# X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_valid)\n",
    "# X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "# X_valid_scaled__array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "# X_valid_imputed = pd.DataFrame(X_valid_scaled__array, columns=X_valid.columns)\n",
    "\n",
    "# y_error_t = clf.predict(X_train_imputed)\n",
    "# y_error_v = clf.predict(X_valid_imputed)\n",
    "\n",
    "# # True Negatives (0)\n",
    "# X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "# y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "# X_valid_TN = X_valid.loc[(y_error_v==0)]\n",
    "# y_valid_TN = y_valid.loc[(y_error_v==0)]\n",
    "\n",
    "# # False Positives (1)\n",
    "# X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "# y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "# X_valid_FP = X_valid.loc[(y_error_v==1)]\n",
    "# y_valid_FP = y_valid.loc[(y_error_v==1)]\n",
    "\n",
    "# # True Positives (2)\n",
    "# X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "# y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "# X_valid_TP = X_valid.loc[(y_error_v==2)]\n",
    "# y_valid_TP = y_valid.loc[(y_error_v==2)]\n",
    "\n",
    "# # False Negatives (3)\n",
    "# X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "# y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "# X_valid_FN = X_valid.loc[(y_error_v==3)]\n",
    "# y_valid_FN = y_valid.loc[(y_error_v==3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_train_imputed = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "X_test_imputed_array = model_final.named_steps['imputer'].transform(X_test)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed_array, columns=X_test.columns)\n",
    "X_test_scaled_array = model_final.named_steps['scaler'].transform(X_test_imputed)\n",
    "X_test_imputed = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "\n",
    "y_error_t = model_final.predict(X_train_imputed)\n",
    "y_error_v = model_final.predict(X_test_imputed)\n",
    "\n",
    "# True Negatives (0)\n",
    "X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "X_valid_TN = X_test.loc[(y_error_v==0)]\n",
    "y_valid_TN = y_test.loc[(y_error_v==0)]\n",
    "\n",
    "# False Positives (1)\n",
    "X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "X_valid_FP = X_test.loc[(y_error_v==1)]\n",
    "y_valid_FP = y_test.loc[(y_error_v==1)]\n",
    "\n",
    "# True Positives (2)\n",
    "X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "X_valid_TP = X_test.loc[(y_error_v==2)]\n",
    "y_valid_TP = y_test.loc[(y_error_v==2)]\n",
    "\n",
    "# False Negatives (3)\n",
    "X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "X_valid_FN = X_test.loc[(y_error_v==3)]\n",
    "y_valid_FN = y_test.loc[(y_error_v==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_FP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.loc[~(y_error_t==1)]\n",
    "y_train_new = y_train.loc[~(y_error_t==1)]\n",
    "\n",
    "X_valid_new = X_valid.loc[~(y_error_v==1)]\n",
    "y_valid_new = y_valid.loc[~(y_error_v==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new, y_train_new = up_sample(X_train_new, y_train_new,'outcome')\n",
    "X_train_new, y_train_new = up_sample(X_train, y_train,'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 350, 'model__min_samples_split': 350}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_new)*sample_ratio)\n",
    "X, y = resample(X_train_new.values, y_train_new.values, n_samples=n_samples, stratify=y_train_new.values, random_state=10)\n",
    "model_final = copy.deepcopy(pipe)\n",
    "model_final.set_params(**best_params2)\n",
    "model_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_new.values, y_valid_new.values\n",
    "\n",
    "# X,y = X_test.values, y_test.values\n",
    "\n",
    "y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.6).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,20)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_RF = df_test_all.copy()\n",
    "y = df_valid_RF.error_category\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgbm  # standard alias\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "# ('model', lgbm.LGBMClassifier(n_jobs=-1, n_estimators=300))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF to classify 4 error categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### **************************************8\n",
    "# Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "# param_grid ={'model__num_leaves': [6, 10, 20, 50], \n",
    "#              'model__min_child_samples': [100, 200, 300, 400, 500], \n",
    "#              'model__min_child_weight': [1e-5,  1e-2,  1,  1e2,  1e4],\n",
    "#              'model__subsample' : [0.2, 0.5, 0.8], \n",
    "#              'model__reg_alpha': [0, 1e-1, 1, 5,  10, 50, 100],\n",
    "#              'model__reg_lambda': [0, 1e-1, 1,  10,  50, 100]}\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 500 ],\n",
    "    'model__max_depth': [ 30 , 40, 50 , 60 , 80, 100],\n",
    "    'model__min_samples_leaf': [100, 70, 50,20, 10,5],\n",
    "    'model__min_samples_split' : [100, 70, 50,20, 10,5]\n",
    "}\n",
    "\n",
    "# param_grid ={'model__max_depth': [6, 10], \n",
    "#    }\n",
    "df_valid_RF = df_test_all.copy()\n",
    "y = df_valid_RF.error_category\n",
    "X = df_valid_RF.drop(['y_actual','y_pred','error_category'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "score, best_params, model_final = param_graph(X, y, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True, multi_class=True, average_metric=\"micro\")\n",
    "\n",
    "# dump(model_final , open('model_final_LGBM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP', 'TP', 'FN' ]\n",
    "df1 = df_test_all.copy()\n",
    "X1 = df1[X_valid.columns]\n",
    "y1 =  df1[['error_category']]\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "# plt.figure(figsize=(20,12))\n",
    "# tree.plot_tree(clf,\n",
    "#                feature_names = list(X1.columns), \n",
    "#                rounded=True, \n",
    "#                filled = True,\n",
    "#                proportion = True,\n",
    "#                class_names = class_names);\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix,plot_confusion_matrix\n",
    "# cm = multilabel_confusion_matrix(y1, y_pred)\n",
    "plot_confusion_matrix(clf, X1, y1, display_labels=['TN','FP','TP','FN'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = model_final.named_steps['imputer'].transform(X_test)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_test_imputed_scaled = pd.DataFrame(X_train_scaled_array, columns=X_test.columns)\n",
    "\n",
    "y_pred2 =clf.predict(X_test_imputed_scaled)\n",
    "# plot_confusion_matrix(clf, X_test, y_test, display_labels=['TN','FP','TP','FN'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = np.where((y_pred2==0) | (y_pred2==2),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_pred3==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import multilabel_confusion_matrix,plot_confusion_matrix\n",
    "\n",
    "\n",
    "# best_params2 = {'model__n_estimators':100,'model__max_depth': 80\n",
    "# ,'model__min_samples_leaf': 50, 'model__min_samples_split': 50}\n",
    "\n",
    "\n",
    "# df_valid_RF = df_test_all.copy()\n",
    "# y = df_valid_RF.error_category\n",
    "# X = df_valid_RF.drop(['y_actual','y_pred','error_category'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# sample_ratio = 1\n",
    "# n_samples = int(len(X)*sample_ratio)\n",
    "# X, y = resample(X, y, n_samples=n_samples, stratify=y, random_state=10)\n",
    "# model_RF_error_cat = copy.deepcopy(pipe)\n",
    "# model_RF_error_cat.set_params(**best_params2)\n",
    "# model_RF_error_cat.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "# print(\"_\"*150)\n",
    "# print(\"\")\n",
    "# print(\"Train Accuracy:\")\n",
    "# print(\"\")\n",
    "\n",
    "# y_pred = model_RF_error_cat.predict(X)\n",
    "# y_pred_proba = model_RF_error_cat.predict_proba(X)\n",
    "\n",
    "# cm = multilabel_confusion_matrix(y, y_pred)\n",
    "# plot_confusion_matrix(model_RF_error_cat, X, y, display_labels=['TN','FP','TP','FN'])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # display_labels=['TN','FP','TP','FN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = model_final.named_steps['imputer'].transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = model_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_train_imputed_scaled = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "X_valid_imputed_array = model_final.named_steps['imputer'].transform(X_valid)\n",
    "X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "X_valid_scaled__array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "X_valid_imputed_scaled = pd.DataFrame(X_valid_scaled__array, columns=X_valid.columns)\n",
    "\n",
    "\n",
    "y_error_t = clf.predict(X_train_imputed_scaled)\n",
    "y_error_v = clf.predict(X_valid_imputed_scaled)\n",
    "\n",
    "# True Negatives (0)\n",
    "X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "X_valid_TN = X_valid.loc[(y_error_v==0)]\n",
    "y_valid_TN = y_valid.loc[(y_error_v==0)]\n",
    "\n",
    "# False Positives (1)\n",
    "X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "X_valid_FP = X_valid.loc[(y_error_v==1)]\n",
    "y_valid_FP = y_valid.loc[(y_error_v==1)]\n",
    "\n",
    "# True Positives (2)\n",
    "X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "X_valid_TP = X_valid.loc[(y_error_v==2)]\n",
    "y_valid_TP = y_valid.loc[(y_error_v==2)]\n",
    "\n",
    "# False Negatives (3)\n",
    "X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "X_valid_FN = X_valid.loc[(y_error_v==3)]\n",
    "y_valid_FN = y_valid.loc[(y_error_v==3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_error_v==3)\n",
    "# y_valid_TP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y_error_v==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_FN.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_True, y_train_True = up_sample(X_train_True, y_train_True,'outcome')\n",
    "# X_train_False, y_train_False = up_sample(X_train_False, y_train_False,'outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TN estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 250, 'model__min_samples_split': 250}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_TN)*sample_ratio)\n",
    "X, y = resample(X_train_TN.values, y_train_TN.values, n_samples=n_samples, stratify=y_train_TN.values, random_state=10)\n",
    "model_final_TN = copy.deepcopy(pipe)\n",
    "model_final_TN.set_params(**best_params2)\n",
    "model_final_TN.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_TN.predict(X)\n",
    "y_pred_proba = model_final_TN.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_FP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_TN.values, y_valid_TN.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_TN.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 40\n",
    ",'model__min_samples_leaf': 50, 'model__min_samples_split': 50}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_FP)*sample_ratio)\n",
    "X, y = resample(X_train_FP.values, y_train_FP.values, n_samples=n_samples, stratify=y_train_FP.values, random_state=10)\n",
    "model_final_FP = copy.deepcopy(pipe)\n",
    "model_final_FP.set_params(**best_params2)\n",
    "model_final_FP.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_FP.predict(X)\n",
    "y_pred_proba = model_final_FP.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_FP.values, y_valid_FP.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_FP.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 150, 'model__min_samples_split': 150}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_TP)*sample_ratio)\n",
    "X, y = resample(X_train_TP.values, y_train_TP.values, n_samples=n_samples, stratify=y_train_TP.values, random_state=10)\n",
    "model_final_TP = copy.deepcopy(pipe)\n",
    "model_final_TP.set_params(**best_params2)\n",
    "model_final_TP.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_TP.predict(X)\n",
    "y_pred_proba = model_final_TP.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_TP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_TP.values, y_valid_TP.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_TP.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FN estimitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 250, 'model__min_samples_split': 250}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_FN)*sample_ratio)\n",
    "X, y = resample(X_train_FN.values, y_train_FN.values, n_samples=n_samples, stratify=y_train_FN.values, random_state=10)\n",
    "model_final_FN = copy.deepcopy(pipe)\n",
    "model_final_FN.set_params(**best_params2)\n",
    "model_final_FN.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = model_final_FN.predict(X)\n",
    "y_pred_proba = model_final_FN.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(model_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = model_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_FN.values, y_valid_FN.values\n",
    "\n",
    "# y_pred = model_final.predict(X)\n",
    "y_pred_proba = model_final_FN.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = X_test, y_test\n",
    "\n",
    "y_pred_proba_list = []\n",
    "for i in range(len(X)):\n",
    "    # X_imputed = model_final.named_steps['imputer'].transform(X.iloc[[i]])\n",
    "    X_valid_imputed_array = model_final.named_steps['imputer'].transform(X.iloc[[i]])\n",
    "    X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "    X_valid_scaled_array = model_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "    df_test_all = pd.DataFrame(X_valid_scaled_array, columns=X_valid.columns)\n",
    "    tree_predict = clf.predict(df_test_all)\n",
    "    if(tree_predict == 0): #TN\n",
    "        y_pred_proba_list.insert(i, list(model_final_TN.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 1): #FP\n",
    "        y_pred_proba_list.insert(i, list(model_final_FP.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 2): #TP\n",
    "        y_pred_proba_list.insert(i, list(model_final_TP.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 3): #FN\n",
    "        y_pred_proba_list.insert(i, list(model_final_FN.predict_proba(X.iloc[[i]])[0]))\n",
    "\n",
    "y_pred_proba = np.array(y_pred_proba_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7ea45291871ad6e398ab50f9f84dad559e0de667f49db4aea6ebf0e175149ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
