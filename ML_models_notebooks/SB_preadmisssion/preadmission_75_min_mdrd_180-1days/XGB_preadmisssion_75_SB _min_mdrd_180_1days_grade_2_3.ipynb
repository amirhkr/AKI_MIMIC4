{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/src')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "from dfwiz import dfwiz\n",
    "from dfwiz import dfwiz_compare\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from utils.vis import spy, look, plot_nunique, plot_dists\n",
    "from utils.processing import sort, impute, replace_inf, drop_empty, select, drop_by_nunique, scale, melt, unmelt, \\\n",
    "                             remove_outliers, get_categories, filter_categorical, onehot, filter_regex, match, cap,get_dates\n",
    "from utils.pipelines import scale_impute_via_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables representing experiment parameters\n",
    "EXPERIMENT = 'Processing Demo'\n",
    "IMPUTE_NUM = 'constant'\n",
    "IMPUTE_CAT = 'other'\n",
    "FIGSIZE    = [12,3]\n",
    "\n",
    "# parameter dict\n",
    "params = {\n",
    "    'experiment':EXPERIMENT,\n",
    "    'figsize'   :FIGSIZE,\n",
    "    'impute_num':IMPUTE_NUM,\n",
    "    'impute_cat':IMPUTE_CAT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy as sp\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn')\n",
    "sns.set_theme(style=\"ticks\")\n",
    "mpl.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "# Title\n",
    "mpl.rcParams['figure.titlesize'] = 22\n",
    "mpl.rcParams['figure.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlesize'] = 22\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlepad'] = 20\n",
    "\n",
    "# Axes labels\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "\n",
    "# Grid and thicks\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['axes.grid.axis'] = 'y'\n",
    "#mpl.rcParams['axes.xmargin'] = 0\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "\n",
    "# Legend\n",
    "mpl.rcParams['legend.facecolor'] = 'w'\n",
    "mpl.rcParams['legend.title_fontsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['legend.frameon'] = True\n",
    "mpl.rcParams['legend.framealpha'] = 1\n",
    "mpl.rcParams['legend.fancybox'] = True\n",
    "mpl.rcParams['legend.facecolor'] = 'white'\n",
    "mpl.rcParams['legend.edgecolor'] = 'blue'\n",
    "mpl.rcParams['legend.borderpad'] = 0.6\n",
    "\n",
    "# Other\n",
    "mpl.rcParams['lines.linewidth'] = 2.5\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['scatter.edgecolors'] = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### upsampler func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "class upsampler(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        return X\n",
    "\n",
    "    def sample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y[y == 0]], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y[y == 1]], y[y == 1]\n",
    "        else:\n",
    "            print(X[y[y == 0]].shape)\n",
    "            X1, y1 = resample(X[y[y == 1]], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y[y == 0]], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "\n",
    "        return X_out, y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### accuracy func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y, y_pred, y_pred_proba):\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "    score = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.plot(fpr,tpr,label=\"AUC=\"+str(round(score,2)))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    # print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "    cr = classification_report(y, y_pred)\n",
    "    print(\"\\r\\n\"+\"Classification report\"+\"\\r\\n\")\n",
    "    print(cr)\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    print(\"\\r\\n\"+\"Specificity\"+\"\\r\\n\")\n",
    "    print(round(specificity,2))\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def up_sample(X_train_raw, y_train_raw,col_name):\n",
    "\n",
    "    # upsampling X_train and y_train\n",
    "    df_upsampled = pd.merge(X_train_raw, y_train_raw, left_index=True, right_index=True)\n",
    "\n",
    "    X_minority = df_upsampled[df_upsampled[col_name]==1]\n",
    "    X_majority = df_upsampled[df_upsampled[col_name]!=1]\n",
    "\n",
    "    n_samples = X_majority.shape[0]\n",
    "    X_minority_upsampled = resample(X_minority,\n",
    "                                    replace=True,     # sample with replacement\n",
    "                                    n_samples=n_samples,    # to match majority class\n",
    "                                    random_state=42) # reproducible results\n",
    "\n",
    "    df_upsampled = pd.concat([X_majority, X_minority_upsampled]).sample(frac=1)\n",
    "\n",
    "    y_train_out = df_upsampled[[col_name]]\n",
    "    X_train_out = df_upsampled.drop([col_name], axis=1)\n",
    "\n",
    "    return X_train_out, y_train_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### define cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "def param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 5, sample_ratio = 0.2, refit=True, use_error=True, multi_class=False, average_metric='macro'):\n",
    "\n",
    "    print(\"This search selects lower indexes of search list if their score is within the error of maximum score.\")\n",
    "    print(\"Putting parameters for less complicated model on the left side of the grid lists leads to better generalisation. \")\n",
    "    print(\" \")\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    n_train = int(sample_ratio * len(y_train))\n",
    "    X_train_s, y_train_s  = resample(X_train, y_train, n_samples=n_train, stratify=y_train)\n",
    "\n",
    "    best_score = {}\n",
    "    best_params = {}\n",
    "    for k, v in param_grid.items():\n",
    "        # best_params[k] = v[int(len(v)/2)-1]\n",
    "        best_params[k] = v[0]\n",
    "    best_params_m1 = best_params.copy()\n",
    "    print(\"start_params:\", best_params)\n",
    "\n",
    "    score = {}\n",
    "    score_std = {}\n",
    "\n",
    "    for i_iter in range(max_iter):\n",
    "        print(\"_\"*100)\n",
    "        print(\"Iteration\", i_iter)\n",
    "\n",
    "        for k, v in param_grid.items():\n",
    "\n",
    "            best_params1 = best_params.copy()\n",
    "            del best_params1[k]  \n",
    "\n",
    "            score[k] = v.copy()\n",
    "            score_std[k] = v.copy()\n",
    "\n",
    "            for i_param, val_param in enumerate(v):\n",
    "                cv_sc = np.zeros(cv)\n",
    "\n",
    "                for i_cv in range(cv):\n",
    "\n",
    "                    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train_s, y_train_s, test_size=0.2, stratify=y_train_s, shuffle=True) # 80% training and 20% test\n",
    "\n",
    "                    p1 = copy.deepcopy(pipe)\n",
    "                    p1.set_params(**best_params1)\n",
    "                    params2 = {k:val_param}\n",
    "                    p1.set_params(**params2)\n",
    "\n",
    "                    p1.fit(X_train2, y_train2.ravel())\n",
    "                    # X,y = p1.named_steps['resample'].fit_resample(X_test2, y_test2)\n",
    "                    X,y = X_test2, y_test2\n",
    "                    # y_pred_proba = p1.predict_proba(X)\n",
    "                    # cv_sc[i_cv] = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "                    y_pred = p1.predict(X)\n",
    "                    if(multi_class):\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred, average=average_metric)\n",
    "                    else:\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred)\n",
    "\n",
    "                    i_cv = i_cv + 1\n",
    "\n",
    "                score[k][i_param] = cv_sc.mean()\n",
    "                score_std[k][i_param] = cv_sc.std()\n",
    "\n",
    "            print(\"\")\n",
    "            print(k)\n",
    "            print(v)\n",
    "            print(score[k])\n",
    "\n",
    "            best_params[k] = v[np.argmax(score[k])]\n",
    "            best_score[k] = score[k][np.argmax(score[k])]\n",
    "\n",
    "            if use_error:\n",
    "                for i_b in  range(np.argmax(score[k]),-1,-1):\n",
    "                    err1 = (score_std[k][i_b] + score_std[k][v.index(best_params[k])] ) / 4\n",
    "                    # print(\"err1\")\n",
    "                    max_del = max(score[k]) - err1\n",
    "                    # print( i_b, score[k][i_b], max(score[k]), err1, max_del )\n",
    "                    if score[k][i_b] >= max_del:\n",
    "                        best_params[k] = v[i_b]\n",
    "                        best_score[k] = score[k][i_b]\n",
    "\n",
    "            print(\"best_param:\",  v[np.argmax(score[k])], \"score:\", max(score[k]))\n",
    "            print(\"selected_param:\",  best_params[k], \"score:\", best_score[k])\n",
    "            \n",
    "\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"best_params =\", best_params)\n",
    "        print(\"\")\n",
    "        if best_params_m1 == best_params:\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "            print(\"Early stop. No improvement in the last iteration.\")\n",
    "            break\n",
    "        best_params_m1 = best_params.copy()\n",
    "\n",
    "    param_graph_plot(score)\n",
    "\n",
    "    if refit:\n",
    "        print(\"Refitting final model...\")\n",
    "        pipeline_final = copy.deepcopy(pipe)\n",
    "        pipeline_final.set_params(**best_params)\n",
    "        pipeline_final.fit(X_train, y_train.values.ravel())\n",
    "    else:\n",
    "        pipeline_final = None\n",
    "\n",
    "    return score, best_params, pipeline_final\n",
    "    \n",
    "\n",
    "def param_graph_plot(score):\n",
    "    ax = {}\n",
    "    fig = {}\n",
    "    for i, (k, v) in enumerate(score.items()):\n",
    "        fig[k], ax[k] = plt.subplots()\n",
    "\n",
    "    for k, v in score.items():\n",
    "        x = score[k]\n",
    "        y = v\n",
    "        ax[k].plot(x,y,\"-o\", label=\"Score\")\n",
    "        # ax[k].set_ylim([0.5, 1])\n",
    "        ax[k].set_title(k)\n",
    "        ax[k].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Define upsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "class upsampler(BaseEstimator): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def fit_resample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).ravel()\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y == 0], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y == 1], y[y == 1]\n",
    "        else:\n",
    "            X1, y1 = resample(X[y == 1], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y == 0], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "        return X_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Load data and select index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table from database\n",
    "# database = \"data.sqlite\"\n",
    "# con = sqlite3.connect(database)\n",
    "\n",
    "# X_train = pd.read_sql_query(\"SELECT * from X_train\", con)\n",
    "# y_train = pd.read_sql_query(\"SELECT * from y_train\", con)\n",
    "# # select index\n",
    "# index_c = ['USUBJID'] # empty list for no index\n",
    "# X_train = X_train.set_index(index_c)\n",
    "# y_train = y_train.set_index(index_c)\n",
    "\n",
    "# X_train1 = X_train[~X_train.scr_umol_l.isna()]\n",
    "# y_train1 = y_train[~X_train.scr_umol_l.isna()]\n",
    "\n",
    "# X_test = pd.read_sql_query(\"SELECT * from X_test\", con)\n",
    "# y_test = pd.read_sql_query(\"SELECT * from y_test\", con)\n",
    "# # select index\n",
    "# index_c = ['USUBJID'] # empty list for no index\n",
    "# X_test = X_test.set_index(index_c)\n",
    "# y_test = y_test.set_index(index_c)\n",
    "\n",
    "# y_test = y_test[~X_test.scr_umol_l.isna()]\n",
    "# X_test = X_test[~X_test.scr_umol_l.isna()]\n",
    "\n",
    "\n",
    "# X_train, y_train  = resample(X_train, y_train, n_samples=5000, stratify=y_train)\n",
    "# X_test, y_test  = resample(X_test, y_test, n_samples=1000, stratify=y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "sqluser = 'uqhkamel'\n",
    "dbname = 'mimiciv'\n",
    "schema_name = 'mimic_derived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to {}'.format(schema_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select * from all_scr_preadmission_75_JOIN\"\n",
    "# data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id','hadm_id'])\n",
    "query = \"select * from all_scr_preadmission_75_min_mdrd_1_180days_JOIN\"\n",
    "data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id'])\n",
    "data.drop('hadm_id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ethnicity'] = data['ethnicity'].replace(['OTHER'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNKNOWN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['AMERICAN INDIAN/ALASKA NATIVE'],np.nan)\n",
    "\n",
    "data = data.fillna(value=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aki_kdigo = ['aki_kdigo_grade_1','aki_kdigo_grade_2','aki_kdigo_grade_3']\n",
    "\n",
    "# outcome_var = ['day_detection_kdigo_grade_1','day_detection_kdigo_grade_2','day_detection_kdigo_grade_3']\n",
    "\n",
    "# outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "# first_24h = 1\n",
    "# data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46300, 110)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 110)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['min_day_rrt_present']<=1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = []\n",
    "outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "first_24h = 1\n",
    "data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7354, 110)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['ckd']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['ckd']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 110)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['kidney_transplant']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['kidney_transplant']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data['egfr_mdrd_scr']>60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.egfr_mdrd_scr<60].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aki_kdigo_grade_1</th>\n",
       "      <th>aki_kdigo_grade_2</th>\n",
       "      <th>aki_kdigo_grade_3</th>\n",
       "      <th>day_detection_kdigo_grade_1</th>\n",
       "      <th>day_detection_kdigo_grade_2</th>\n",
       "      <th>day_detection_kdigo_grade_3</th>\n",
       "      <th>aki_mkdigo_grade_1</th>\n",
       "      <th>aki_mkdigo_grade_2</th>\n",
       "      <th>aki_mkdigo_grade_3</th>\n",
       "      <th>day_detection_mkdigo_grade_1</th>\n",
       "      <th>day_detection_mkdigo_grade_2</th>\n",
       "      <th>day_detection_mkdigo_grade_3</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>ckd</th>\n",
       "      <th>is_mdrd</th>\n",
       "      <th>egfr_epi_scr</th>\n",
       "      <th>egfr_mdrd_scr</th>\n",
       "      <th>kidney_transplant</th>\n",
       "      <th>congestive_heart_failure</th>\n",
       "      <th>diabetes_type2</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>obesity_icd</th>\n",
       "      <th>peripheral_vascular_disease</th>\n",
       "      <th>chronic_liver_disease</th>\n",
       "      <th>mild_liver_disease</th>\n",
       "      <th>severe_liver_disease</th>\n",
       "      <th>myocardial_infarct</th>\n",
       "      <th>chronic_pulmonary_disease</th>\n",
       "      <th>chronic_heart_failure</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>hemoglobin_min</th>\n",
       "      <th>hemoglobin_max</th>\n",
       "      <th>platelets_min</th>\n",
       "      <th>platelets_max</th>\n",
       "      <th>wbc_min</th>\n",
       "      <th>wbc_max</th>\n",
       "      <th>wbc_bd_min</th>\n",
       "      <th>wbc_bd_max</th>\n",
       "      <th>albumin_min</th>\n",
       "      <th>albumin_max</th>\n",
       "      <th>globulin_min</th>\n",
       "      <th>globulin_max</th>\n",
       "      <th>total_protein_min</th>\n",
       "      <th>total_protein_max</th>\n",
       "      <th>aniongap_min</th>\n",
       "      <th>aniongap_max</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>bun_min</th>\n",
       "      <th>bun_max</th>\n",
       "      <th>calcium_min</th>\n",
       "      <th>calcium_max</th>\n",
       "      <th>chloride_min</th>\n",
       "      <th>chloride_max</th>\n",
       "      <th>creatinine_min</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>glucose_min</th>\n",
       "      <th>glucose_max</th>\n",
       "      <th>sodium_min</th>\n",
       "      <th>sodium_max</th>\n",
       "      <th>potassium_min</th>\n",
       "      <th>potassium_max</th>\n",
       "      <th>pt_min</th>\n",
       "      <th>pt_max</th>\n",
       "      <th>thrombin_min</th>\n",
       "      <th>thrombin_max</th>\n",
       "      <th>ptt_min</th>\n",
       "      <th>ptt_max</th>\n",
       "      <th>inr_min</th>\n",
       "      <th>inr_max</th>\n",
       "      <th>bilirubin_total_min</th>\n",
       "      <th>bilirubin_total_max</th>\n",
       "      <th>egfr_epi_scr_max</th>\n",
       "      <th>egfr_mdrd_scr_max</th>\n",
       "      <th>heart_rate_min</th>\n",
       "      <th>heart_rate_max</th>\n",
       "      <th>heart_rate_mean</th>\n",
       "      <th>sbp_min</th>\n",
       "      <th>sbp_max</th>\n",
       "      <th>sbp_mean</th>\n",
       "      <th>dbp_min</th>\n",
       "      <th>dbp_max</th>\n",
       "      <th>dbp_mean</th>\n",
       "      <th>resp_rate_min</th>\n",
       "      <th>resp_rate_max</th>\n",
       "      <th>resp_rate_mean</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>arbs_acei</th>\n",
       "      <th>cyclosporine</th>\n",
       "      <th>bmi</th>\n",
       "      <th>urineoutput_24hr</th>\n",
       "      <th>supplemental_oxygen</th>\n",
       "      <th>invasive_vent</th>\n",
       "      <th>hfnc</th>\n",
       "      <th>non_invasive_vent</th>\n",
       "      <th>tracheostomy</th>\n",
       "      <th>min_day_rrt_present</th>\n",
       "      <th>min_day_rrt_active</th>\n",
       "      <th>weight_admit</th>\n",
       "      <th>weight_min</th>\n",
       "      <th>weight_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30004627</th>\n",
       "      <th>12844527</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>33.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>171.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>7.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>106.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>135.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.1</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>132.766667</td>\n",
       "      <td>43.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>66.900000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.586207</td>\n",
       "      <td>36.28</td>\n",
       "      <td>36.94</td>\n",
       "      <td>36.665714</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30011241</th>\n",
       "      <th>14731650</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>26.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>144.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>105.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10.9</td>\n",
       "      <td>12.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.3</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>71.240000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>119.360000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>47.600000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.888889</td>\n",
       "      <td>36.11</td>\n",
       "      <td>37.06</td>\n",
       "      <td>36.565000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30016265</th>\n",
       "      <th>16142166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>19.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>19.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>111.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>12.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.7</td>\n",
       "      <td>35.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>76.742857</td>\n",
       "      <td>72.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>113.270270</td>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>45.729730</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.94</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>81.5</td>\n",
       "      <td>94.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30022756</th>\n",
       "      <th>19658144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.2</td>\n",
       "      <td>44.4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>14.1</td>\n",
       "      <td>212.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.8</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>63.777778</td>\n",
       "      <td>94.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>128.961538</td>\n",
       "      <td>57.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>68.692308</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.629630</td>\n",
       "      <td>36.72</td>\n",
       "      <td>37.94</td>\n",
       "      <td>37.245714</td>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30023204</th>\n",
       "      <th>18738693</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>440.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>99.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.9</td>\n",
       "      <td>29.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>51.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>108.468750</td>\n",
       "      <td>63.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>106.700000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.935484</td>\n",
       "      <td>36.39</td>\n",
       "      <td>37.28</td>\n",
       "      <td>36.662222</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>86.1</td>\n",
       "      <td>86.1</td>\n",
       "      <td>86.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aki_kdigo_grade_1  aki_kdigo_grade_2  aki_kdigo_grade_3  \\\n",
       "stay_id  subject_id                                                            \n",
       "30004627 12844527                    0                  0                  0   \n",
       "30011241 14731650                    0                  0                  0   \n",
       "30016265 16142166                    0                  0                  0   \n",
       "30022756 19658144                    0                  0                  0   \n",
       "30023204 18738693                    1                  0                  0   \n",
       "\n",
       "                     day_detection_kdigo_grade_1  day_detection_kdigo_grade_2  \\\n",
       "stay_id  subject_id                                                             \n",
       "30004627 12844527                      9999999.0                    9999999.0   \n",
       "30011241 14731650                      9999999.0                    9999999.0   \n",
       "30016265 16142166                      9999999.0                    9999999.0   \n",
       "30022756 19658144                      9999999.0                    9999999.0   \n",
       "30023204 18738693                            1.0                    9999999.0   \n",
       "\n",
       "                     day_detection_kdigo_grade_3  aki_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                                    \n",
       "30004627 12844527                      9999999.0                   0   \n",
       "30011241 14731650                      9999999.0                   0   \n",
       "30016265 16142166                      9999999.0                   0   \n",
       "30022756 19658144                      9999999.0                   1   \n",
       "30023204 18738693                      9999999.0                   1   \n",
       "\n",
       "                     aki_mkdigo_grade_2  aki_mkdigo_grade_3  \\\n",
       "stay_id  subject_id                                           \n",
       "30004627 12844527                     0                   0   \n",
       "30011241 14731650                     0                   0   \n",
       "30016265 16142166                     0                   0   \n",
       "30022756 19658144                     1                   0   \n",
       "30023204 18738693                     1                   0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                 \n",
       "30004627 12844527                       9999999.0   \n",
       "30011241 14731650                       9999999.0   \n",
       "30016265 16142166                       9999999.0   \n",
       "30022756 19658144                             1.0   \n",
       "30023204 18738693                             1.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_2  \\\n",
       "stay_id  subject_id                                 \n",
       "30004627 12844527                       9999999.0   \n",
       "30011241 14731650                       9999999.0   \n",
       "30016265 16142166                       9999999.0   \n",
       "30022756 19658144                       9999999.0   \n",
       "30023204 18738693                       9999999.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_3   age  female  \\\n",
       "stay_id  subject_id                                               \n",
       "30004627 12844527                       9999999.0  63.0       0   \n",
       "30011241 14731650                       9999999.0  82.0       1   \n",
       "30016265 16142166                       9999999.0  79.0       1   \n",
       "30022756 19658144                       9999999.0  89.0       1   \n",
       "30023204 18738693                       9999999.0  46.0       0   \n",
       "\n",
       "                                  ethnicity  ckd  is_mdrd  egfr_epi_scr  \\\n",
       "stay_id  subject_id                                                       \n",
       "30004627 12844527    BLACK/AFRICAN AMERICAN    0        1          64.0   \n",
       "30011241 14731650                       NaN    0        1          52.0   \n",
       "30016265 16142166                       NaN    0        0          90.0   \n",
       "30022756 19658144                     WHITE    0        1          68.0   \n",
       "30023204 18738693                     WHITE    0        1          51.0   \n",
       "\n",
       "                     egfr_mdrd_scr  kidney_transplant  \\\n",
       "stay_id  subject_id                                     \n",
       "30004627 12844527             61.0                  0   \n",
       "30011241 14731650             53.0                  0   \n",
       "30016265 16142166            109.0                  0   \n",
       "30022756 19658144             71.0                  0   \n",
       "30023204 18738693             47.0                  0   \n",
       "\n",
       "                     congestive_heart_failure  diabetes_type2  \\\n",
       "stay_id  subject_id                                             \n",
       "30004627 12844527                           0               0   \n",
       "30011241 14731650                           0               0   \n",
       "30016265 16142166                           1               1   \n",
       "30022756 19658144                           0               0   \n",
       "30023204 18738693                           0               0   \n",
       "\n",
       "                     chronic_kidney_disease  hypertension  obesity_icd  \\\n",
       "stay_id  subject_id                                                      \n",
       "30004627 12844527                         0             0            0   \n",
       "30011241 14731650                         0             1            0   \n",
       "30016265 16142166                         0             1            0   \n",
       "30022756 19658144                         0             1            0   \n",
       "30023204 18738693                         0             1            0   \n",
       "\n",
       "                     peripheral_vascular_disease  chronic_liver_disease  \\\n",
       "stay_id  subject_id                                                       \n",
       "30004627 12844527                              0                      0   \n",
       "30011241 14731650                              0                      0   \n",
       "30016265 16142166                              1                      0   \n",
       "30022756 19658144                              0                      0   \n",
       "30023204 18738693                              0                      0   \n",
       "\n",
       "                     mild_liver_disease  severe_liver_disease  \\\n",
       "stay_id  subject_id                                             \n",
       "30004627 12844527                     0                     0   \n",
       "30011241 14731650                     0                     0   \n",
       "30016265 16142166                     0                     0   \n",
       "30022756 19658144                     0                     0   \n",
       "30023204 18738693                     0                     0   \n",
       "\n",
       "                     myocardial_infarct  chronic_pulmonary_disease  \\\n",
       "stay_id  subject_id                                                  \n",
       "30004627 12844527                     0                          0   \n",
       "30011241 14731650                     1                          1   \n",
       "30016265 16142166                     0                          0   \n",
       "30022756 19658144                     0                          0   \n",
       "30023204 18738693                     0                          0   \n",
       "\n",
       "                     chronic_heart_failure  sepsis  hematocrit_min  \\\n",
       "stay_id  subject_id                                                  \n",
       "30004627 12844527                        0       0            30.2   \n",
       "30011241 14731650                        0       0            25.7   \n",
       "30016265 16142166                        0       0            21.0   \n",
       "30022756 19658144                        0       0            40.2   \n",
       "30023204 18738693                        0       1            19.7   \n",
       "\n",
       "                     hematocrit_max  hemoglobin_min  hemoglobin_max  \\\n",
       "stay_id  subject_id                                                   \n",
       "30004627 12844527              33.5            10.2            11.3   \n",
       "30011241 14731650              26.4             8.0             8.4   \n",
       "30016265 16142166              35.4             8.0            11.8   \n",
       "30022756 19658144              44.4            12.4            14.1   \n",
       "30023204 18738693              24.4             6.6             8.3   \n",
       "\n",
       "                     platelets_min  platelets_max  wbc_min  wbc_max  \\\n",
       "stay_id  subject_id                                                   \n",
       "30004627 12844527            171.0          205.0      7.8     10.7   \n",
       "30011241 14731650            144.0          157.0     11.7     17.0   \n",
       "30016265 16142166             80.0          104.0     10.2     19.5   \n",
       "30022756 19658144            212.0          227.0      8.3      9.1   \n",
       "30023204 18738693            440.0          489.0     15.2     27.0   \n",
       "\n",
       "                     wbc_bd_min  wbc_bd_max  albumin_min  albumin_max  \\\n",
       "stay_id  subject_id                                                     \n",
       "30004627 12844527           7.8        10.7          NaN          NaN   \n",
       "30011241 14731650          11.7        17.0          2.4          2.4   \n",
       "30016265 16142166          10.2        19.5          NaN          NaN   \n",
       "30022756 19658144           8.3         9.1          4.2          4.2   \n",
       "30023204 18738693          15.2        27.0          2.8          2.8   \n",
       "\n",
       "                     globulin_min  globulin_max  total_protein_min  \\\n",
       "stay_id  subject_id                                                  \n",
       "30004627 12844527             NaN           NaN                NaN   \n",
       "30011241 14731650             NaN           NaN                NaN   \n",
       "30016265 16142166             NaN           NaN                NaN   \n",
       "30022756 19658144             NaN           NaN                NaN   \n",
       "30023204 18738693             NaN           NaN                NaN   \n",
       "\n",
       "                     total_protein_max  aniongap_min  aniongap_max  \\\n",
       "stay_id  subject_id                                                  \n",
       "30004627 12844527                  NaN          12.0          13.0   \n",
       "30011241 14731650                  NaN          10.0          11.0   \n",
       "30016265 16142166                  NaN           7.0          11.0   \n",
       "30022756 19658144                  NaN          18.0          18.0   \n",
       "30023204 18738693                  NaN          13.0          17.0   \n",
       "\n",
       "                     bicarbonate_min  bicarbonate_max  bun_min  bun_max  \\\n",
       "stay_id  subject_id                                                       \n",
       "30004627 12844527               23.0             24.0     29.0     29.0   \n",
       "30011241 14731650               25.0             27.0     17.0     19.0   \n",
       "30016265 16142166               24.0             24.0     13.0     16.0   \n",
       "30022756 19658144               24.0             25.0     20.0     23.0   \n",
       "30023204 18738693               19.0             22.0     23.0     24.0   \n",
       "\n",
       "                     calcium_min  calcium_max  chloride_min  chloride_max  \\\n",
       "stay_id  subject_id                                                         \n",
       "30004627 12844527            8.2          8.8         106.0         107.0   \n",
       "30011241 14731650            7.8          7.8         105.0         106.0   \n",
       "30016265 16142166            7.7          7.7         111.0         115.0   \n",
       "30022756 19658144           10.0         10.0         103.0         107.0   \n",
       "30023204 18738693            7.4          8.5         100.0         104.0   \n",
       "\n",
       "                     creatinine_min  creatinine_max  glucose_min  glucose_max  \\\n",
       "stay_id  subject_id                                                             \n",
       "30004627 12844527               1.0             1.2        135.0        148.0   \n",
       "30011241 14731650               0.8             1.0        103.0        124.0   \n",
       "30016265 16142166               0.4             0.5         88.0         88.0   \n",
       "30022756 19658144               0.4             0.4         90.0         94.0   \n",
       "30023204 18738693               1.4             1.6         99.0        124.0   \n",
       "\n",
       "                     sodium_min  sodium_max  potassium_min  potassium_max  \\\n",
       "stay_id  subject_id                                                         \n",
       "30004627 12844527         138.0       139.0            4.1            4.1   \n",
       "30011241 14731650         138.0       139.0            3.4            3.5   \n",
       "30016265 16142166         141.0       142.0            4.1            4.5   \n",
       "30022756 19658144         142.0       145.0            3.8            3.9   \n",
       "30023204 18738693         130.0       132.0            5.0            5.5   \n",
       "\n",
       "                     pt_min  pt_max  thrombin_min  thrombin_max  ptt_min  \\\n",
       "stay_id  subject_id                                                        \n",
       "30004627 12844527      13.0    13.0           NaN           NaN     28.1   \n",
       "30011241 14731650      10.9    12.8           NaN           NaN     27.3   \n",
       "30016265 16142166      12.9    16.7           NaN           NaN     22.7   \n",
       "30022756 19658144      11.3    11.4           NaN           NaN     29.8   \n",
       "30023204 18738693      10.8    10.9           NaN           NaN     27.9   \n",
       "\n",
       "                     ptt_max  inr_min  inr_max  bilirubin_total_min  \\\n",
       "stay_id  subject_id                                                   \n",
       "30004627 12844527       28.1      1.2      1.2                  NaN   \n",
       "30011241 14731650       27.7      1.0      1.2                  0.5   \n",
       "30016265 16142166       35.3      1.2      1.5                  NaN   \n",
       "30022756 19658144       33.4      1.0      1.1                  0.9   \n",
       "30023204 18738693       29.3      1.0      1.0                  0.7   \n",
       "\n",
       "                     bilirubin_total_max  egfr_epi_scr_max  egfr_mdrd_scr_max  \\\n",
       "stay_id  subject_id                                                             \n",
       "30004627 12844527                    NaN              64.0               61.0   \n",
       "30011241 14731650                    0.6              52.0               53.0   \n",
       "30016265 16142166                    NaN              92.0              119.0   \n",
       "30022756 19658144                    0.9              92.0              150.0   \n",
       "30023204 18738693                    0.7              51.0               47.0   \n",
       "\n",
       "                     heart_rate_min  heart_rate_max  heart_rate_mean  sbp_min  \\\n",
       "stay_id  subject_id                                                             \n",
       "30004627 12844527              55.0            81.0        71.000000    109.0   \n",
       "30011241 14731650              52.0            91.0        71.240000    101.0   \n",
       "30016265 16142166              51.0            85.0        76.742857     72.0   \n",
       "30022756 19658144              52.0            82.0        63.777778     94.0   \n",
       "30023204 18738693              93.0           125.0       108.468750     63.0   \n",
       "\n",
       "                     sbp_max    sbp_mean  dbp_min  dbp_max   dbp_mean  \\\n",
       "stay_id  subject_id                                                     \n",
       "30004627 12844527      156.0  132.766667     43.0     83.0  66.900000   \n",
       "30011241 14731650      147.0  119.360000     38.0     63.0  47.600000   \n",
       "30016265 16142166      152.0  113.270270     31.0     74.0  45.729730   \n",
       "30022756 19658144      155.0  128.961538     57.0    100.0  68.692308   \n",
       "30023204 18738693      128.0  106.700000     42.0     77.0  64.333333   \n",
       "\n",
       "                     resp_rate_min  resp_rate_max  resp_rate_mean  \\\n",
       "stay_id  subject_id                                                 \n",
       "30004627 12844527              8.0           21.0       15.586207   \n",
       "30011241 14731650              9.0           22.0       14.888889   \n",
       "30016265 16142166              7.0           26.0       17.250000   \n",
       "30022756 19658144             10.0           22.0       16.629630   \n",
       "30023204 18738693             10.0           23.0       15.935484   \n",
       "\n",
       "                     temperature_min  temperature_max  temperature_mean  \\\n",
       "stay_id  subject_id                                                       \n",
       "30004627 12844527              36.28            36.94         36.665714   \n",
       "30011241 14731650              36.11            37.06         36.565000   \n",
       "30016265 16142166                NaN              NaN               NaN   \n",
       "30022756 19658144              36.72            37.94         37.245714   \n",
       "30023204 18738693              36.39            37.28         36.662222   \n",
       "\n",
       "                     spo2_min  spo2_max  arbs_acei  cyclosporine    bmi  \\\n",
       "stay_id  subject_id                                                       \n",
       "30004627 12844527        95.0     100.0          0             0    NaN   \n",
       "30011241 14731650        94.0     100.0          0             0    NaN   \n",
       "30016265 16142166        95.0     100.0          0             0  47.94   \n",
       "30022756 19658144        94.0      97.0          1             0    NaN   \n",
       "30023204 18738693        91.0     100.0          0             0    NaN   \n",
       "\n",
       "                     urineoutput_24hr  supplemental_oxygen  invasive_vent  \\\n",
       "stay_id  subject_id                                                         \n",
       "30004627 12844527                60.0                    0              1   \n",
       "30011241 14731650                90.0                    0              1   \n",
       "30016265 16142166               150.0                    1              1   \n",
       "30022756 19658144               110.0                    0              0   \n",
       "30023204 18738693                50.0                    1              0   \n",
       "\n",
       "                     hfnc  non_invasive_vent  tracheostomy  \\\n",
       "stay_id  subject_id                                          \n",
       "30004627 12844527       0                  0             0   \n",
       "30011241 14731650       0                  0             0   \n",
       "30016265 16142166       0                  0             0   \n",
       "30022756 19658144       0                  0             0   \n",
       "30023204 18738693       0                  0             0   \n",
       "\n",
       "                     min_day_rrt_present  min_day_rrt_active  weight_admit  \\\n",
       "stay_id  subject_id                                                          \n",
       "30004627 12844527             99999999.0          99999999.0          81.0   \n",
       "30011241 14731650             99999999.0          99999999.0          85.0   \n",
       "30016265 16142166             99999999.0          99999999.0          81.5   \n",
       "30022756 19658144             99999999.0          99999999.0          62.0   \n",
       "30023204 18738693             99999999.0          99999999.0          86.1   \n",
       "\n",
       "                     weight_min  weight_max  \n",
       "stay_id  subject_id                          \n",
       "30004627 12844527          81.0        81.0  \n",
       "30011241 14731650          78.0        85.0  \n",
       "30016265 16142166          81.5        94.1  \n",
       "30022756 19658144          62.0        62.0  \n",
       "30023204 18738693          86.1        86.1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dropna(axis=1, thresh = int(0.3*data.shape[0]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_window = 3\n",
    "\n",
    "data.loc[(((data['aki_kdigo_grade_2']== 1) | (data['aki_kdigo_grade_3']==1)) \\\n",
    "    &((data['day_detection_kdigo_grade_2']<=prediction_window) | (data['day_detection_kdigo_grade_3']<=prediction_window)) \\\n",
    "        |(data['min_day_rrt_present']<= prediction_window)), 'outcome'] = 1\n",
    "\n",
    "\n",
    "data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_window = 3\n",
    "\n",
    "# data.loc[(( (data['aki_kdigo_grade_1']== 1)) \\\n",
    "#     &( (data['day_detection_kdigo_grade_1']<=prediction_window))), 'outcome'] = 1\n",
    "\n",
    "\n",
    "# data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "'day_detection_kdigo_grade_1',\n",
    "'day_detection_kdigo_grade_2',\n",
    "'day_detection_kdigo_grade_3',\n",
    "'day_detection_mkdigo_grade_1',\n",
    "'day_detection_mkdigo_grade_2',\n",
    "'day_detection_mkdigo_grade_3',\n",
    "'min_day_rrt_active',\n",
    "'min_day_rrt_present',\n",
    "# 'ckd',\n",
    "'chronic_kidney_disease'\n",
    "]\n",
    "# CRP and vomit_nausea as they had mostly empty\n",
    "\n",
    "data.drop(drop_X, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missingness percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.reset_index().drop_duplicates(subset=['stay_id','subject_id','hadm_id']).set_index(['stay_id','subject_id','hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove unpopulated columns\n",
    "# data.pipe(sort)\\\n",
    "#               .pipe(replace_inf).pipe(drop_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by column type\n",
    "data_num = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'numerical')\n",
    "\n",
    "data_cat = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cat = data_cat.pipe(filter_categorical, cutoff=20, plot=False)\\\n",
    "#                                             .pipe(sort).pipe(spy, title='Before onehot', figsize=[12,4])\\\n",
    "#                                             .fillna('other').pipe(onehot)\n",
    "# data_cat = data_cat.fillna('other').pipe(onehot)\n",
    "data_cat = pd.get_dummies(data_cat,prefix=[''], prefix_sep='', columns = ['ethnicity'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed = pd.merge(data_num, data_cat, left_index=True, right_index=True)\n",
    "processed = pd.merge(data_num, data_cat, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23651"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['is_mdrd'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9864\n",
       "1    3928\n",
       "Name: aki_kdigo_grade_1, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = processed[processed['is_mdrd']==0]\n",
    "tmp1.aki_kdigo_grade_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.165344657212295"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed.is_mdrd.value_counts()\n",
    "processed['is_mdrd'].sum()/len(processed)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2 = processed.copy()\n",
    "processed.drop(['egfr_epi_scr','egfr_mdrd_scr'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38252810939294396"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(processed[processed['aki_kdigo_grade_1']==1].shape[0])/processed.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "    'aki_kdigo_grade_1',\n",
    "    'aki_mkdigo_grade_1',\n",
    "\n",
    "    'aki_kdigo_grade_2',\n",
    "    'aki_mkdigo_grade_2',\n",
    "\n",
    "    'aki_kdigo_grade_3',\n",
    "    'aki_mkdigo_grade_3',\n",
    "    'is_mdrd'\n",
    "\n",
    "]\n",
    " \n",
    "select_y = ['outcome']\n",
    "\n",
    "processed_X = processed.pipe(filter_regex, drop_X+select_y)\n",
    "processed_Y = processed.filter(regex='|'.join(select_y))\n",
    "raw_Y = data_num.pipe(replace_inf).pipe(drop_empty).filter(regex='|'.join(select_y)).pipe(remove_outliers)\n",
    "df_y = raw_Y[select_y]\n",
    "\n",
    "\n",
    "df_X, df_y = match(processed_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20682\n",
       "1    16761\n",
       "Name: female, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.female.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_X, df_y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# X_train_0, X_test, y_train_0, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y) # \n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train_0, y_train_0, test_size=0.2, random_state=42, shuffle=True, stratify=y_train_0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = df_X, df_y\n",
    "# X_train, y_train = up_sample(X_train, y_train,'outcome')\n",
    "X_train,  y_train = [\n",
    "    df.reset_index(drop=True)\n",
    "    for df in up_sample(X_train, y_train,'outcome')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# rus = RandomUnderSampler(random_state=42, sampling_strategy='auto')\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfwiz_compare(X_train,X_test, label=['df_train','df_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0.0        33098\n",
       "1.0         4345\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm  # standard alias\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "('scaler', MinMaxScaler()),\n",
    "('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "('model', lgbm.LGBMClassifier(n_jobs=-1, n_estimators=300))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "('scaler', MinMaxScaler()),\n",
    "('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "('model', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Cross validation search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### **************************************8\n",
    "# # Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "\n",
    "\n",
    "# param_grid ={'model__num_leaves': [6, 10, 20, 50], \n",
    "#              'model__min_child_samples': [100, 200, 300, 400, 500], \n",
    "#              'model__min_child_weight': [1e-5,  1e-2,  1,  1e2,  1e4],\n",
    "#              'model__subsample' : [0.2, 0.5, 0.8], \n",
    "#              'model__reg_alpha': [0, 1e-1, 1, 5,  10, 50, 100],\n",
    "#              'model__reg_lambda': [0, 1e-1, 1,  10,  50, 100]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# score, best_params, pipeline_final = param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True)\n",
    "\n",
    "# # dump(pipeline_final , open('pipeline_final_LGBM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgbm  # standard alias\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# # ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan, sample_posterior=True)),\n",
    "# ('model', lgbm.LGBMClassifier(n_jobs=-1))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt import BayesSearchCV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# bayes_cv_tuner = BayesSearchCV(\n",
    "#     estimator = pipe\n",
    "#     ,search_spaces = {\n",
    "#         'model__n_estimators': (100,200,300,400),\n",
    "#         'model__num_leaves': (6, 10, 20, 50), \n",
    "#         'model__min_child_samples': (100, 200, 300, 400, 500), \n",
    "#         'model__min_child_weight': (1e-5,  1e-2,  1,  1e2,  1e4),\n",
    "#         'model__subsample' : (0.2, 0.5, 0.8), \n",
    "#         'model__reg_alpha': (0, 1e-1, 1, 5,  10, 50, 100),\n",
    "#         'model__reg_lambda': (0, 1e-1, 1,  10,  50, 100)\n",
    "\n",
    "#     }, \n",
    "#     cv = StratifiedKFold(\n",
    "#         n_splits=3,\n",
    "#         shuffle=True,\n",
    "#     ),\n",
    "#     # cv=3,\n",
    "#     n_jobs = 3,\n",
    "#     n_iter = 10,   \n",
    "#     verbose = 0,\n",
    "#     scoring='f1'\n",
    "# )\n",
    "\n",
    "# sample_ratio = 0.1\n",
    "# n_samples = int(len(X_train)*sample_ratio)\n",
    "# X, y = resample(X_train.values, y_train.values, n_samples=n_samples, stratify=y_train.values, random_state=10)\n",
    "# result = bayes_cv_tuner.fit(X, y.ravel())\n",
    "# # print(result.score(X_test, y_test))\n",
    "# print(result.best_params_)\n",
    "# print(result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Fitting Pipeline one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "Train Accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.95      0.90     26478\n",
      "         1.0       0.94      0.84      0.89     26478\n",
      "\n",
      "    accuracy                           0.90     52956\n",
      "   macro avg       0.90      0.90      0.89     52956\n",
      "weighted avg       0.90      0.90      0.89     52956\n",
      "\n",
      "\n",
      "_________________________________________\n",
      "\n",
      "Specificity\n",
      "\n",
      "0.95\n",
      "\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "# manual params setting\n",
    "# best_params = {'model__num_leaves': 20, 'model__min_child_samples': 100, 'model__min_child_weight': 0.01, 'model__subsample': 0.8, 'model__reg_alpha': 0, 'model__reg_lambda': 0.1}\n",
    "# best_params = {'model__n_estimators': 400,'model__num_leaves': 20, 'model__min_child_samples': 300, 'model__min_child_weight': 0.01, 'model__subsample': 0.2, 'model__reg_alpha': 1, 'model__reg_lambda': 50}\n",
    "# best_params = {'model__min_child_samples': 300, 'model__min_child_weight': 1, 'model__n_estimators': 400, 'model__num_leaves': 20, 'model__reg_alpha': 1.0, 'model__reg_lambda': 50, 'model__subsample': 0.2}\n",
    "# best_params = {'model__num_leaves': 20, 'model__min_child_samples': 300, 'model__min_child_weight': 1, 'model__subsample': 0.2, 'model__reg_alpha': 0.1, 'model__reg_lambda': 50}\n",
    "\n",
    "best_params = {'model__n_estimators':100,'model__max_depth':120\n",
    ",'model__min_samples_leaf': 100, 'model__min_samples_split': 100}\n",
    "\n",
    "# Or get parameters from search above\n",
    "best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train)*sample_ratio)\n",
    "X, y = resample(X_train.values, y_train.outcome.values, n_samples=n_samples, stratify=y_train.values, random_state=10)\n",
    "pipeline_final = copy.deepcopy(pipe)\n",
    "pipeline_final.set_params(**best_params2)\n",
    "pipeline_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(pipeline_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.95      6620\n",
      "         1.0       0.57      0.80      0.67       869\n",
      "\n",
      "    accuracy                           0.91      7489\n",
      "   macro avg       0.77      0.86      0.81      7489\n",
      "weighted avg       0.93      0.91      0.91      7489\n",
      "\n",
      "\n",
      "_________________________________________\n",
      "\n",
      "Specificity\n",
      "\n",
      "0.92\n",
      "\n",
      "_________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X,y = pipeline_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "\n",
    "X,y = X_test.values, y_test.values\n",
    "\n",
    "y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.45).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_XGB_grade23, tpr_XGB_grade23, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "%store fpr_XGB_grade23\n",
    "%store tpr_XGB_grade23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r fpr_XGB_grade123\n",
    "%store -r tpr_XGB_grade123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7.5,6)\n",
    "plt.rcParams[\"figure.figsize\"] = (9,8)\n",
    "mpl.rcParams['lines.linewidth'] = 1.5\n",
    "plt.plot(fpr_XGB_grade23,tpr_XGB_grade23,label=\"XGB (AKI grade_2_3) AUC=\"+str(round(0.93,2)))\n",
    "plt.plot(fpr_XGB_grade123,tpr_XGB_grade123,label=\"XGB (AKI grade_1_2_3) AUC=\"+str(round(0.88,2)))\n",
    "plt.plot([0, 1], [0, 1], marker=\".\", alpha=0.4)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator = pipeline_final._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = final_estimator.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,20)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_impute(df, pipe):\n",
    "    data_scaled = pipe.named_steps['scaler'].transform(df)\n",
    "    df_scaled = pd.DataFrame(data_scaled, columns=df.columns)\n",
    "    data_imputed = pipe.named_steps['imputer'].transform(df_scaled)\n",
    "    df_result = pd.DataFrame(data_imputed, columns=df.columns)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "exp = dx.Explainer(pipeline_final, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_parts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number = 1\n",
    "exp.predict_parts(X_test.iloc[[row_number]], N=100).plot(min_max=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_t = scale_impute_via_pipeline(df=X_test,pipe=pipeline_final)\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(final_estimator)\n",
    "shap_values = explainer.shap_values(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.temperature_min.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.temperature_min.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"age\",shap_values[1], X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_t = scale_impute_via_pipeline(X_train, pipeline_final)\n",
    "shap.initjs()\n",
    "# X_sampled = df_X_train_imp.sample(100, random_state=10)\n",
    "explainer = shap.TreeExplainer(final_estimator)\n",
    "shap_values = explainer.shap_values(X_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"age\",shap_values[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_train_t,max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_t = scale_impute(df=X_test,pipe=pipeline_final)\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(pipeline_final._final_estimator)\n",
    "shap_values = explainer.shap_values(X_test_t)\n",
    "shap.summary_plot(shap_values[1], X_test_t, max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X_train.columns:\n",
    "    shap.dependence_plot(name, shap_values[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHAP values\n",
    "\n",
    "# compute SHAP values\n",
    "X_test_t = scale_impute(df=X_test,pipe=pipeline_final)\n",
    "shap.initjs()\n",
    "explainer = shap.Explainer(pipeline_final._final_estimator, X_test_t)\n",
    "shap_values = explainer(X_test_t,check_additivity=False)\n",
    "shap.plots.beeswarm(shap_values,max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number=1\n",
    "single_observation = X_train.iloc[[row_number]].values[0]\n",
    "X_train_t = scale_impute(df=X_train,pipe=pipeline_final)\n",
    "\n",
    "# data = shap_values.data[row_number]\n",
    "# data = single_observation\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.Explainer(final_estimator,X_train_t, check_additivity=False)\n",
    "# shap_values = explainer(X_train_t)\n",
    "shap_values = explainer(single_observation)\n",
    "\n",
    "\n",
    "\n",
    "class ShapObject:\n",
    "    \n",
    "    def __init__(self, base_values, data, values, feature_names):\n",
    "        self.base_values = base_values # Single value\n",
    "        self.data = data # Raw feature values for 1 row of data\n",
    "        self.values = values # SHAP values for the same row of data\n",
    "        self.feature_names = feature_names # Column names\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "shap_object = ShapObject(base_values = shap_values.base_values[row_number],\n",
    "                         values = shap_values.values[row_number],\n",
    "                         feature_names = single_observation.columns,\n",
    "                         data = single_observation)\n",
    "\n",
    "                         \n",
    "\n",
    "shap.waterfall_plot(shap_object, max_display=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining X_test,y_test and y_pred in one dataset\n",
    "# del(df_test_all)\n",
    "df_test_all = X_test.copy()\n",
    "df_test_all['y_actual'] = y_test\n",
    "df_test_all['y_pred'] = y_pred\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3\n",
    "\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TN = df_test_all[df_test_all.error_category==0]\n",
    "df_FP = df_test_all[df_test_all.error_category==1]\n",
    "\n",
    "df_TP = df_test_all[df_test_all.error_category==2]\n",
    "df_FN = df_test_all[df_test_all.error_category==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "df_TN_shap = df_TN.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "df_TN_shap = scale_impute_via_pipeline(df_TN_shap)\n",
    "shap.initjs()\n",
    "# X_sampled = df_X_train_imp.sample(100, random_state=10)\n",
    "explainer = shap.TreeExplainer(final_estimator)\n",
    "shap_values = explainer.shap_values(df_TN_shap)\n",
    "shap.summary_plot(shap_values[1], df_TN_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "# error_df = {\"df_FP\":df_FP, \"df_FN\":df_FN}\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "    df_shap = scale_impute_via_pipeline(df_shap, final_estimator)\n",
    "\n",
    "    explainer = shap.TreeExplainer(final_estimator)\n",
    "    shap_values = explainer.shap_values(df_shap)\n",
    "    print(\"SHAP: \"+k)\n",
    "    shap.summary_plot(shap_values[1], df_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_processed = processed2.copy()\n",
    "common_FN = pd.merge(df_FN, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "common_FN.drop([col for col in common_FN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "common_FN.aki_kdigo_grade_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FN.aki_kdigo_grade_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FN.aki_kdigo_grade_3.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "exp = dx.Explainer(pipeline_final, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_performance(model_type='classification').plot(geom='roc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_parts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number = 1\n",
    "exp.predict_parts(X_test.iloc[[row_number]], N=100).plot(min_max=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[[row_number]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[row_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "# error_df = {\"df_FP\":df_FP, \"df_FN\":df_FN}\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "\n",
    "    row_number = 1\n",
    "    print(\"SHAP: \"+k)\n",
    "    exp.predict_parts(df_shap.iloc[[row_number]], N=100).plot(min_max=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the DataFrames\n",
    "# common_processed = processed2.copy()\n",
    "common_processed = processed.copy()\n",
    "common_FP = pd.merge(df_FP, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FP.drop([col for col in common_FP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TN = pd.merge(df_TN, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TN.drop([col for col in common_TN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TP = pd.merge(df_TP, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TP.drop([col for col in common_TP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_FN = pd.merge(df_FN, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FN.drop([col for col in common_FN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_test_all = pd.merge(df_test_all, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_test_all.drop([col for col in common_test_all.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FP.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FP, kind=\"hex\", joint_kws={'color':'#66ffcc'})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<60].shape[0])/(common_FP.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<60].shape[0])/(processed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_TN[common_TN.egfr_epi_scr<60].shape[0])/(common_TN.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<60].shape[0])/(processed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TP, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr_max\", y=\"age\", data=common_FN, kind=\"hex\", joint_kws={'color':\"#ffe6ff\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FP, kind=\"hex\", joint_kws={'color':'#66ffcc'})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hist2d(common_FP.egfr_epi_scr, common_FP.age, bins=[x_bins, y_bins])\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hexbin(common_FP.egfr_epi_scr, common_FP.age, bins=50)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(common_FP.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=common_FP, x=col, bins=50, stat='percent', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for True negative and  False positive and compare their distribution.\n",
    "# It plots the distribution and prints Jensen-Shanon distance.\n",
    "# from functions_compare_distribution import compare_hist_df\n",
    "from dfwiz import dfwiz, dfwiz_compare\n",
    "# healthy patients\n",
    "TN = df_test_all.query(\"error_category == 0\")[X_test.columns] # True negative\n",
    "FP = df_test_all.query(\"error_category == 1\")[X_test.columns] # False positive\n",
    "\n",
    "if len(TN) == 0 or len(FP) == 0:\n",
    "    print(\"Error! one of the dataframes are empty\")\n",
    "else:\n",
    "    # compare_hist_df(TN, FP) # plot distributions and output Jensen-Shanon distance.\n",
    "    dfwiz_compare(FP, TN,label=['FP', 'TN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.kdeplot(data=df_test_all, x=col, hue='error_category', bins=50, stat='density', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', common_norm=False, bins=50, stat=\"percent\");\n",
    "    plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_FP, x=df_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"density\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', bins=len(df_test_all), stat='density', element=\"step\", fill=False, cumulative=True,common_norm=False);\n",
    "    plt.title(\"Cumulative distribution function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree on validation set to differentiate between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "del(df_test_all)\n",
    "\n",
    "# X_valid_imputed_array = pipeline_final.named_steps['imputer'].transform(X_valid)\n",
    "X_test_scaled_array = pipeline_final.named_steps['scaler'].transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "X_test_imp_array = pipeline_final.named_steps['imputer'].transform(X_test_scaled)\n",
    "df_test_all = pd.DataFrame(X_test_imp_array, columns=X_test.columns)\n",
    "\n",
    "\n",
    "# df_test_all['y_actual'] = y_valid.values.ravel()\n",
    "df_test_all['y_actual'] = y_test.values.ravel()\n",
    "df_test_all['y_pred'] = y_pred\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP', 'TP', 'FN' ]\n",
    "df1 = df_test_all.copy()\n",
    "X1 = df1[X_test.columns]\n",
    "X1\n",
    "y1 =  df1[['error_category']]\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 5 , class_weight='balanced', random_state=42, criterion=\"gini\", min_impurity_decrease = 0.01)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "plt.figure(figsize=(20,12))\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = list(X1.columns), \n",
    "               rounded=True, \n",
    "               filled = True,\n",
    "               proportion = True,\n",
    "               class_names = class_names);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_imputed_array = pipeline_final.named_steps['imputer'].transform(X_train)\n",
    "# X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "# X_train_scaled_array = pipeline_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "# X_train_imputed = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "# X_valid_imputed_array = pipeline_final.named_steps['imputer'].transform(X_valid)\n",
    "# X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "# X_valid_scaled__array = pipeline_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "# X_valid_imputed = pd.DataFrame(X_valid_scaled__array, columns=X_valid.columns)\n",
    "\n",
    "# y_error_t = clf.predict(X_train_imputed)\n",
    "# y_error_v = clf.predict(X_valid_imputed)\n",
    "\n",
    "# # True Negatives (0)\n",
    "# X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "# y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "# X_valid_TN = X_valid.loc[(y_error_v==0)]\n",
    "# y_valid_TN = y_valid.loc[(y_error_v==0)]\n",
    "\n",
    "# # False Positives (1)\n",
    "# X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "# y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "# X_valid_FP = X_valid.loc[(y_error_v==1)]\n",
    "# y_valid_FP = y_valid.loc[(y_error_v==1)]\n",
    "\n",
    "# # True Positives (2)\n",
    "# X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "# y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "# X_valid_TP = X_valid.loc[(y_error_v==2)]\n",
    "# y_valid_TP = y_valid.loc[(y_error_v==2)]\n",
    "\n",
    "# # False Negatives (3)\n",
    "# X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "# y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "# X_valid_FN = X_valid.loc[(y_error_v==3)]\n",
    "# y_valid_FN = y_valid.loc[(y_error_v==3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = pipeline_final.named_steps['imputer'].transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = pipeline_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_train_imputed = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "X_test_imputed_array = pipeline_final.named_steps['imputer'].transform(X_test)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed_array, columns=X_test.columns)\n",
    "X_test_scaled_array = pipeline_final.named_steps['scaler'].transform(X_test_imputed)\n",
    "X_test_imputed = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "\n",
    "y_error_t = pipeline_final.predict(X_train_imputed)\n",
    "y_error_v = pipeline_final.predict(X_test_imputed)\n",
    "\n",
    "# True Negatives (0)\n",
    "X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "X_valid_TN = X_test.loc[(y_error_v==0)]\n",
    "y_valid_TN = y_test.loc[(y_error_v==0)]\n",
    "\n",
    "# False Positives (1)\n",
    "X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "X_valid_FP = X_test.loc[(y_error_v==1)]\n",
    "y_valid_FP = y_test.loc[(y_error_v==1)]\n",
    "\n",
    "# True Positives (2)\n",
    "X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "X_valid_TP = X_test.loc[(y_error_v==2)]\n",
    "y_valid_TP = y_test.loc[(y_error_v==2)]\n",
    "\n",
    "# False Negatives (3)\n",
    "X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "X_valid_FN = X_test.loc[(y_error_v==3)]\n",
    "y_valid_FN = y_test.loc[(y_error_v==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_FP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.loc[~(y_error_t==1)]\n",
    "y_train_new = y_train.loc[~(y_error_t==1)]\n",
    "\n",
    "X_valid_new = X_valid.loc[~(y_error_v==1)]\n",
    "y_valid_new = y_valid.loc[~(y_error_v==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new, y_train_new = up_sample(X_train_new, y_train_new,'outcome')\n",
    "X_train_new, y_train_new = up_sample(X_train, y_train,'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 350, 'model__min_samples_split': 350}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_new)*sample_ratio)\n",
    "X, y = resample(X_train_new.values, y_train_new.values, n_samples=n_samples, stratify=y_train_new.values, random_state=10)\n",
    "pipeline_final = copy.deepcopy(pipe)\n",
    "pipeline_final.set_params(**best_params2)\n",
    "pipeline_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(pipeline_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = pipeline_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_new.values, y_valid_new.values\n",
    "\n",
    "# X,y = X_test.values, y_test.values\n",
    "\n",
    "y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.6).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,20)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_RF = df_test_all.copy()\n",
    "y = df_valid_RF.error_category\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgbm  # standard alias\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "# ('model', lgbm.LGBMClassifier(n_jobs=-1, n_estimators=300))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF to classify 4 error categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### **************************************8\n",
    "# Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "# param_grid ={'model__num_leaves': [6, 10, 20, 50], \n",
    "#              'model__min_child_samples': [100, 200, 300, 400, 500], \n",
    "#              'model__min_child_weight': [1e-5,  1e-2,  1,  1e2,  1e4],\n",
    "#              'model__subsample' : [0.2, 0.5, 0.8], \n",
    "#              'model__reg_alpha': [0, 1e-1, 1, 5,  10, 50, 100],\n",
    "#              'model__reg_lambda': [0, 1e-1, 1,  10,  50, 100]}\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 500 ],\n",
    "    'model__max_depth': [ 30 , 40, 50 , 60 , 80, 100],\n",
    "    'model__min_samples_leaf': [100, 70, 50,20, 10,5],\n",
    "    'model__min_samples_split' : [100, 70, 50,20, 10,5]\n",
    "}\n",
    "\n",
    "# param_grid ={'model__max_depth': [6, 10], \n",
    "#    }\n",
    "df_valid_RF = df_test_all.copy()\n",
    "y = df_valid_RF.error_category\n",
    "X = df_valid_RF.drop(['y_actual','y_pred','error_category'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "score, best_params, pipeline_final = param_graph(X, y, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True, multi_class=True, average_metric=\"micro\")\n",
    "\n",
    "# dump(pipeline_final , open('pipeline_final_LGBM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP', 'TP', 'FN' ]\n",
    "df1 = df_test_all.copy()\n",
    "X1 = df1[X_valid.columns]\n",
    "y1 =  df1[['error_category']]\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "# plt.figure(figsize=(20,12))\n",
    "# tree.plot_tree(clf,\n",
    "#                feature_names = list(X1.columns), \n",
    "#                rounded=True, \n",
    "#                filled = True,\n",
    "#                proportion = True,\n",
    "#                class_names = class_names);\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix,plot_confusion_matrix\n",
    "# cm = multilabel_confusion_matrix(y1, y_pred)\n",
    "plot_confusion_matrix(clf, X1, y1, display_labels=['TN','FP','TP','FN'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = pipeline_final.named_steps['imputer'].transform(X_test)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = pipeline_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_test_imputed_scaled = pd.DataFrame(X_train_scaled_array, columns=X_test.columns)\n",
    "\n",
    "y_pred2 =clf.predict(X_test_imputed_scaled)\n",
    "# plot_confusion_matrix(clf, X_test, y_test, display_labels=['TN','FP','TP','FN'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = np.where((y_pred2==0) | (y_pred2==2),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_pred3==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import multilabel_confusion_matrix,plot_confusion_matrix\n",
    "\n",
    "\n",
    "# best_params2 = {'model__n_estimators':100,'model__max_depth': 80\n",
    "# ,'model__min_samples_leaf': 50, 'model__min_samples_split': 50}\n",
    "\n",
    "\n",
    "# df_valid_RF = df_test_all.copy()\n",
    "# y = df_valid_RF.error_category\n",
    "# X = df_valid_RF.drop(['y_actual','y_pred','error_category'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# sample_ratio = 1\n",
    "# n_samples = int(len(X)*sample_ratio)\n",
    "# X, y = resample(X, y, n_samples=n_samples, stratify=y, random_state=10)\n",
    "# model_RF_error_cat = copy.deepcopy(pipe)\n",
    "# model_RF_error_cat.set_params(**best_params2)\n",
    "# model_RF_error_cat.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "# print(\"_\"*150)\n",
    "# print(\"\")\n",
    "# print(\"Train Accuracy:\")\n",
    "# print(\"\")\n",
    "\n",
    "# y_pred = model_RF_error_cat.predict(X)\n",
    "# y_pred_proba = model_RF_error_cat.predict_proba(X)\n",
    "\n",
    "# cm = multilabel_confusion_matrix(y, y_pred)\n",
    "# plot_confusion_matrix(model_RF_error_cat, X, y, display_labels=['TN','FP','TP','FN'])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # display_labels=['TN','FP','TP','FN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_array = pipeline_final.named_steps['imputer'].transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed_array, columns=X_train.columns)\n",
    "X_train_scaled_array = pipeline_final.named_steps['scaler'].transform(X_train_imputed)\n",
    "X_train_imputed_scaled = pd.DataFrame(X_train_scaled_array, columns=X_train.columns)\n",
    "\n",
    "\n",
    "X_valid_imputed_array = pipeline_final.named_steps['imputer'].transform(X_valid)\n",
    "X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "X_valid_scaled__array = pipeline_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "X_valid_imputed_scaled = pd.DataFrame(X_valid_scaled__array, columns=X_valid.columns)\n",
    "\n",
    "\n",
    "y_error_t = clf.predict(X_train_imputed_scaled)\n",
    "y_error_v = clf.predict(X_valid_imputed_scaled)\n",
    "\n",
    "# True Negatives (0)\n",
    "X_train_TN = X_train.loc[(y_error_t==0)]\n",
    "y_train_TN = y_train.loc[(y_error_t==0)]\n",
    "\n",
    "X_valid_TN = X_valid.loc[(y_error_v==0)]\n",
    "y_valid_TN = y_valid.loc[(y_error_v==0)]\n",
    "\n",
    "# False Positives (1)\n",
    "X_train_FP = X_train.loc[(y_error_t==1)]\n",
    "y_train_FP = y_train.loc[(y_error_t==1)]\n",
    "\n",
    "X_valid_FP = X_valid.loc[(y_error_v==1)]\n",
    "y_valid_FP = y_valid.loc[(y_error_v==1)]\n",
    "\n",
    "# True Positives (2)\n",
    "X_train_TP = X_train.loc[(y_error_t==2)]\n",
    "y_train_TP = y_train.loc[(y_error_t==2)]\n",
    "\n",
    "X_valid_TP = X_valid.loc[(y_error_v==2)]\n",
    "y_valid_TP = y_valid.loc[(y_error_v==2)]\n",
    "\n",
    "# False Negatives (3)\n",
    "X_train_FN = X_train.loc[(y_error_t==3)]\n",
    "y_train_FN = y_train.loc[(y_error_t==3)]\n",
    "\n",
    "X_valid_FN = X_valid.loc[(y_error_v==3)]\n",
    "y_valid_FN = y_valid.loc[(y_error_v==3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_error_v==3)\n",
    "# y_valid_TP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y_error_v==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_FN.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_True, y_train_True = up_sample(X_train_True, y_train_True,'outcome')\n",
    "# X_train_False, y_train_False = up_sample(X_train_False, y_train_False,'outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TN estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 250, 'model__min_samples_split': 250}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_TN)*sample_ratio)\n",
    "X, y = resample(X_train_TN.values, y_train_TN.values, n_samples=n_samples, stratify=y_train_TN.values, random_state=10)\n",
    "pipeline_final_TN = copy.deepcopy(pipe)\n",
    "pipeline_final_TN.set_params(**best_params2)\n",
    "pipeline_final_TN.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = pipeline_final_TN.predict(X)\n",
    "y_pred_proba = pipeline_final_TN.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(pipeline_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_FP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = pipeline_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_TN.values, y_valid_TN.values\n",
    "\n",
    "# y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final_TN.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 40\n",
    ",'model__min_samples_leaf': 50, 'model__min_samples_split': 50}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_FP)*sample_ratio)\n",
    "X, y = resample(X_train_FP.values, y_train_FP.values, n_samples=n_samples, stratify=y_train_FP.values, random_state=10)\n",
    "pipeline_final_FP = copy.deepcopy(pipe)\n",
    "pipeline_final_FP.set_params(**best_params2)\n",
    "pipeline_final_FP.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = pipeline_final_FP.predict(X)\n",
    "y_pred_proba = pipeline_final_FP.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(pipeline_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = pipeline_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_FP.values, y_valid_FP.values\n",
    "\n",
    "# y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final_FP.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 150, 'model__min_samples_split': 150}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_TP)*sample_ratio)\n",
    "X, y = resample(X_train_TP.values, y_train_TP.values, n_samples=n_samples, stratify=y_train_TP.values, random_state=10)\n",
    "pipeline_final_TP = copy.deepcopy(pipe)\n",
    "pipeline_final_TP.set_params(**best_params2)\n",
    "pipeline_final_TP.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = pipeline_final_TP.predict(X)\n",
    "y_pred_proba = pipeline_final_TP.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(pipeline_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_TP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = pipeline_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_TP.values, y_valid_TP.values\n",
    "\n",
    "# y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final_TP.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FN estimitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "# best_params2 = {'model__n_estimators':300,'model__max_depth': 40\n",
    "# ,'model__min_samples_leaf': 0.1, 'model__min_samples_split': 0.1}\n",
    "\n",
    "best_params2 = {'model__n_estimators':100,'model__max_depth': 50\n",
    ",'model__min_samples_leaf': 250, 'model__min_samples_split': 250}\n",
    "\n",
    "\n",
    "# Or get parameters from search above\n",
    "# best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train_FN)*sample_ratio)\n",
    "X, y = resample(X_train_FN.values, y_train_FN.values, n_samples=n_samples, stratify=y_train_FN.values, random_state=10)\n",
    "pipeline_final_FN = copy.deepcopy(pipe)\n",
    "pipeline_final_FN.set_params(**best_params2)\n",
    "pipeline_final_FN.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = pipeline_final_FN.predict(X)\n",
    "y_pred_proba = pipeline_final_FN.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(pipeline_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = pipeline_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "X,y = X_valid_FN.values, y_valid_FN.values\n",
    "\n",
    "# y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final_FN.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = X_test, y_test\n",
    "\n",
    "y_pred_proba_list = []\n",
    "for i in range(len(X)):\n",
    "    # X_imputed = pipeline_final.named_steps['imputer'].transform(X.iloc[[i]])\n",
    "    X_valid_imputed_array = pipeline_final.named_steps['imputer'].transform(X.iloc[[i]])\n",
    "    X_valid_imputed = pd.DataFrame(X_valid_imputed_array, columns=X_valid.columns)\n",
    "    X_valid_scaled_array = pipeline_final.named_steps['scaler'].transform(X_valid_imputed)\n",
    "    df_test_all = pd.DataFrame(X_valid_scaled_array, columns=X_valid.columns)\n",
    "    tree_predict = clf.predict(df_test_all)\n",
    "    if(tree_predict == 0): #TN\n",
    "        y_pred_proba_list.insert(i, list(pipeline_final_TN.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 1): #FP\n",
    "        y_pred_proba_list.insert(i, list(pipeline_final_FP.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 2): #TP\n",
    "        y_pred_proba_list.insert(i, list(pipeline_final_TP.predict_proba(X.iloc[[i]])[0]))\n",
    "    elif(tree_predict == 3): #FN\n",
    "        y_pred_proba_list.insert(i, list(pipeline_final_FN.predict_proba(X.iloc[[i]])[0]))\n",
    "\n",
    "y_pred_proba = np.array(y_pred_proba_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = (y_pred_proba[:,1] >= 0.4).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7ea45291871ad6e398ab50f9f84dad559e0de667f49db4aea6ebf0e175149ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
