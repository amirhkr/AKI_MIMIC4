{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('/Users/uqhkamel/PhD/Code/AKI_mimiciv/mimic-code-main/mimic-iv/src')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "from dfwiz import dfwiz\n",
    "from dfwiz import dfwiz_compare\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from utils.vis import spy, look, plot_nunique, plot_dists\n",
    "from utils.processing import sort, impute, replace_inf, drop_empty, select, drop_by_nunique, scale, melt, unmelt, \\\n",
    "                             remove_outliers, get_categories, filter_categorical, onehot, filter_regex, match, cap,get_dates\n",
    "from utils.pipelines import scale_impute_via_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables representing experiment parameters\n",
    "EXPERIMENT = 'Processing Demo'\n",
    "IMPUTE_NUM = 'constant'\n",
    "IMPUTE_CAT = 'other'\n",
    "FIGSIZE    = [12,3]\n",
    "\n",
    "# parameter dict\n",
    "params = {\n",
    "    'experiment':EXPERIMENT,\n",
    "    'figsize'   :FIGSIZE,\n",
    "    'impute_num':IMPUTE_NUM,\n",
    "    'impute_cat':IMPUTE_CAT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy as sp\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn')\n",
    "sns.set_theme(style=\"ticks\")\n",
    "mpl.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "# Title\n",
    "mpl.rcParams['figure.titlesize'] = 22\n",
    "mpl.rcParams['figure.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlesize'] = 22\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlepad'] = 20\n",
    "\n",
    "# Axes labels\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "\n",
    "# Grid and thicks\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['axes.grid.axis'] = 'y'\n",
    "#mpl.rcParams['axes.xmargin'] = 0\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "\n",
    "# Legend\n",
    "mpl.rcParams['legend.facecolor'] = 'w'\n",
    "mpl.rcParams['legend.title_fontsize'] = 14\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['legend.frameon'] = True\n",
    "mpl.rcParams['legend.framealpha'] = 1\n",
    "mpl.rcParams['legend.fancybox'] = True\n",
    "mpl.rcParams['legend.facecolor'] = 'white'\n",
    "mpl.rcParams['legend.edgecolor'] = 'blue'\n",
    "mpl.rcParams['legend.borderpad'] = 0.6\n",
    "\n",
    "# Other\n",
    "mpl.rcParams['lines.linewidth'] = 2.5\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['scatter.edgecolors'] = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### upsampler func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "class upsampler(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        return X\n",
    "\n",
    "    def sample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y[y == 0]], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y[y == 1]], y[y == 1]\n",
    "        else:\n",
    "            print(X[y[y == 0]].shape)\n",
    "            X1, y1 = resample(X[y[y == 1]], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y[y == 0]], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "\n",
    "        return X_out, y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### accuracy func def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y, y_pred, y_pred_proba):\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "    score = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.plot(fpr,tpr,label=\"AUC=\"+str(round(score,2)))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['Negative','Positive']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    # print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "    cr = classification_report(y, y_pred)\n",
    "    print(\"\\r\\n\"+\"Classification report\"+\"\\r\\n\")\n",
    "    print(cr)\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    print(\"\\r\\n\"+\"Specificity\"+\"\\r\\n\")\n",
    "    print(round(specificity,2))\n",
    "\n",
    "    print(\"\\r\\n_________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def up_sample(X_train_raw, y_train_raw,col_name):\n",
    "\n",
    "    # upsampling X_train and y_train\n",
    "    df_upsampled = pd.merge(X_train_raw, y_train_raw, left_index=True, right_index=True)\n",
    "\n",
    "    X_minority = df_upsampled[df_upsampled[col_name]==1]\n",
    "    X_majority = df_upsampled[df_upsampled[col_name]!=1]\n",
    "\n",
    "    n_samples = X_majority.shape[0]\n",
    "    X_minority_upsampled = resample(X_minority,\n",
    "                                    replace=True,     # sample with replacement\n",
    "                                    n_samples=n_samples,    # to match majority class\n",
    "                                    random_state=42) # reproducible results\n",
    "\n",
    "    df_upsampled = pd.concat([X_majority, X_minority_upsampled]).sample(frac=1)\n",
    "\n",
    "    y_train_out = df_upsampled[[col_name]]\n",
    "    X_train_out = df_upsampled.drop([col_name], axis=1)\n",
    "\n",
    "    return X_train_out, y_train_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "### define cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "def param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 5, sample_ratio = 0.2, refit=True, use_error=True, multi_class=False, average_metric='macro'):\n",
    "\n",
    "    print(\"This search selects lower indexes of search list if their score is within the error of maximum score.\")\n",
    "    print(\"Putting parameters for less complicated model on the left side of the grid lists leads to better generalisation. \")\n",
    "    print(\" \")\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    n_train = int(sample_ratio * len(y_train))\n",
    "    X_train_s, y_train_s  = resample(X_train, y_train, n_samples=n_train, stratify=y_train)\n",
    "\n",
    "    best_score = {}\n",
    "    best_params = {}\n",
    "    for k, v in param_grid.items():\n",
    "        # best_params[k] = v[int(len(v)/2)-1]\n",
    "        best_params[k] = v[0]\n",
    "    best_params_m1 = best_params.copy()\n",
    "    print(\"start_params:\", best_params)\n",
    "\n",
    "    score = {}\n",
    "    score_std = {}\n",
    "\n",
    "    for i_iter in range(max_iter):\n",
    "        print(\"_\"*100)\n",
    "        print(\"Iteration\", i_iter)\n",
    "\n",
    "        for k, v in param_grid.items():\n",
    "\n",
    "            best_params1 = best_params.copy()\n",
    "            del best_params1[k]  \n",
    "\n",
    "            score[k] = v.copy()\n",
    "            score_std[k] = v.copy()\n",
    "\n",
    "            for i_param, val_param in enumerate(v):\n",
    "                cv_sc = np.zeros(cv)\n",
    "\n",
    "                for i_cv in range(cv):\n",
    "\n",
    "                    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train_s, y_train_s, test_size=0.2, stratify=y_train_s, shuffle=True) # 80% training and 20% test\n",
    "\n",
    "                    p1 = copy.deepcopy(pipe)\n",
    "                    p1.set_params(**best_params1)\n",
    "                    params2 = {k:val_param}\n",
    "                    p1.set_params(**params2)\n",
    "\n",
    "                    p1.fit(X_train2, y_train2.ravel())\n",
    "                    # X,y = p1.named_steps['resample'].fit_resample(X_test2, y_test2)\n",
    "                    X,y = X_test2, y_test2\n",
    "                    # y_pred_proba = p1.predict_proba(X)\n",
    "                    # cv_sc[i_cv] = metrics.roc_auc_score(y,  y_pred_proba[::,1])\n",
    "                    y_pred = p1.predict(X)\n",
    "                    if(multi_class):\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred, average=average_metric)\n",
    "                    else:\n",
    "                        cv_sc[i_cv] = metrics.f1_score(y, y_pred)\n",
    "\n",
    "                    i_cv = i_cv + 1\n",
    "\n",
    "                score[k][i_param] = cv_sc.mean()\n",
    "                score_std[k][i_param] = cv_sc.std()\n",
    "\n",
    "            print(\"\")\n",
    "            print(k)\n",
    "            print(v)\n",
    "            print(score[k])\n",
    "\n",
    "            best_params[k] = v[np.argmax(score[k])]\n",
    "            best_score[k] = score[k][np.argmax(score[k])]\n",
    "\n",
    "            if use_error:\n",
    "                for i_b in  range(np.argmax(score[k]),-1,-1):\n",
    "                    err1 = (score_std[k][i_b] + score_std[k][v.index(best_params[k])] ) / 4\n",
    "                    # print(\"err1\")\n",
    "                    max_del = max(score[k]) - err1\n",
    "                    # print( i_b, score[k][i_b], max(score[k]), err1, max_del )\n",
    "                    if score[k][i_b] >= max_del:\n",
    "                        best_params[k] = v[i_b]\n",
    "                        best_score[k] = score[k][i_b]\n",
    "\n",
    "            print(\"best_param:\",  v[np.argmax(score[k])], \"score:\", max(score[k]))\n",
    "            print(\"selected_param:\",  best_params[k], \"score:\", best_score[k])\n",
    "            \n",
    "\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"best_params =\", best_params)\n",
    "        print(\"\")\n",
    "        if best_params_m1 == best_params:\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "            print(\"Early stop. No improvement in the last iteration.\")\n",
    "            break\n",
    "        best_params_m1 = best_params.copy()\n",
    "\n",
    "    param_graph_plot(score)\n",
    "\n",
    "    if refit:\n",
    "        print(\"Refitting final model...\")\n",
    "        pipeline_final = copy.deepcopy(pipe)\n",
    "        pipeline_final.set_params(**best_params)\n",
    "        pipeline_final.fit(X_train, y_train.values.ravel())\n",
    "    else:\n",
    "        pipeline_final = None\n",
    "\n",
    "    return score, best_params, pipeline_final\n",
    "    \n",
    "\n",
    "def param_graph_plot(score):\n",
    "    ax = {}\n",
    "    fig = {}\n",
    "    for i, (k, v) in enumerate(score.items()):\n",
    "        fig[k], ax[k] = plt.subplots()\n",
    "\n",
    "    for k, v in score.items():\n",
    "        x = score[k]\n",
    "        y = v\n",
    "        ax[k].plot(x,y,\"-o\", label=\"Score\")\n",
    "        # ax[k].set_ylim([0.5, 1])\n",
    "        ax[k].set_title(k)\n",
    "        ax[k].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Define upsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "class upsampler(BaseEstimator): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def fit_resample(self, X, y = None):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).ravel()\n",
    "        if len(y[y == 0]) < len(y[y == 1]):\n",
    "            X1, y1 = resample(X[y == 0], y[y == 0], random_state=0, n_samples=len(y[y == 1]))\n",
    "            X2, y2 = X[y == 1], y[y == 1]\n",
    "        else:\n",
    "            X1, y1 = resample(X[y == 1], y[y == 1], random_state=0, n_samples=len(y[y == 0]))\n",
    "            X2, y2 = X[y == 0], y[y == 0]\n",
    "        X_out = np.vstack((X1, X2))\n",
    "        y_out = np.hstack((y1, y2))  \n",
    "        return X_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "### Load data and select index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection\n",
    "sqluser = 'uqhkamel'\n",
    "dbname = 'mimiciv'\n",
    "schema_name = 'mimic_derived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local postgres version of mimic\n",
    "con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "cur = con.cursor()\n",
    "cur.execute('SET search_path to {}'.format(schema_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select * from all_scr_preadmission_75_JOIN\"\n",
    "# data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id','hadm_id'])\n",
    "query = \"select * from AKI_ICU_JOIN_SB\"\n",
    "data = pd.read_sql_query(query,con,index_col=['stay_id','subject_id'])\n",
    "data.drop('hadm_id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ethnicity'] = data['ethnicity'].replace(['OTHER'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNKNOWN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['UNABLE TO OBTAIN'],np.nan)\n",
    "data['ethnicity'] = data['ethnicity'].replace(['AMERICAN INDIAN/ALASKA NATIVE'],np.nan)\n",
    "\n",
    "data = data.fillna(value=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aki_kdigo = ['aki_kdigo_grade_1','aki_kdigo_grade_2','aki_kdigo_grade_3']\n",
    "\n",
    "# outcome_var = ['day_detection_kdigo_grade_1','day_detection_kdigo_grade_2','day_detection_kdigo_grade_3']\n",
    "\n",
    "# outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "# first_24h = 1\n",
    "# data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39497, 108)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1231, 108)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['min_day_rrt_present']<=1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = []\n",
    "outcome_var.append('min_day_rrt_present')\n",
    "\n",
    "\n",
    "first_24h = 1\n",
    "data= data[data[outcome_var].min(axis=1)>first_24h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6675, 108)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['ckd']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['ckd']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 108)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['kidney_transplant']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['kidney_transplant']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data['egfr_mdrd_scr']>60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.egfr_mdrd_scr<60].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aki_kdigo_grade_1</th>\n",
       "      <th>aki_kdigo_grade_2</th>\n",
       "      <th>aki_kdigo_grade_3</th>\n",
       "      <th>day_detection_kdigo_grade_1</th>\n",
       "      <th>day_detection_kdigo_grade_2</th>\n",
       "      <th>day_detection_kdigo_grade_3</th>\n",
       "      <th>aki_mkdigo_grade_1</th>\n",
       "      <th>aki_mkdigo_grade_2</th>\n",
       "      <th>aki_mkdigo_grade_3</th>\n",
       "      <th>day_detection_mkdigo_grade_1</th>\n",
       "      <th>day_detection_mkdigo_grade_2</th>\n",
       "      <th>day_detection_mkdigo_grade_3</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>ckd</th>\n",
       "      <th>kidney_transplant</th>\n",
       "      <th>congestive_heart_failure</th>\n",
       "      <th>diabetes_type2</th>\n",
       "      <th>chronic_kidney_disease</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>obesity_icd</th>\n",
       "      <th>peripheral_vascular_disease</th>\n",
       "      <th>chronic_liver_disease</th>\n",
       "      <th>mild_liver_disease</th>\n",
       "      <th>severe_liver_disease</th>\n",
       "      <th>myocardial_infarct</th>\n",
       "      <th>chronic_pulmonary_disease</th>\n",
       "      <th>aschronic_heart_failure</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>hemoglobin_min</th>\n",
       "      <th>hemoglobin_max</th>\n",
       "      <th>platelets_min</th>\n",
       "      <th>platelets_max</th>\n",
       "      <th>wbc_min</th>\n",
       "      <th>wbc_max</th>\n",
       "      <th>wbc_bd_min</th>\n",
       "      <th>wbc_bd_max</th>\n",
       "      <th>albumin_min</th>\n",
       "      <th>albumin_max</th>\n",
       "      <th>globulin_min</th>\n",
       "      <th>globulin_max</th>\n",
       "      <th>total_protein_min</th>\n",
       "      <th>total_protein_max</th>\n",
       "      <th>aniongap_min</th>\n",
       "      <th>aniongap_max</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>bun_min</th>\n",
       "      <th>bun_max</th>\n",
       "      <th>calcium_min</th>\n",
       "      <th>calcium_max</th>\n",
       "      <th>chloride_min</th>\n",
       "      <th>chloride_max</th>\n",
       "      <th>creatinine_min</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>glucose_min</th>\n",
       "      <th>glucose_max</th>\n",
       "      <th>sodium_min</th>\n",
       "      <th>sodium_max</th>\n",
       "      <th>potassium_min</th>\n",
       "      <th>potassium_max</th>\n",
       "      <th>pt_min</th>\n",
       "      <th>pt_max</th>\n",
       "      <th>thrombin_min</th>\n",
       "      <th>thrombin_max</th>\n",
       "      <th>ptt_min</th>\n",
       "      <th>ptt_max</th>\n",
       "      <th>inr_min</th>\n",
       "      <th>inr_max</th>\n",
       "      <th>bilirubin_total_min</th>\n",
       "      <th>bilirubin_total_max</th>\n",
       "      <th>egfr_epi_scr_max</th>\n",
       "      <th>egfr_mdrd_scr_max</th>\n",
       "      <th>heart_rate_min</th>\n",
       "      <th>heart_rate_max</th>\n",
       "      <th>heart_rate_mean</th>\n",
       "      <th>sbp_min</th>\n",
       "      <th>sbp_max</th>\n",
       "      <th>sbp_mean</th>\n",
       "      <th>dbp_min</th>\n",
       "      <th>dbp_max</th>\n",
       "      <th>dbp_mean</th>\n",
       "      <th>resp_rate_min</th>\n",
       "      <th>resp_rate_max</th>\n",
       "      <th>resp_rate_mean</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>arbs_acei</th>\n",
       "      <th>cyclosporine</th>\n",
       "      <th>bmi</th>\n",
       "      <th>urineoutput_24hr</th>\n",
       "      <th>supplemental_oxygen</th>\n",
       "      <th>invasive_vent</th>\n",
       "      <th>hfnc</th>\n",
       "      <th>non_invasive_vent</th>\n",
       "      <th>tracheostomy</th>\n",
       "      <th>min_day_rrt_present</th>\n",
       "      <th>min_day_rrt_active</th>\n",
       "      <th>weight_admit</th>\n",
       "      <th>weight_min</th>\n",
       "      <th>weight_max</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30529524</th>\n",
       "      <th>19052676</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>442.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>107.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>16.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.6</td>\n",
       "      <td>40.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>100.906250</td>\n",
       "      <td>82.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>109.636364</td>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>39.030303</td>\n",
       "      <td>11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22.078125</td>\n",
       "      <td>36.61</td>\n",
       "      <td>38.28</td>\n",
       "      <td>37.453333</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.78</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31772784</th>\n",
       "      <th>15123107</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>36.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>202.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>98.807692</td>\n",
       "      <td>138.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>155.846154</td>\n",
       "      <td>67.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>77.269231</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.461538</td>\n",
       "      <td>36.39</td>\n",
       "      <td>37.17</td>\n",
       "      <td>36.747143</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>475.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>67.4</td>\n",
       "      <td>67.4</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32906132</th>\n",
       "      <th>14029832</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>28.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>211.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.8</td>\n",
       "      <td>27.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>101.523810</td>\n",
       "      <td>83.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>128.666667</td>\n",
       "      <td>59.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>81.952381</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>36.56</td>\n",
       "      <td>37.28</td>\n",
       "      <td>36.940000</td>\n",
       "      <td>95.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>77.8</td>\n",
       "      <td>77.8</td>\n",
       "      <td>77.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35949655</th>\n",
       "      <th>10240707</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>10.9</td>\n",
       "      <td>150.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>105.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>118.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.3</td>\n",
       "      <td>26.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>87.636364</td>\n",
       "      <td>87.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>63.900000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.181818</td>\n",
       "      <td>36.83</td>\n",
       "      <td>37.22</td>\n",
       "      <td>37.025000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>125.3</td>\n",
       "      <td>125.3</td>\n",
       "      <td>125.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33571346</th>\n",
       "      <th>13443421</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>164.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5</td>\n",
       "      <td>31.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>90.280000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>68.083333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>36.61</td>\n",
       "      <td>37.39</td>\n",
       "      <td>37.111250</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>59.8</td>\n",
       "      <td>59.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aki_kdigo_grade_1  aki_kdigo_grade_2  aki_kdigo_grade_3  \\\n",
       "stay_id  subject_id                                                            \n",
       "30529524 19052676                    1                  1                  0   \n",
       "31772784 15123107                    1                  0                  0   \n",
       "32906132 14029832                    0                  0                  0   \n",
       "35949655 10240707                    1                  0                  0   \n",
       "33571346 13443421                    1                  0                  0   \n",
       "\n",
       "                     day_detection_kdigo_grade_1  day_detection_kdigo_grade_2  \\\n",
       "stay_id  subject_id                                                             \n",
       "30529524 19052676                            1.0                          2.0   \n",
       "31772784 15123107                            1.0                    9999999.0   \n",
       "32906132 14029832                      9999999.0                    9999999.0   \n",
       "35949655 10240707                            1.0                    9999999.0   \n",
       "33571346 13443421                            1.0                    9999999.0   \n",
       "\n",
       "                     day_detection_kdigo_grade_3  aki_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                                    \n",
       "30529524 19052676                      9999999.0                   1   \n",
       "31772784 15123107                      9999999.0                   1   \n",
       "32906132 14029832                      9999999.0                   0   \n",
       "35949655 10240707                      9999999.0                   1   \n",
       "33571346 13443421                      9999999.0                   1   \n",
       "\n",
       "                     aki_mkdigo_grade_2  aki_mkdigo_grade_3  \\\n",
       "stay_id  subject_id                                           \n",
       "30529524 19052676                     1                   0   \n",
       "31772784 15123107                     0                   0   \n",
       "32906132 14029832                     0                   0   \n",
       "35949655 10240707                     0                   0   \n",
       "33571346 13443421                     0                   0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_1  \\\n",
       "stay_id  subject_id                                 \n",
       "30529524 19052676                             1.0   \n",
       "31772784 15123107                             1.0   \n",
       "32906132 14029832                       9999999.0   \n",
       "35949655 10240707                             1.0   \n",
       "33571346 13443421                             1.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_2  \\\n",
       "stay_id  subject_id                                 \n",
       "30529524 19052676                             2.0   \n",
       "31772784 15123107                       9999999.0   \n",
       "32906132 14029832                       9999999.0   \n",
       "35949655 10240707                       9999999.0   \n",
       "33571346 13443421                       9999999.0   \n",
       "\n",
       "                     day_detection_mkdigo_grade_3   age  female ethnicity  \\\n",
       "stay_id  subject_id                                                         \n",
       "30529524 19052676                       9999999.0  44.0       0       NaN   \n",
       "31772784 15123107                       9999999.0  71.0       1       NaN   \n",
       "32906132 14029832                       9999999.0  55.0       1       NaN   \n",
       "35949655 10240707                       9999999.0  73.0       0       NaN   \n",
       "33571346 13443421                       9999999.0  33.0       1       NaN   \n",
       "\n",
       "                     ckd  kidney_transplant  congestive_heart_failure  \\\n",
       "stay_id  subject_id                                                     \n",
       "30529524 19052676      0                  0                         1   \n",
       "31772784 15123107      0                  0                         0   \n",
       "32906132 14029832      0                  0                         0   \n",
       "35949655 10240707      0                  0                         1   \n",
       "33571346 13443421      0                  0                         0   \n",
       "\n",
       "                     diabetes_type2  chronic_kidney_disease  hypertension  \\\n",
       "stay_id  subject_id                                                         \n",
       "30529524 19052676                 0                       0             0   \n",
       "31772784 15123107                 1                       0             1   \n",
       "32906132 14029832                 1                       0             1   \n",
       "35949655 10240707                 1                       0             0   \n",
       "33571346 13443421                 0                       0             0   \n",
       "\n",
       "                     obesity_icd  peripheral_vascular_disease  \\\n",
       "stay_id  subject_id                                             \n",
       "30529524 19052676              0                            0   \n",
       "31772784 15123107              0                            0   \n",
       "32906132 14029832              0                            0   \n",
       "35949655 10240707              0                            0   \n",
       "33571346 13443421              0                            0   \n",
       "\n",
       "                     chronic_liver_disease  mild_liver_disease  \\\n",
       "stay_id  subject_id                                              \n",
       "30529524 19052676                        0                   0   \n",
       "31772784 15123107                        0                   0   \n",
       "32906132 14029832                        0                   0   \n",
       "35949655 10240707                        0                   0   \n",
       "33571346 13443421                        0                   0   \n",
       "\n",
       "                     severe_liver_disease  myocardial_infarct  \\\n",
       "stay_id  subject_id                                             \n",
       "30529524 19052676                       0                   1   \n",
       "31772784 15123107                       0                   0   \n",
       "32906132 14029832                       0                   0   \n",
       "35949655 10240707                       0                   1   \n",
       "33571346 13443421                       0                   0   \n",
       "\n",
       "                     chronic_pulmonary_disease  aschronic_heart_failure  \\\n",
       "stay_id  subject_id                                                       \n",
       "30529524 19052676                            0                        1   \n",
       "31772784 15123107                            0                        0   \n",
       "32906132 14029832                            0                        0   \n",
       "35949655 10240707                            1                        1   \n",
       "33571346 13443421                            0                        0   \n",
       "\n",
       "                     sepsis  hematocrit_min  hematocrit_max  hemoglobin_min  \\\n",
       "stay_id  subject_id                                                           \n",
       "30529524 19052676         1            24.6            24.6             7.7   \n",
       "31772784 15123107         0            36.4            36.4            11.6   \n",
       "32906132 14029832         0            19.6            28.1             6.2   \n",
       "35949655 10240707         0            28.0            33.2             9.4   \n",
       "33571346 13443421         0            33.0            44.0            11.1   \n",
       "\n",
       "                     hemoglobin_max  platelets_min  platelets_max  wbc_min  \\\n",
       "stay_id  subject_id                                                          \n",
       "30529524 19052676               7.7          442.0          442.0     14.5   \n",
       "31772784 15123107              11.6          202.0          202.0     13.0   \n",
       "32906132 14029832               9.2          211.0          247.0      8.5   \n",
       "35949655 10240707              10.9          150.0          202.0     13.1   \n",
       "33571346 13443421              13.6          164.0          284.0     14.6   \n",
       "\n",
       "                     wbc_max  wbc_bd_min  wbc_bd_max  albumin_min  \\\n",
       "stay_id  subject_id                                                 \n",
       "30529524 19052676       14.5        14.5        14.5          NaN   \n",
       "31772784 15123107       13.0        13.0        13.0          3.4   \n",
       "32906132 14029832        9.7         8.5         9.7          3.0   \n",
       "35949655 10240707       16.4        13.1        16.4          3.3   \n",
       "33571346 13443421       24.0        14.6        24.0          3.6   \n",
       "\n",
       "                     albumin_max  globulin_min  globulin_max  \\\n",
       "stay_id  subject_id                                            \n",
       "30529524 19052676            NaN           NaN           NaN   \n",
       "31772784 15123107            3.4           NaN           NaN   \n",
       "32906132 14029832            3.0           NaN           NaN   \n",
       "35949655 10240707            3.3           NaN           NaN   \n",
       "33571346 13443421            4.4           NaN           NaN   \n",
       "\n",
       "                     total_protein_min  total_protein_max  aniongap_min  \\\n",
       "stay_id  subject_id                                                       \n",
       "30529524 19052676                  NaN                NaN          16.0   \n",
       "31772784 15123107                  NaN                NaN          17.0   \n",
       "32906132 14029832                  NaN                NaN          12.0   \n",
       "35949655 10240707                  NaN                NaN          16.0   \n",
       "33571346 13443421                  NaN                NaN          14.0   \n",
       "\n",
       "                     aniongap_max  bicarbonate_min  bicarbonate_max  bun_min  \\\n",
       "stay_id  subject_id                                                            \n",
       "30529524 19052676            18.0             25.0             26.0     30.0   \n",
       "31772784 15123107            17.0             24.0             24.0      8.0   \n",
       "32906132 14029832            12.0             22.0             22.0     12.0   \n",
       "35949655 10240707            21.0             16.0             18.0     80.0   \n",
       "33571346 13443421            14.0             17.0             19.0     11.0   \n",
       "\n",
       "                     bun_max  calcium_min  calcium_max  chloride_min  \\\n",
       "stay_id  subject_id                                                    \n",
       "30529524 19052676       37.0          9.1          9.2          94.0   \n",
       "31772784 15123107        8.0          8.8          8.8          99.0   \n",
       "32906132 14029832       12.0          8.0          8.0         104.0   \n",
       "35949655 10240707       84.0          7.9          8.6         105.0   \n",
       "33571346 13443421       14.0          8.0         22.5         106.0   \n",
       "\n",
       "                     chloride_max  creatinine_min  creatinine_max  \\\n",
       "stay_id  subject_id                                                 \n",
       "30529524 19052676            95.0             1.4             1.9   \n",
       "31772784 15123107            99.0             0.5             0.5   \n",
       "32906132 14029832           104.0             1.1             1.1   \n",
       "35949655 10240707           111.0             1.3             1.7   \n",
       "33571346 13443421           106.0             0.9             1.2   \n",
       "\n",
       "                     glucose_min  glucose_max  sodium_min  sodium_max  \\\n",
       "stay_id  subject_id                                                     \n",
       "30529524 19052676          107.0        141.0       136.0       138.0   \n",
       "31772784 15123107          208.0        208.0       140.0       140.0   \n",
       "32906132 14029832          364.0        364.0       138.0       138.0   \n",
       "35949655 10240707          118.0        124.0       139.0       141.0   \n",
       "33571346 13443421          107.0        110.0       133.0       135.0   \n",
       "\n",
       "                     potassium_min  potassium_max  pt_min  pt_max  \\\n",
       "stay_id  subject_id                                                 \n",
       "30529524 19052676              3.9            4.2    16.4    16.4   \n",
       "31772784 15123107              3.6            3.6    12.3    12.3   \n",
       "32906132 14029832              3.8            3.8    10.8    10.8   \n",
       "35949655 10240707              4.2            5.1    11.7    14.6   \n",
       "33571346 13443421              3.7            3.9    11.1    11.7   \n",
       "\n",
       "                     thrombin_min  thrombin_max  ptt_min  ptt_max  inr_min  \\\n",
       "stay_id  subject_id                                                          \n",
       "30529524 19052676             NaN           NaN     27.6     40.4      1.5   \n",
       "31772784 15123107             NaN           NaN     23.3     23.3      1.1   \n",
       "32906132 14029832             NaN           NaN     27.8     27.8      1.0   \n",
       "35949655 10240707             NaN           NaN     21.3     26.1      1.1   \n",
       "33571346 13443421             NaN           NaN     25.5     31.6      1.0   \n",
       "\n",
       "                     inr_max  bilirubin_total_min  bilirubin_total_max  \\\n",
       "stay_id  subject_id                                                      \n",
       "30529524 19052676        1.5                  0.6                  0.6   \n",
       "31772784 15123107        1.1                  NaN                  NaN   \n",
       "32906132 14029832        1.0                  0.2                  0.2   \n",
       "35949655 10240707        1.3                  0.3                  0.3   \n",
       "33571346 13443421        1.1                  0.4                  0.4   \n",
       "\n",
       "                     egfr_epi_scr_max  egfr_mdrd_scr_max  heart_rate_min  \\\n",
       "stay_id  subject_id                                                        \n",
       "30529524 19052676                42.0               39.0            82.0   \n",
       "31772784 15123107                97.0              122.0            91.0   \n",
       "32906132 14029832                56.0               52.0            72.0   \n",
       "35949655 10240707                39.0               40.0            80.0   \n",
       "33571346 13443421                59.0               52.0            75.0   \n",
       "\n",
       "                     heart_rate_max  heart_rate_mean  sbp_min  sbp_max  \\\n",
       "stay_id  subject_id                                                      \n",
       "30529524 19052676             138.0       100.906250     82.0    152.0   \n",
       "31772784 15123107             111.0        98.807692    138.0    171.0   \n",
       "32906132 14029832             135.0       101.523810     83.0    158.0   \n",
       "35949655 10240707             100.0        87.636364     87.0    108.0   \n",
       "33571346 13443421             131.0        90.280000     88.0    123.0   \n",
       "\n",
       "                       sbp_mean  dbp_min  dbp_max   dbp_mean  resp_rate_min  \\\n",
       "stay_id  subject_id                                                           \n",
       "30529524 19052676    109.636364     31.0     72.0  39.030303           11.0   \n",
       "31772784 15123107    155.846154     67.0     87.0  77.269231           11.0   \n",
       "32906132 14029832    128.666667     59.0    114.0  81.952381            5.0   \n",
       "35949655 10240707     98.000000     53.0     71.0  63.900000           15.0   \n",
       "33571346 13443421    102.500000     55.0     81.0  68.083333           12.0   \n",
       "\n",
       "                     resp_rate_max  resp_rate_mean  temperature_min  \\\n",
       "stay_id  subject_id                                                   \n",
       "30529524 19052676             40.0       22.078125            36.61   \n",
       "31772784 15123107             32.0       18.461538            36.39   \n",
       "32906132 14029832             27.0       16.333333            36.56   \n",
       "35949655 10240707             26.0       19.181818            36.83   \n",
       "33571346 13443421             31.0       20.000000            36.61   \n",
       "\n",
       "                     temperature_max  temperature_mean  spo2_min  spo2_max  \\\n",
       "stay_id  subject_id                                                          \n",
       "30529524 19052676              38.28         37.453333      80.0     100.0   \n",
       "31772784 15123107              37.17         36.747143      90.0     100.0   \n",
       "32906132 14029832              37.28         36.940000      95.0     100.0   \n",
       "35949655 10240707              37.22         37.025000      96.0     100.0   \n",
       "33571346 13443421              37.39         37.111250      90.0     100.0   \n",
       "\n",
       "                     arbs_acei  cyclosporine    bmi  urineoutput_24hr  \\\n",
       "stay_id  subject_id                                                     \n",
       "30529524 19052676            0             0  42.78             220.0   \n",
       "31772784 15123107            1             0    NaN             475.0   \n",
       "32906132 14029832            0             0    NaN             300.0   \n",
       "35949655 10240707            0             0    NaN             100.0   \n",
       "33571346 13443421            0             0    NaN             350.0   \n",
       "\n",
       "                     supplemental_oxygen  invasive_vent  hfnc  \\\n",
       "stay_id  subject_id                                             \n",
       "30529524 19052676                      0              1     0   \n",
       "31772784 15123107                      1              0     0   \n",
       "32906132 14029832                      0              0     0   \n",
       "35949655 10240707                      0              0     0   \n",
       "33571346 13443421                      0              1     0   \n",
       "\n",
       "                     non_invasive_vent  tracheostomy  min_day_rrt_present  \\\n",
       "stay_id  subject_id                                                         \n",
       "30529524 19052676                    0             0           99999999.0   \n",
       "31772784 15123107                    0             0           99999999.0   \n",
       "32906132 14029832                    0             0           99999999.0   \n",
       "35949655 10240707                    0             0           99999999.0   \n",
       "33571346 13443421                    0             0           99999999.0   \n",
       "\n",
       "                     min_day_rrt_active  weight_admit  weight_min  weight_max  \\\n",
       "stay_id  subject_id                                                             \n",
       "30529524 19052676            99999999.0          77.0        77.0        77.0   \n",
       "31772784 15123107            99999999.0          67.4        67.4        69.9   \n",
       "32906132 14029832            99999999.0          77.8        77.8        77.8   \n",
       "35949655 10240707            99999999.0         125.3       125.3       125.3   \n",
       "33571346 13443421            99999999.0          59.8        59.8        59.8   \n",
       "\n",
       "                     hospital_expire_flag  \n",
       "stay_id  subject_id                        \n",
       "30529524 19052676                       0  \n",
       "31772784 15123107                       0  \n",
       "32906132 14029832                       0  \n",
       "35949655 10240707                       0  \n",
       "33571346 13443421                       0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dropna(axis=1, thresh = int(0.3*data.shape[0]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_window = 3\n",
    "\n",
    "# data.loc[(((data['aki_kdigo_grade_1']== 1)| (data['aki_kdigo_grade_2']== 1) | (data['aki_kdigo_grade_3']==1)) \\\n",
    "#     &( (data['day_detection_kdigo_grade_1']<=prediction_window)| (data['day_detection_kdigo_grade_2']<=prediction_window) | (data['day_detection_kdigo_grade_3']<=prediction_window)) \\\n",
    "#         |(data['min_day_rrt_present']<= prediction_window)), 'outcome'] = 1\n",
    "\n",
    "\n",
    "# data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_window = 3\n",
    "\n",
    "data.loc[(( (data['aki_kdigo_grade_1']== 1)) \\\n",
    "    &( (data['day_detection_kdigo_grade_1']<=prediction_window))), 'outcome'] = 1\n",
    "\n",
    "\n",
    "data.loc[data.outcome.isna(),'outcome']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "'day_detection_kdigo_grade_1',\n",
    "'day_detection_kdigo_grade_2',\n",
    "'day_detection_kdigo_grade_3',\n",
    "'day_detection_mkdigo_grade_1',\n",
    "'day_detection_mkdigo_grade_2',\n",
    "'day_detection_mkdigo_grade_3',\n",
    "'min_day_rrt_active',\n",
    "'min_day_rrt_present',\n",
    "'ckd',\n",
    "'chronic_kidney_disease'\n",
    "]\n",
    "# CRP and vomit_nausea as they had mostly empty\n",
    "\n",
    "data.drop(drop_X, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missingness percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = 20 # remove rows with NaN is 80 or more in each row\n",
    "min_count =  int(((100-perc)/100)*data.shape[0])\n",
    "data.dropna(axis=1, thresh = min_count, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.reset_index().drop_duplicates(subset=['stay_id','subject_id','hadm_id']).set_index(['stay_id','subject_id','hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove unpopulated columns\n",
    "# data.pipe(sort)\\\n",
    "#               .pipe(replace_inf).pipe(drop_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by column type\n",
    "data_num = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'numerical')\n",
    "\n",
    "data_cat = data.pipe(sort).pipe(replace_inf).pipe(drop_empty).pipe(select, 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cat = data_cat.pipe(filter_categorical, cutoff=20, plot=False)\\\n",
    "#                                             .pipe(sort).pipe(spy, title='Before onehot', figsize=[12,4])\\\n",
    "#                                             .fillna('other').pipe(onehot)\n",
    "# data_cat = data_cat.fillna('other').pipe(onehot)\n",
    "data_cat = pd.get_dummies(data_cat,prefix=[''], prefix_sep='', columns = ['ethnicity'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed = pd.merge(data_num, data_cat, left_index=True, right_index=True)\n",
    "processed = pd.merge(data_num, data_cat, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2 = processed.copy()\n",
    "# processed.drop(['egfr_epi_scr','egfr_mdrd_scr'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04590799339179057"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(processed[processed['aki_kdigo_grade_3']==1].shape[0])/processed.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18466"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(processed[processed['aki_kdigo_grade_1']==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31476, 90)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# X_MI = np.array(processed.creatinine_max).reshape(-1,1)\n",
    "# y_MI = np.array(processed.outcome)\n",
    "\n",
    "# mi = mutual_info_classif(X_MI,y_MI)\n",
    "# mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKI_1_df = (processed[processed['outcome']==1])\n",
    "# AKI_0_df = (processed[processed['outcome']==0])\n",
    "\n",
    "# columns = ['egfr_epi_scr_max', 'egfr_mdrd_scr_max','creatinine_max','creatinine_min']\n",
    "\n",
    "\n",
    "\n",
    "# dfwiz_compare(AKI_1_df, AKI_0_df, columns=columns, label = ['AKi_1', 'AKI_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKI_1_df.hospital_expire_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKI_0_df.hospital_expire_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X   = [\n",
    "    'aki_kdigo_grade_1',\n",
    "    'aki_mkdigo_grade_1',\n",
    "\n",
    "    'aki_kdigo_grade_2',\n",
    "    'aki_mkdigo_grade_2',\n",
    "\n",
    "    'aki_kdigo_grade_3',\n",
    "    'aki_mkdigo_grade_3',\n",
    "    'is_mdrd',\n",
    "    'hospital_expire_flag'\n",
    "\n",
    "]\n",
    " \n",
    "select_y = ['outcome']\n",
    "\n",
    "processed_X = processed.pipe(filter_regex, drop_X+select_y)\n",
    "processed_Y = processed.filter(regex='|'.join(select_y))\n",
    "raw_Y = data_num.pipe(replace_inf).pipe(drop_empty).filter(regex='|'.join(select_y)).pipe(remove_outliers)\n",
    "df_y = raw_Y[select_y]\n",
    "\n",
    "\n",
    "df_X, df_y = match(processed_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.female.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_X, df_y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_0, X_valid, y_train_0, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y) # \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_0, y_train_0, test_size=0.25, random_state=42, shuffle=True, stratify=y_train_0) #0.25 *0.8 = 0.2 for test and 0.75*0.8 = 0.60 for train\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train.copy()\n",
    "y_train_copy = y_train.copy()\n",
    "\n",
    "train_df = pd.merge(X_train_copy, y_train_copy, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "train_df.drop([col for col in train_df.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "processed_copy = processed2.copy()\n",
    "processed_copy = pd.merge(processed_copy, train_df, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "processed_copy.drop([col for col in processed_copy.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AKI_1_df = (processed_copy[processed_copy['outcome']==1])\n",
    "AKI_0_df = (processed_copy[processed_copy['outcome']==0])\n",
    "\n",
    "columns = ['egfr_epi_scr_max', 'egfr_mdrd_scr_max','creatinine_max','creatinine_min']\n",
    "\n",
    "\n",
    "\n",
    "dfwiz_compare(AKI_1_df, AKI_0_df, columns=columns, label = ['AKi_1', 'AKI_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "def scale_impute(df, pipe):\n",
    "    data_scaled = pipe.named_steps['scaler'].transform(df)\n",
    "    df_scaled = pd.DataFrame(data_scaled, columns=df.columns)\n",
    "    data_imputed = pipe.named_steps['imputer'].transform(df_scaled)\n",
    "    df_result = pd.DataFrame(data_imputed, columns=df.columns)\n",
    "    return df_result\n",
    "\n",
    "X_train_copy = X_train.copy()\n",
    "y_train_copy = y_train.copy()\n",
    "\n",
    "X_train_copy = scale_impute(X_train_copy, pipeline_final)\n",
    "\n",
    "\n",
    "X_MI = np.array(X_train_copy.creatinine_max).reshape(-1,1)\n",
    "y_MI = np.array(y_train_copy.outcome)\n",
    "\n",
    "mi = mutual_info_classif(X_MI,y_MI)\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_1_df.hospital_expire_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_1_df.query(\"hospital_expire_flag==1\").shape[0]/AKI_1_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_0_df.hospital_expire_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_0_df.query(\"hospital_expire_flag==1\").shape[0]/AKI_0_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = df_X, df_y\n",
    "# X_train, y_train = up_sample(X_train, y_train,'outcome')\n",
    "# X_train,  y_train = [\n",
    "#     df.reset_index(drop=True)\n",
    "#     for df in up_sample(X_train, y_train,'outcome')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfwiz_compare(X_train,X_test, label=['df_train','df_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.query(\"outcome==1\").sum()/df_y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm  # standard alias\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "# ('resample', upsampler()),\n",
    "('scaler', MinMaxScaler()),\n",
    "('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan)),\n",
    "('model', lgbm.LGBMClassifier(n_jobs=-1, n_estimators=300))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### Cross validation search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### **************************************8\n",
    "# # Make sure simpler models are at the start of array. The search picks numbers on the left side if they are within the error of maximum score.   \n",
    "\n",
    "\n",
    "# param_grid ={'model__num_leaves': [6, 10, 20, 50], \n",
    "#              'model__min_child_samples': [100, 200, 300, 400, 500], \n",
    "#              'model__min_child_weight': [1e-5,  1e-2,  1,  1e2,  1e4],\n",
    "#              'model__subsample' : [0.2, 0.5, 0.8], \n",
    "#              'model__reg_alpha': [0, 1e-1, 1, 5,  10, 50, 100],\n",
    "#              'model__reg_lambda': [0, 1e-1, 1,  10,  50, 100]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# score, best_params, pipeline_final = param_graph(X_train, y_train, pipe, param_grid, cv=5, max_iter = 4, sample_ratio = 0.1, refit=False, use_error=True)\n",
    "\n",
    "# # dump(pipeline_final , open('pipeline_final_LGBM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgbm  # standard alias\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "# # ('resample', upsampler()),\n",
    "# ('scaler', MinMaxScaler()),\n",
    "# ('imputer',IterativeImputer(max_iter=10, random_state=42, missing_values=np.nan, sample_posterior=True)),\n",
    "# ('model', lgbm.LGBMClassifier(n_jobs=-1))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt import BayesSearchCV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# bayes_cv_tuner = BayesSearchCV(\n",
    "#     estimator = pipe\n",
    "#     ,search_spaces = {\n",
    "#         'model__n_estimators': (100,200,300,400),\n",
    "#         'model__num_leaves': (6, 10, 20, 50), \n",
    "#         'model__min_child_samples': (100, 200, 300, 400, 500), \n",
    "#         'model__min_child_weight': (1e-5,  1e-2,  1,  1e2,  1e4),\n",
    "#         'model__subsample' : (0.2, 0.5, 0.8), \n",
    "#         'model__reg_alpha': (0, 1e-1, 1, 5,  10, 50, 100),\n",
    "#         'model__reg_lambda': (0, 1e-1, 1,  10,  50, 100)\n",
    "\n",
    "#     }, \n",
    "#     cv = StratifiedKFold(\n",
    "#         n_splits=5,\n",
    "#         shuffle=True,\n",
    "#     ),\n",
    "#     # cv=3,\n",
    "#     n_jobs = 3,\n",
    "#     n_iter = 10,   \n",
    "#     verbose = 0,\n",
    "#     scoring='f1'\n",
    "# )\n",
    "\n",
    "# sample_ratio = 0.1\n",
    "# n_samples = int(len(X_train)*sample_ratio)\n",
    "# X, y = resample(X_train.values, y_train.values, n_samples=n_samples, stratify=y_train.values, random_state=10)\n",
    "# result = bayes_cv_tuner.fit(X, y.ravel())\n",
    "# # print(result.score(X_test, y_test))\n",
    "# print(result.best_params_)\n",
    "# print(result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Fitting Pipeline one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual params setting\n",
    "best_params = {'model__n_estimators': 400,'model__num_leaves': 50, 'model__min_child_samples': 100, 'model__min_child_weight': 1, 'model__subsample': 0.2, 'model__reg_alpha': 50, 'model__reg_lambda': 0}\n",
    "\n",
    "# Or get parameters from search above\n",
    "best_params2 = best_params\n",
    "\n",
    "sample_ratio = 1\n",
    "n_samples = int(len(X_train)*sample_ratio)\n",
    "X, y = resample(X_train.values, y_train.outcome.values, n_samples=n_samples, stratify=y_train.values, random_state=10)\n",
    "pipeline_final = copy.deepcopy(pipe)\n",
    "pipeline_final.set_params(**best_params2)\n",
    "pipeline_final.fit(X, y.ravel());\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"_\"*150)\n",
    "print(\"\")\n",
    "print(\"Train Accuracy:\")\n",
    "print(\"\")\n",
    "\n",
    "y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final.predict_proba(X)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dump(pipeline_final, open('pipe_rf.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "def scale_impute(df, pipe):\n",
    "    data_scaled = pipe.named_steps['scaler'].transform(df)\n",
    "    df_scaled = pd.DataFrame(data_scaled, columns=df.columns)\n",
    "    data_imputed = pipe.named_steps['imputer'].transform(df_scaled)\n",
    "    df_result = pd.DataFrame(data_imputed, columns=df.columns)\n",
    "    return df_result\n",
    "\n",
    "X_train_copy = X_train.copy()\n",
    "y_train_copy = y_train.copy()\n",
    "\n",
    "X_train_copy = scale_impute(X_train_copy, pipeline_final)\n",
    "\n",
    "\n",
    "X_MI = np.array(X_train_copy[['creatinine_max','egfr_epi_scr_max']])\n",
    "y_MI = np.array(y_train_copy.outcome)\n",
    "\n",
    "mi = mutual_info_classif(X_MI,y_MI)\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X,y = pipeline_final.named_steps['resample'].fit_resample(X_test, y_test)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "clf_threshold = 0.45\n",
    "\n",
    "X,y = X_valid.values, y_valid.values\n",
    "\n",
    "y_pred = pipeline_final.predict(X)\n",
    "y_pred_proba = pipeline_final.predict_proba(X)\n",
    "y_pred  = (y_pred_proba[:,1] >= clf_threshold).astype(int)\n",
    "\n",
    "confusion_matrix_plot(y, y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_kappa_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_XGB_grade123, tpr_XGB_grade123, _ = metrics.roc_curve(y,   y_pred_proba[::,1])\n",
    "%store fpr_XGB_grade123\n",
    "%store tpr_XGB_grade123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r fpr_RF_grade123\n",
    "%store -r tpr_RF_grade123\n",
    "\n",
    "%store -r fpr_ANN_grade123\n",
    "%store -r tpr_ANN_grade123\n",
    "\n",
    "%store -r fpr_LR_grade123\n",
    "%store -r tpr_LR_grade123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (7.5,6)\n",
    "plt.rcParams[\"figure.figsize\"] = (9,8)\n",
    "mpl.rcParams['lines.linewidth'] = 1.5\n",
    "plt.plot(fpr_XGB_grade123,tpr_XGB_grade123,label=\"XGB (AUC=0.90)\")\n",
    "plt.plot(fpr_RF_grade123,tpr_RF_grade123,label=\"RF    (AUC=0.88)\")\n",
    "plt.plot(fpr_LR_grade123,tpr_LR_grade123,label=\"LR    (AUC=0.87)\")\n",
    "plt.plot(fpr_ANN_grade123,tpr_ANN_grade123,label=\"ANN (AUC=0.86)\")\n",
    "plt.plot([0, 1], [0, 1], marker=\".\", alpha=0.4)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator = pipeline_final._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = final_estimator.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train.columns\n",
    "plt.rcParams[\"figure.figsize\"] = (12,20)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_impute(df, pipe):\n",
    "    data_scaled = pipe.named_steps['scaler'].transform(df)\n",
    "    df_scaled = pd.DataFrame(data_scaled, columns=df.columns)\n",
    "    data_imputed = pipe.named_steps['imputer'].transform(df_scaled)\n",
    "    df_result = pd.DataFrame(data_imputed, columns=df.columns)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "exp = dx.Explainer(pipeline_final, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_parts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number = 1\n",
    "exp.predict_parts(X_test.iloc[[row_number]], N=100).plot(min_max=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_t = scale_impute_via_pipeline(df=X_test,pipe=pipeline_final)\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(final_estimator)\n",
    "shap_values = explainer.shap_values(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.temperature_min.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.temperature_min.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"age\",shap_values[1], X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_t = scale_impute_via_pipeline(X_train, pipeline_final)\n",
    "shap.initjs()\n",
    "# X_sampled = df_X_train_imp.sample(100, random_state=10)\n",
    "explainer = shap.TreeExplainer(final_estimator)\n",
    "shap_values = explainer.shap_values(X_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"age\",shap_values[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_train_t,max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_test_t = scale_impute(df=X_test,pipe=pipeline_final)\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(pipeline_final._final_estimator)\n",
    "shap_values = explainer.shap_values(X_test_t)\n",
    "shap.summary_plot(shap_values[1], X_test_t, max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X_train.columns:\n",
    "    shap.dependence_plot(name, shap_values[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHAP values\n",
    "\n",
    "# compute SHAP values\n",
    "X_test_t = scale_impute(df=X_test,pipe=pipeline_final)\n",
    "shap.initjs()\n",
    "explainer = shap.Explainer(pipeline_final._final_estimator, X_test_t)\n",
    "shap_values = explainer(X_test_t,check_additivity=False)\n",
    "shap.plots.beeswarm(shap_values,max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number=1\n",
    "single_observation = X_train.iloc[[row_number]].values[0]\n",
    "X_train_t = scale_impute(df=X_train,pipe=pipeline_final)\n",
    "\n",
    "# data = shap_values.data[row_number]\n",
    "# data = single_observation\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.Explainer(final_estimator,X_train_t, check_additivity=False)\n",
    "# shap_values = explainer(X_train_t)\n",
    "shap_values = explainer(single_observation)\n",
    "\n",
    "\n",
    "\n",
    "class ShapObject:\n",
    "    \n",
    "    def __init__(self, base_values, data, values, feature_names):\n",
    "        self.base_values = base_values # Single value\n",
    "        self.data = data # Raw feature values for 1 row of data\n",
    "        self.values = values # SHAP values for the same row of data\n",
    "        self.feature_names = feature_names # Column names\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "shap_object = ShapObject(base_values = shap_values.base_values[row_number],\n",
    "                         values = shap_values.values[row_number],\n",
    "                         feature_names = single_observation.columns,\n",
    "                         data = single_observation)\n",
    "\n",
    "                         \n",
    "\n",
    "shap.waterfall_plot(shap_object, max_display=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining X_test,y_test and y_pred in one dataset\n",
    "# del(df_test_all)\n",
    "df_test_all = X_test.copy()\n",
    "df_test_all['y_actual'] = y_test\n",
    "df_test_all['y_pred'] = y_pred\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3\n",
    "\n",
    "# df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TN = df_test_all[df_test_all.error_category==0]\n",
    "df_FP = df_test_all[df_test_all.error_category==1]\n",
    "\n",
    "df_TP = df_test_all[df_test_all.error_category==2]\n",
    "df_FN = df_test_all[df_test_all.error_category==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "df_TN_shap = df_TN.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "df_TN_shap = scale_impute_via_pipeline(df_TN_shap)\n",
    "shap.initjs()\n",
    "# X_sampled = df_X_train_imp.sample(100, random_state=10)\n",
    "explainer = shap.TreeExplainer(final_estimator)\n",
    "shap_values = explainer.shap_values(df_TN_shap)\n",
    "shap.summary_plot(shap_values[1], df_TN_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "# error_df = {\"df_FP\":df_FP, \"df_FN\":df_FN}\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "    df_shap = scale_impute_via_pipeline(df_shap, final_estimator)\n",
    "\n",
    "    explainer = shap.TreeExplainer(final_estimator)\n",
    "    shap_values = explainer.shap_values(df_shap)\n",
    "    print(\"SHAP: \"+k)\n",
    "    shap.summary_plot(shap_values[1], df_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_processed = processed2.copy()\n",
    "common_FN = pd.merge(df_FN, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "common_FN.drop([col for col in common_FN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "common_FN.aki_kdigo_grade_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FN.aki_kdigo_grade_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FN.aki_kdigo_grade_3.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "exp = dx.Explainer(pipeline_final, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_performance(model_type='classification').plot(geom='roc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_parts().plot(max_vars=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number = 1\n",
    "exp.predict_parts(X_test.iloc[[row_number]], N=100).plot(min_max=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[[row_number]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[row_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "# error_df = {\"df_FP\":df_FP, \"df_FN\":df_FN}\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "\n",
    "    row_number = 1\n",
    "    print(\"SHAP: \"+k)\n",
    "    exp.predict_parts(df_shap.iloc[[row_number]], N=100).plot(min_max=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap.iloc[[281]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break-down plot using Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "rand_list = random.sample(range(0, df_FP.shape[0]), 10)\n",
    "\n",
    "clf_threshold = 0.38\n",
    "import dalex as dx\n",
    "\n",
    "# error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "error_df = {\"df_FP\":df_FP}\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "\n",
    "    for row_number in rand_list:\n",
    "        print(\"Using DALEX on false positive instance with row number: \"+str(row_number))\n",
    "        exp.predict_parts(df_shap.iloc[[row_number]], N=100).plot(min_max=[0,1], max_vars=30, baseline=clf_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP plot using Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "rand_list = random.sample(range(0, df_FP.shape[0]), 10)\n",
    "\n",
    "clf_threshold = 0.38\n",
    "import dalex as dx\n",
    "\n",
    "# error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "error_df = {\"df_FP\":df_FP}\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "\n",
    "    for row_number in rand_list:\n",
    "        print(\"Using DALEX SHAP on false positive instance with row number: \"+str(row_number))\n",
    "        exp.predict_parts(df_shap.iloc[[row_number]], N=100, type='shap').plot(min_max=[0,1], max_vars=30, baseline=clf_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP.creatinine_max.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TN.creatinine_min.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "rand_list = random.sample(range(0, df_TN.shape[0]), 10)\n",
    "\n",
    "\n",
    "import dalex as dx\n",
    "\n",
    "# error_df = {\"df_TN\":df_TN, \"df_FP\":df_FP, \"df_TP\":df_TP, \"df_FN\":df_FN}\n",
    "error_df = {\"df_TN\":df_TN}\n",
    "\n",
    "for k,df in error_df.items():\n",
    "    df_shap = df.drop(['y_pred','y_actual','error_category'], axis=1)\n",
    "\n",
    "    for row_number in rand_list:\n",
    "        print(\"Using DALEX on true negative instance with row number: \"+str(row_number))\n",
    "        exp.predict_parts(df_shap.iloc[[row_number]], N=100).plot(min_max=[0,1], max_vars=30, baseline=clf_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the DataFrames\n",
    "# common_processed = processed2.copy()\n",
    "common_processed = processed.copy()\n",
    "common_FP = pd.merge(df_FP, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FP.drop([col for col in common_FP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TN = pd.merge(df_TN, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TN.drop([col for col in common_TN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_TP = pd.merge(df_TP, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_TP.drop([col for col in common_TP.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_FN = pd.merge(df_FN, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_FN.drop([col for col in common_FN.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Merge the DataFrames\n",
    "common_test_all = pd.merge(df_test_all, common_processed, how='inner', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "#Drop the duplicate columns\n",
    "common_test_all.drop([col for col in common_test_all.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FP.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FP, kind=\"hex\", joint_kws={'color':'#66ffcc'})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<60].shape[0])/(common_FP.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<60].shape[0])/(processed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_TN[common_TN.egfr_epi_scr<60].shape[0])/(common_TN.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(common_FP[common_FP.egfr_epi_scr<60].shape[0])/(processed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_TP, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FN, kind=\"hex\", joint_kws={'color':\"#66ffcc\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr_max\", y=\"age\", data=common_FN, kind=\"hex\", joint_kws={'color':\"#ffe6ff\"})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=\"egfr_epi_scr\", y=\"age\", data=common_FP, kind=\"hex\", joint_kws={'color':'#66ffcc'})\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.axvline(60, 0,10, linestyle='--', color = 'red', linewidth=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "sns.histplot(data=common_FP, x=common_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"percent\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hist2d(common_FP.egfr_epi_scr, common_FP.age, bins=[x_bins, y_bins])\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins\n",
    "x_min = np.min(common_FP.egfr_epi_scr)\n",
    "x_max = np.max(common_FP.egfr_epi_scr)\n",
    "  \n",
    "y_min = np.min(common_FP.age)\n",
    "y_max = np.max(common_FP.age)\n",
    "  \n",
    "x_bins = np.linspace(x_min, x_max, 50)\n",
    "y_bins = np.linspace(y_min, y_max, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "plt.hexbin(common_FP.egfr_epi_scr, common_FP.age, bins=50)\n",
    "plt.axvline(90, 0,10, linestyle='--', color = 'blue', linewidth=1.5)\n",
    "plt.title(\"2D histogram of false positives\")\n",
    "ax.set_xlabel('minimum EGFR') \n",
    "ax.set_ylabel('Age') \n",
    "\n",
    "# show plot\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(common_FP.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=common_FP, x=col, bins=50, stat='percent', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for True negative and  False positive and compare their distribution.\n",
    "# It plots the distribution and prints Jensen-Shanon distance.\n",
    "# from functions_compare_distribution import compare_hist_df\n",
    "from dfwiz import dfwiz, dfwiz_compare\n",
    "# healthy patients\n",
    "TN = df_test_all.query(\"error_category == 0\")[X_test.columns] # True negative\n",
    "FP = df_test_all.query(\"error_category == 1\")[X_test.columns] # False positive\n",
    "\n",
    "if len(TN) == 0 or len(FP) == 0:\n",
    "    print(\"Error! one of the dataframes are empty\")\n",
    "else:\n",
    "    # compare_hist_df(TN, FP) # plot distributions and output Jensen-Shanon distance.\n",
    "    dfwiz_compare(FP, TN,label=['FP', 'TN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.kdeplot(data=df_test_all, x=col, hue='error_category', bins=50, stat='density', common_norm=False);\n",
    "    plt.title(col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', common_norm=False, bins=50, stat=\"percent\");\n",
    "    plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_FP, x=df_FP.egfr_epi_scr, hue='age', common_norm=False, bins=50, stat=\"density\");\n",
    "plt.title(\"Kernel Density Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_test_all.columns):\n",
    "    plt.figure(i)\n",
    "    sns.histplot(data=df_test_all, x=col, hue='error_category', bins=len(df_test_all), stat='density', element=\"step\", fill=False, cumulative=True,common_norm=False);\n",
    "    plt.title(\"Cumulative distribution function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree on validation set to differentiate between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the category of error\n",
    "del(df_test_all)\n",
    "\n",
    "\n",
    "# X_test_scaled_array = pipeline_final.named_steps['scaler'].transform(X_test)\n",
    "# X_test_scaled = pd.DataFrame(X_test_scaled_array, columns=X_test.columns)\n",
    "# X_test_imp_array = pipeline_final.named_steps['imputer'].transform(X_test_scaled)\n",
    "# df_test_all = pd.DataFrame(X_test_imp_array, columns=X_test.columns)\n",
    "\n",
    "\n",
    "X_test_imp_array = pipeline_final.named_steps['imputer'].transform(X_test)\n",
    "df_test_all = pd.DataFrame(X_test_imp_array, columns=X_test.columns)\n",
    "\n",
    "\n",
    "# df_test_all['y_actual'] = y_valid.values.ravel()\n",
    "df_test_all['y_actual'] = y_test.values.ravel()\n",
    "df_test_all['y_pred'] = y_pred\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # To suppress a warning for commands below \n",
    "\n",
    "df_test_all['error_category'] = 0 # create'error_category' column\n",
    "for i in df_test_all.index:\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 0: # True negative 0 \n",
    "          df_test_all['error_category'][i] = 0\n",
    "     if df_test_all['y_actual'][i] == 0 and df_test_all['y_pred'][i] == 1: # False positive 1\n",
    "          df_test_all['error_category'][i] = 1\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 1: # True positive 2\n",
    "          df_test_all['error_category'][i] = 2\n",
    "     if df_test_all['y_actual'][i] == 1 and df_test_all['y_pred'][i] == 0: # False negative 3\n",
    "          df_test_all['error_category'][i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP_TN = df_test_all.loc[(df_test_all['error_category'] == 0) | (df_test_all['error_category'] == 1)]\n",
    "df_FP_FN = df_test_all.loc[(df_test_all['error_category'] == 1) | (df_test_all['error_category'] == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP_TN.error_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP_FN.error_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['TN', 'FP']\n",
    "df1 = df_FP_TN.copy()\n",
    "X1 = df1[X_test.columns]\n",
    "X1\n",
    "y1 =  df1[['error_category']]\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 5 , class_weight='balanced', random_state=42, criterion=\"gini\", min_impurity_decrease = 0.01)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "plt.figure(figsize=(20,12))\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = list(X1.columns), \n",
    "               rounded=True, \n",
    "               filled = True,\n",
    "               proportion = True,\n",
    "               class_names = class_names);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a descision tree to predict the model error in negative cases ('True negative' vs 'False positive'). \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['FP', 'FN']\n",
    "df1 = df_FP_FN.copy()\n",
    "X1 = df1[X_test.columns]\n",
    "X1\n",
    "y1 =  df1[['error_category']]\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 5 , class_weight='balanced', random_state=42, criterion=\"gini\", min_impurity_decrease = 0.01)\n",
    "clf = clf.fit(X1, y1)\n",
    "\n",
    "# plot the tree\n",
    "plt.figure(figsize=(20,12))\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = list(X1.columns), \n",
    "               rounded=True, \n",
    "               filled = True,\n",
    "               proportion = True,\n",
    "               class_names = class_names);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.loc[~(y_error_t==1)]\n",
    "y_train_new = y_train.loc[~(y_error_t==1)]\n",
    "\n",
    "X_valid_new = X_valid.loc[~(y_error_v==1)]\n",
    "y_valid_new = y_valid.loc[~(y_error_v==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new, y_train_new = up_sample(X_train_new, y_train_new,'outcome')\n",
    "X_train_new, y_train_new = up_sample(X_train, y_train,'outcome')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7ea45291871ad6e398ab50f9f84dad559e0de667f49db4aea6ebf0e175149ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
